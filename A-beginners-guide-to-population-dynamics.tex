\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{unicode=true,
            pdftitle={Introduction to R for Population dynamics},
            pdfauthor={Anthony Davidson},
            colorlinks=true,
            linkcolor=blue,
            citecolor=Blue,
            urlcolor=blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Introduction to R for Population dynamics}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Anthony Davidson}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{Build from Ben Statons R book with contributions by Henry Hershey}

\usepackage{booktabs}
\usepackage{pdfpages}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\let\oldmaketitle\maketitle
\AtBeginDocument{\let\maketitle\relax}

\begin{document}
\maketitle

% % \thispagestyle{empty}
% \begin{center}
% % {\Huge A BOOK}
% \includegraphics{cover_image.png}
% % {\huge by Me}
% \end{center}
%
% \let\maketitle\oldmaketitle
% \maketitle

% \cleardoublepage\newpage\thispagestyle{empty}\null
% \cleardoublepage\newpage\thispagestyle{empty}\null
% \cleardoublepage\newpage
% \thispagestyle{empty}
% \cleardoublepage\begin{center}
% \newgeometry{left=0cm,right=0cm,top=0cm,bottom=0cm}
% \includegraphics{cover_image.png}
% \restoregeometry
% \end{center}
% \setlength{\abovedisplayskip}{-5pt}
% \setlength{\abovedisplayshortskip}{-5pt}

\includepdf[pages={1}]{img/cover_image.pdf}
\thispagestyle{empty}
\let\maketitle\oldmaketitle
\maketitle
\thispagestyle{empty}

{
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{overview}{%
\chapter*{Overview}\label{overview}}
\addcontentsline{toc}{chapter}{Overview}

To begin with this model defines the life cycle of a species, then extendes this to estimate population size and growth rate over a projected time frame and then analysis the elasticity and sensistivity of the matrix population model. I have done this with southern right whales as an example.

\hypertarget{what-is-covered}{%
\section*{What is Covered?}\label{what-is-covered}}
\addcontentsline{toc}{section}{What is Covered?}

The book is composed of six chapters intended to cover a suite of topics in introductory R programming. In general, the material builds in complexity from chapter to chapter and earlier chapters can be seen as prerequisites for later chapters.

\begin{itemize}
\tightlist
\item
  \textbf{Chapter \ref{ch1}} covers the basics of working in R through RStudio, including the basics of the R coding language and environment.
\item
  \textbf{Chapter \ref{ch2}} covers the basics of plotting using the base R graphics functionality.
\item
  \textbf{Chapter \ref{ch3}} covers the basics of fitting statistical models using built-in functionality for generalized linear models as well as non-linear models.\\
\item
  \textbf{Chapter \ref{ch4}} covers the basics of simulation modeling in R.
\item
  \textbf{Chapter \ref{ch5}} covers the basics of the \texttt{\{dplyr\}} and \texttt{\{reshape2\}} packages for manipulating and summarizing large data sets using highly readable code.
\item
  \textbf{Chapter \ref{ch6}} covers the basics of producing maps and performing spatial analysis in R. \emph{This chapter was contributed by Henry Hershey}
\end{itemize}

\hypertarget{external-resources}{%
\section{External Resources}\label{external-resources}}

This book is an extention of several gitbooks that are intended to be a first course in R programming for a range of different professionals. It is by no means comprehensive (no book about R ever could be), but instead attempts to introduce the main topics and develop the skills needed to get a beginner up and running with applying R to their own work in the context of population dynamics. Some of the courses were intended to be a companion to in-person workshop sessions. Although the examples shown have a natural resource/ecological theme, the general skills presented are general to R users across all scientific disciplines.

\hypertarget{ch4}{%
\chapter{Monte Carlo Methods}\label{ch4}}

\hypertarget{chapter-overview}{%
\section*{Chapter Overview}\label{chapter-overview}}
\addcontentsline{toc}{section}{Chapter Overview}

Simulation modeling is one of the primary reasons to move away from \texttt{spreadsheet-type} programs (like Microsoft Excel) and into a program like \texttt{R}. R allows you to replicate the same (possibly complex and detailed) calculations over and over with different random values. You can then summarize and plot the results of these replicated calculations all within the same program. Analyses of this type are called \textbf{Monte Carlo methods}: they randomly sample from a set of quantities for the purpose of generating and summarizing a distribution of some statistic related to the sampled quantities. If this concept is confusing, hopefully this chapter will clarify.

In this chapter, you will learn the basic skills needed for simulation (i.e., Monte Carlo) modeling in R including:

\begin{itemize}
\tightlist
\item
  introduce randomness to a model
\item
  repeat calculations many times with \texttt{replicate()} and \texttt{for()} loops
\item
  summarization of many values from a distribution
\item
  more advanced function writing
\item
  applying population dynamics \emph{added by Anthony}
\end{itemize}

\textbf{IMPORTANT NOTE}: If you did not attend the sessions corresponding to Chapters \ref{ch1} or \ref{ch2} or \ref{ch3}, you are recommended to walk through the material found in those chapters before proceeding to this material. Remember that if you are confused about a topic, you can use \textbf{CTRL + F} to find previous cases where that topic has been discussed in this book.

\hypertarget{before-you-begin}{%
\section*{Before You Begin}\label{before-you-begin}}
\addcontentsline{toc}{section}{Before You Begin}

You should create a new directory and R script for your work in this Chapter. Create a new R script called \texttt{Ch4.R} and save it in the directory \texttt{C:/Users/YOU/Documents/R-Book/Chapter4}. Set your working directory to that location. Revisit the material in Sections \ref{scripts} and \ref{working-dir} for more details on these steps.

\hypertarget{layout-of-this-chapter}{%
\section*{Layout of This Chapter}\label{layout-of-this-chapter}}
\addcontentsline{toc}{section}{Layout of This Chapter}

This chapter is divided into three main sections:

\begin{itemize}
\item
  \textbf{Required Material} (Sections \ref{randomness} - \ref{mc-summaries}) which is necessary to understand the examples in this chapter and the subsequent chapters
\item
  \textbf{Example Cases} (Sections \ref{sim-examples} and \ref{resample-examples}) which apply the skills learned in the required material. In the workshop session, you will walkthrough 2-3 of these example cases at the choice of the group of the participants. If you are interested in simulation modeling, you are suggested to work through all of the example cases, as slightly different tricks will be shown in the different examples.
\item
  \textbf{Population dynamics} (Sections \ldots) - this is an extention of simulation and MCMC methods to estimate the viability of populations (PVA).
\end{itemize}

\hypertarget{randomness}{%
\section{Introducing Randomness}\label{randomness}}

A critical part of simulation modeling is the use of random processes. A \textbf{random process} is one that generates a different outcome according to some rules each time it is executed. They are tightly linked to the concept of \textbf{uncertainty}: you are unsure about the outcome the next time the process is executed. There are two basic ways to introduce randomness in R: \textbf{random deviates} and \textbf{resampling}.

\hypertarget{random-deviates}{%
\subsection{Random deviates}\label{random-deviates}}

In Section \ref{dists}, you learned about using probability distributions in R. One of the uses was the \texttt{r-} family of distribution functions. These functions create random numbers following a random process specified by a probability distribution.

Consider animal survival as an example. At the end of each year, each individual alive at the start can either live or die. There are two outcomes here, and suppose each animal has an 80\% chance of surviving. The number of individuals that survive is the result of a \textbf{binomial random process} in which there were \(n\) individuals alive at the start of this year and \(p\) is the probability that any one individual survives to the next year. You can execute one binomial random process where \(p = 0.8\) and \(n = 100\) like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rbinom}\NormalTok{(}\DataTypeTok{n =} \DecValTok{1}\NormalTok{, }\DataTypeTok{size =} \DecValTok{100}\NormalTok{, }\DataTypeTok{prob =} \FloatTok{0.8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 88
\end{verbatim}

The result you get will almost certainly be different from the one printed here. That is the random component.

You can execute many such binomial processes by changing the \texttt{n} argument. Plot the distribution of expected surviving individuals:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survivors =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\DecValTok{100}\NormalTok{, }\FloatTok{0.8}\NormalTok{)}
\KeywordTok{hist}\NormalTok{(survivors, }\DataTypeTok{col =} \StringTok{"skyblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-5-1} \end{center}

Another random process is the \textbf{lognormal process}: it generates random numbers such that the log of the values are normally-distributed with mean equal to \texttt{logmean} and standard deviation equal to \texttt{logsd}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(}\KeywordTok{rlnorm}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.1}\NormalTok{), }\DataTypeTok{col =} \StringTok{"skyblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-7-1} \end{center}

There are many random processes you can use in R. Checkout Table \ref{tab:dist-table-pdf} for more examples as well as the help files for each individual function for more details.

\hypertarget{resampling}{%
\subsection{Resampling}\label{resampling}}

Using random deviates works great for creating new random numbers, but what if you already have a set of numbers that you wish to introduce randomness to? For this, you can use \textbf{resampling techniques}. In R, the \texttt{sample()} function is used to sample \texttt{size} elements from the vector \texttt{x}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sample}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{size =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5 4 3 1 7
\end{verbatim}

You can sample with replacement (where it is possible to sample the same element two or more times):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sample}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{), }\DataTypeTok{size =} \DecValTok{10}\NormalTok{, }\DataTypeTok{replace =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "a" "c" "a" "c" "a" "c" "c" "a" "a" "c"
\end{verbatim}

You can set probabilities on the sampling of different elements\footnote{If \texttt{prob} doesn't sum to 1, then it will be rescaled: \texttt{prob\ =\ prob/sum(prob)}}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sample}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"live"}\NormalTok{, }\StringTok{"die"}\NormalTok{), }\DataTypeTok{size =} \DecValTok{10}\NormalTok{, }\DataTypeTok{replace =}\NormalTok{ T,}
       \DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.8}\NormalTok{, }\FloatTok{0.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "live" "live" "live" "die"  "live" "live" "live" "live" "live" "die"
\end{verbatim}

Notice that this is the same as the binomial random process above, but with only 10 trials and the printing of the outcomes rather than the number of successes.

\hypertarget{reproducing-randomness}{%
\section{Reproducing Randomness}\label{reproducing-randomness}}

For reproducibility purposes, you may wish to get the same exact random numbers each time you run your script. To do this, you need to set the \textbf{random seed}, which is the starting point of the random number generator your computer uses. If you run these two lines of code, you should get the same result as printed here:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -1.207066
\end{verbatim}

\hypertarget{replication}{%
\section{Replication}\label{replication}}

To use Monte Carlo methods, you need to be able to replicate some random process many times. There are two main ways this is commonly done: either with\texttt{replicate()} or with \texttt{for()} loops.

\hypertarget{replicate}{%
\subsection{\texorpdfstring{\texttt{replicate()}}{replicate()}}\label{replicate}}

The \texttt{replicate()} function executes some expression many times and returns the output from each execution. Say we have a vector \texttt{x}, which represents 30 observations of fish length (mm):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We wish to build the sampling distribution of the mean length ``by hand''. We can sample randomly from it, calculate the mean, then repeat this process many times:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{means =}\StringTok{ }\KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =} \DecValTok{1000}\NormalTok{, }\DataTypeTok{expr =}\NormalTok{ \{}
\NormalTok{  x_i =}\StringTok{ }\KeywordTok{sample}\NormalTok{(x, }\KeywordTok{length}\NormalTok{(x), }\DataTypeTok{replace =}\NormalTok{ T)}
  \KeywordTok{mean}\NormalTok{(x_i)}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

If we take \texttt{mean(means)} and \texttt{sd(means)}, that should be very similar to \texttt{mean(x)} and \texttt{se(x)}. Create the \texttt{se()} function (also shown in Section \ref{error-bars}) and prove this to yourself:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sd}\NormalTok{(x)}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{length}\NormalTok{(x))}
\KeywordTok{mean}\NormalTok{(means); }\KeywordTok{mean}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 493.4968
\end{verbatim}

\begin{verbatim}
## [1] 493.4166
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sd}\NormalTok{(means); }\KeywordTok{se}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.967572
\end{verbatim}

\begin{verbatim}
## [1] 5.044153
\end{verbatim}

\hypertarget{for-loops}{%
\subsection{\texorpdfstring{The \texttt{for()} loop}{The for() loop}}\label{for-loops}}

In programming, a \emph{loop} is a command that does something over and over until it reaches some point that you specify. R has a few types of loops: \texttt{repeat()}, \texttt{while()}, and \texttt{for()}, to name a few. \texttt{for()} loops are among the most common in simulation modeling. A \texttt{for()} loop repeats some action for however many times you tell it \textbf{for} each value in some vector. The syntax is:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (var }\ControlFlowTok{in}\NormalTok{ seq) \{}
  \KeywordTok{expression}\NormalTok{(var)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The loop calculates the expression for values of \texttt{var} for each element in the vector \texttt{seq}. For example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{) \{}
  \KeywordTok{print}\NormalTok{(i}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
## [1] 4
## [1] 9
## [1] 16
## [1] 25
\end{verbatim}

The \texttt{print()} command will be executed 5 times: once for each value of \texttt{i}. It is the same as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{i =}\StringTok{ }\DecValTok{1}\NormalTok{; }\KeywordTok{print}\NormalTok{(i}\OperatorTok{^}\DecValTok{2}\NormalTok{); i =}\StringTok{ }\DecValTok{2}\NormalTok{; }\KeywordTok{print}\NormalTok{(i}\OperatorTok{^}\DecValTok{2}\NormalTok{); i =}\StringTok{ }\DecValTok{3}\NormalTok{; }\KeywordTok{print}\NormalTok{(i}\OperatorTok{^}\DecValTok{2}\NormalTok{); i =}\StringTok{ }\DecValTok{4}\NormalTok{; }\KeywordTok{print}\NormalTok{(i}\OperatorTok{^}\DecValTok{2}\NormalTok{); i =}\StringTok{ }\DecValTok{5}\NormalTok{; }\KeywordTok{print}\NormalTok{(i}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you remove the \texttt{print()} function, see what happens:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{) \{}
\NormalTok{  i}\OperatorTok{^}\DecValTok{2}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Nothing is printed to the console. R did the calculation, but did not show you or store the result. Often, you'll need to store the results of the calculation in a \textbf{container object}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results =}\StringTok{ }\KeywordTok{numeric}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This makes an empty numeric vector of length 5 that are all 0's. You can store the output of your loop calculations in \texttt{results}:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{) \{}
\NormalTok{  results[i] =}\StringTok{ }\NormalTok{i}\OperatorTok{^}\DecValTok{2}
\NormalTok{\}}
\NormalTok{results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1  4  9 16 25
\end{verbatim}

When \texttt{i\^{}2} is calculated, it will be placed in the element \texttt{results{[}i{]}}. This was a trivial example, because you would never use a \texttt{for()} loop to do things as simple as vectorized calculation. The expression \texttt{(1:5)\^{}2} would give the same result with significantly less code (see Section \ref{vector-math}).

However, there are times where it is advantageous to use a loop. Particularly in cases where:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the calculations in one element are determined from the value in previous elements, such as in time series models
\item
  the calculations have multiple steps
\item
  you wish to store multiple results
\item
  you wish to track the progress of your calculations
\end{enumerate}

As an illustration for item (1) above, build a (very) basic population model. At the start of the first year, the population abundance is 1000 individuals and grows by an average factor of 1.1 per year (reproduction and death processes result in a growth rate of 10\%) before harvest. The growth rate varies randomly, however. Each year, the 1.1 growth factor has variability introduced by small changes in survival and reproductive process. Model these variations as lognormal random variables. After production, 8\% of the population is harvested. Simulate the abundance at the end of the year for 100 years:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nt =}\StringTok{ }\DecValTok{100}       \CommentTok{# number of years}
\NormalTok{N =}\StringTok{ }\OtherTok{NULL}       \CommentTok{# container for abundance}
\NormalTok{N[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\DecValTok{1000}    \CommentTok{# first end-of-year abundance}

\ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{nt) \{}
  \CommentTok{# N this year is N last year * growth *}
    \CommentTok{# randomness * fraction that survive harvest}
\NormalTok{  N[t] =}\StringTok{ }\NormalTok{(N[t}\DecValTok{-1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\FloatTok{1.1} \OperatorTok{*}\StringTok{ }\KeywordTok{rlnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.1}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\FloatTok{0.08}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Plot the abundance time series:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(N, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{15}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Year"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Abundance"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-23-1} \end{center}

Examples of the other three utilities of using \texttt{for()} loops over replicate are shown in the example cases and exercises.

\hypertarget{adv-funcs}{%
\section{Function Writing}\label{adv-funcs}}

In Monte Carlo analyses, it is often useful to wrap code into functions. This allows for easy replication and setting adjustment (e.g., if you wanted to compare the growth trajectories of two populations with differing growth rates). As an example, turn the population model shown above into a function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pop_sim =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(nt, grow, sd_grow, U, }\DataTypeTok{plot =}\NormalTok{ F) \{}
\NormalTok{  N =}\StringTok{ }\OtherTok{NULL} \CommentTok{# empty flexible vector container}
\NormalTok{  N[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\DecValTok{1000}
  \ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{nt) \{}
\NormalTok{    N[t] =}\StringTok{ }\NormalTok{(N[t}\DecValTok{-1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{grow }\OperatorTok{*}\StringTok{ }\KeywordTok{rlnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, sd_grow)) }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{U)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (plot) \{}
    \KeywordTok{plot}\NormalTok{(N, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{15}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Year"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Abundance"}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  N}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This function takes five inputs:

\begin{itemize}
\tightlist
\item
  \texttt{nt}: the number of years,
\item
  \texttt{grow}: the population growth rate,
\item
  \texttt{sd\_grow}: the amount of annual variability in the growth rate
\item
  \texttt{U}: the annual exploitation rate
\item
  \texttt{plot}: whether you wish to have a plot created. It has a default setting of \texttt{FALSE}: if you don't specify \texttt{plot\ =\ T} when you call \texttt{pop\_sim()}, you won't see a plot made.
\end{itemize}

It returns one output: the vector of population abundance.

Execute your simulation function once using the same settings as before:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pop_sim}\NormalTok{(}\DecValTok{100}\NormalTok{, }\FloatTok{1.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.08}\NormalTok{, T)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-25-1} \end{center}

Now, you wish to replicate this simulation 1000 times. Use the \texttt{replicate()} function to do this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out =}\StringTok{ }\KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =} \DecValTok{1000}\NormalTok{, }\DataTypeTok{expr =} \KeywordTok{pop_sim}\NormalTok{(}\DecValTok{100}\NormalTok{, }\FloatTok{1.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.08}\NormalTok{, F))}
\end{Highlighting}
\end{Shaded}

If you do \texttt{dim(out)}, you'll see that years are stored as rows (there are 100 of them) and replicates are stored as columns (there are 1000 of them). Notice how wrapping the code in the function made the \texttt{replicate()} call easy.

\textbf{Here are some advantages of wrapping code like this into a function}:

\begin{itemize}
\tightlist
\item
  If you do the same task at multiple places in your script, you don't need to type all of the code to perform the task, just the function call.
\item
  If you need to change the way the function behaves (i.e., the function body), you only need to change it in one place: in the function definition.
\item
  You can easily change the settings of the code (e.g., whether or not you want to see the plot) in one place
\item
  Function writing can lead to shorter scripts
\item
  Function writing can lead to more readable code (if it is easy for readers to interpret what your functions do - informative function and argument names, as well as documentation can help here)
\end{itemize}

\hypertarget{mc-summaries}{%
\section{Summarization}\label{mc-summaries}}

After replicating a calculation many times, you will need to summarize the results. Here are several examples using the \texttt{out} matrix from Section \ref{adv-funcs}.

\hypertarget{central-tendency}{%
\subsection{Central Tendency}\label{central-tendency}}

You can calculate the mean abundance each year across your iterations using the \texttt{apply()} function (Section \ref{data-summaries}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N_mean =}\StringTok{ }\KeywordTok{apply}\NormalTok{(out, }\DecValTok{1}\NormalTok{, mean)}
\NormalTok{N_mean[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1000.000 1017.150 1034.970 1052.022 1068.358 1086.700 1102.685
##  [8] 1125.383 1141.774 1159.921
\end{verbatim}

You could do the same thing using \texttt{median} rather than \texttt{mean}. The mode is more difficult to calculate in R, if you need to get the mode, try to Google it\footnote{Google is an R programmer's best friend. There is a massive online community for R, and if you have a question on something, it has almost certainly been asked somewhere on the web.}.

\hypertarget{variability}{%
\subsection{Variability}\label{variability}}

One of the primary reasons to conduct a Monte Carlo analysis is to obtain estimates of variability. You can summarize the variability easily using the \texttt{quantile()} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# obtain the 10% and 90% quantiles each year across iterations}
\NormalTok{N_quants =}\StringTok{ }\KeywordTok{apply}\NormalTok{(out, }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{quantile}\NormalTok{(x, }\KeywordTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.9}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

Notice how a user-defined function was passed to \texttt{apply()}. Now plot the summary of the randomized abundances as a time series like before:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(N_mean, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10000}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(N_quants[}\DecValTok{1}\NormalTok{,], }\DataTypeTok{lty =} \DecValTok{2}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(N_quants[}\DecValTok{2}\NormalTok{,], }\DataTypeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-30-1} \end{center}

The range within the two dashed lines represents the range that encompassed the central 80\% of the random abundances each year.

\hypertarget{frequencies}{%
\subsection{Frequencies}\label{frequencies}}

Often you will want to count how many times something happened. In some cases, the fraction of times something happened can be interpreted as a probability of that event occuring.

The \texttt{table()} function is useful for counting occurrences of discrete events. Suppose you are interested in how many of your iterations resulted in fewer than 1000 individuals at year 10:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out10 =}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(out[}\DecValTok{10}\NormalTok{,] }\OperatorTok{<}\StringTok{ }\DecValTok{1000}\NormalTok{, }\StringTok{"less10"}\NormalTok{, }\StringTok{"greater10"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(out10)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## out10
## greater10    less10 
##       649       351
\end{verbatim}

Suppose you are also interested in how many of your iterations resulted in fewer than 1100 individuals at year 20:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out20 =}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(out[}\DecValTok{20}\NormalTok{,] }\OperatorTok{<}\StringTok{ }\DecValTok{1100}\NormalTok{, }\StringTok{"less20"}\NormalTok{, }\StringTok{"greater20"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(out20)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## out20
## greater20    less20 
##       587       413
\end{verbatim}

Now suppose you are interested in how these two metrics are related:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(out10, out20)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            out20
## out10       greater20 less20
##   greater10       486    163
##   less10          101    250
\end{verbatim}

One example of an interpretation of this output might be that populations that were greater than 1000 at year 10 were commonly greater than 1100 at year 20. Also, if a population was less than 1000 at year 10, it was more likely to be less than 1100 at year 20 than to be greater than it.

You can turn these into probabilities (if you believe your model represents reality) by dividing each cell by the total number of iterations:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\KeywordTok{table}\NormalTok{(out10, out20)}\OperatorTok{/}\DecValTok{1000}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            out20
## out10       greater20 less20
##   greater10      0.49   0.16
##   less10         0.10   0.25
\end{verbatim}

\hypertarget{sim-examples}{%
\section{Simulation-Based Examples}\label{sim-examples}}

\hypertarget{rnorm-ex}{%
\subsection{\texorpdfstring{Test \texttt{rnorm}}{Test rnorm}}\label{rnorm-ex}}

In this example, you will verify that the function \texttt{rnorm()} works the same way that \texttt{qnorm()} and \texttt{pnorm()} indicate that it should work. That is, you will verify that random deviates generated using \texttt{rnorm()} have the same properties as the true normal distribution given by \texttt{qnorm()} and \texttt{pnorm()}. Hopefully it will also reinforce the way the random, quantile, and cumulative distribution functions work in R.

First, specify the mean and standard deviation for this example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu =}\StringTok{ }\DecValTok{500}\NormalTok{; sig =}\StringTok{ }\DecValTok{30}
\end{Highlighting}
\end{Shaded}

Now make up \texttt{n} (any number of your choosing, something greater than 10) random deviates from this normal distribution:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{random =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, mu, sig)}
\end{Highlighting}
\end{Shaded}

Test the quantiles (obtain the values that \texttt{p} * 100\% of the quantities fall below, both for random numbers and from the \texttt{qnorm()} function):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.99}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\NormalTok{random_q =}\StringTok{ }\KeywordTok{quantile}\NormalTok{(random, p)}
\NormalTok{normal_q =}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(p, mu, sig)}
\KeywordTok{plot}\NormalTok{(normal_q }\OperatorTok{~}\StringTok{ }\NormalTok{random_q); }\KeywordTok{abline}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-38-1} \end{center}

The fact that all the quantiles fall around the 1:1 line suggests the \texttt{n} random samples are indeed from a normal distribution. Any deviations you see are due to sampling errors. If you increase \texttt{n} to \texttt{n\ =\ 1e6} (one million), you'll see no deviations. This is called a \textbf{q-q plot}, and is frequently used to assess the fit of data to a distribution.

Now test the random values in their agreement with the \texttt{pnorm()} function. Plot the cumulative density functions for the truly normal curve and the one approximated by the random deviates:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{400}\NormalTok{, }\DecValTok{600}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{random_cdf =}\StringTok{ }\KeywordTok{ecdf}\NormalTok{(random)}
\NormalTok{random_p =}\StringTok{ }\KeywordTok{random_cdf}\NormalTok{(q)}
\NormalTok{normal_p =}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(q, mu, sig)}
\KeywordTok{plot}\NormalTok{(normal_p }\OperatorTok{~}\StringTok{ }\NormalTok{q, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{)}
\KeywordTok{points}\NormalTok{(random_p }\OperatorTok{~}\StringTok{ }\NormalTok{q, }\DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-40-1} \end{center}

The \texttt{ecdf()} function obtains the empirical cumulative density function (which is just \texttt{pnorm()} for a sample). It allows you to plug in any random variable and obtain the probability of having one less than it.

\hypertarget{power-ex}{%
\subsection{Stochastic Power Analysis}\label{power-ex}}

A \textbf{power analysis} is one where the analyst wishes to determine how much power they will have to detect an effect. Power is inversely related to the probability of making a Type II Error: failing to reject a false null hypothesis\footnote{English: concluding there is no effect when there truly is one}. In other words, having high power means that you have a high chance of detecting an effect if an effect truly exists. Power is a function of the effect size, the sample size \texttt{n}, and the variability in the data. Strong effects are easier to detect than weak ones, more samples increase the test's sensitivity (the ability to detect weak effects), and lower variability results in more power.

You can conduct a power analysis using stochastic simulation (i.e., a Monte Carlo analysis). Here, you will write a power analysis to determine how likely are you to be able to correctly identify what you deem to be a biologically-meaningful difference in survival between two tagging procedures.

You know one tagging procedure has approximately a 10\% mortality rate (10\% of tagged fish die within the first 12 hours as result of the tagging process). Another cheaper, and less labor-intensive method has been proposed, but before implementing it, your agency wishes to determine if it will have a meaningful impact on the reliability of the study or on the ability of the crew to tag enough individuals that will survive long enough to be useful. You and your colleagues determine that if the mortality rate of the new tagging method reaches 25\%, then gains in time and cost-efficiency would be offset by needing to tag more fish (because more will die). You have decided to perform a small-scale study to determine if using the new method could result in 25\% or more mortality. The study will tag \texttt{n} individuals using both methods (new and old) and track the fraction that survived after 12 hours. Before performing the study however, you deem it important to determine how large \texttt{n} needs to be to answer this question. You decide to use a stochastic power analysis to help your research group. The small-scale study can tag a total of at most 100 fish with the currently available resources. Could you tag fewer than 100 total individuals and still have a high probability of detecting a statistically significant difference in mortality?

The stochastic power analysis approach works like this (this is called \textbf{psuedocode}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate data under the reality that the difference is real with \texttt{n} observations per treatment, where \texttt{n\ \textless{}\ 100/2}
\item
  Fit the model that will be used when the real data are collected to the simulated data
\item
  Determine if the difference was detected with a significant p-value
\item
  Replicate steps 1 - 3 many times
\item
  Replicate step 4 while varying \texttt{n} over the interval from 10 to 50
\item
  Determine what fraction of the p-values were deemed significant at each \texttt{n}
\end{enumerate}

Step 2 will require fitting a generalized linear model; for a review, revisit Section \ref{glms} (specifically Section \ref{logis-regression} on logistic regression).

First, create a function that will generate data, fit the model, and determine if the p-value is significant (steps 1-3 above):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim_fit =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, }\DataTypeTok{p_old =} \FloatTok{0.10}\NormalTok{, }\DataTypeTok{p_new =} \FloatTok{0.25}\NormalTok{) \{}
  
  \CommentTok{### step 1: create the data }\AlertTok{###}
  \CommentTok{# generate random response data}
\NormalTok{  dead_old =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_old)}
\NormalTok{  dead_new =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_new)}
  \CommentTok{# create the predictor variable}
\NormalTok{  method =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"old"}\NormalTok{, }\StringTok{"new"}\NormalTok{), }\DataTypeTok{each =}\NormalTok{ n)}
  \CommentTok{# create a data.frame to pass to glm}
\NormalTok{  df =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{dead =} \KeywordTok{c}\NormalTok{(dead_old, dead_new), }\DataTypeTok{method =}\NormalTok{ method)}
  \CommentTok{# relevel so old is the reference}
\NormalTok{  df}\OperatorTok{$}\NormalTok{method =}\StringTok{ }\KeywordTok{relevel}\NormalTok{(df}\OperatorTok{$}\NormalTok{method, }\DataTypeTok{ref =} \StringTok{"old"}\NormalTok{)}
  
  \CommentTok{### step 2: fit the model }\AlertTok{###}
\NormalTok{  fit =}\StringTok{ }\KeywordTok{glm}\NormalTok{(dead }\OperatorTok{~}\StringTok{ }\NormalTok{method, }\DataTypeTok{data =}\NormalTok{ df, }\DataTypeTok{family =}\NormalTok{ binomial)}
  
  \CommentTok{### step 3: determine if a sig. p-value was found }\AlertTok{###}
  \CommentTok{# extract the p-value}
\NormalTok{  pval =}\StringTok{ }\KeywordTok{summary}\NormalTok{(fit)}\OperatorTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{]}
  \CommentTok{# determine if it was found to be significant}
\NormalTok{  pval }\OperatorTok{<}\StringTok{ }\FloatTok{0.05}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Next, for steps 4 and 5, set up a \textbf{nested \texttt{for} loop}. This will have two loops: one that loops over sample sizes (step 5) and one that loops over replicates of each sample size (step 4). First, create the looping objects and containers:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{I =}\StringTok{ }\DecValTok{500}  \CommentTok{# the number of replicates at each sample size}
\NormalTok{n_try =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{10}\NormalTok{)  }\CommentTok{# the test sample sizes}
\NormalTok{N =}\StringTok{ }\KeywordTok{length}\NormalTok{(n_try)        }\CommentTok{# count them}
\CommentTok{# container: }
\NormalTok{out =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, I, N) }\CommentTok{# matrix with I rows and N columns}
\end{Highlighting}
\end{Shaded}

Now perform the nested loop. The inner-loop iterations will be completed for each element of \texttt{n} in the sequence \texttt{1:N}. The output (which is one element: \texttt{TRUE} or \texttt{FALSE} based on the significance of the p-value) is stored in the corresponding row and column for that iteration of that sample size.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{I) \{}
\NormalTok{    out[i,n] =}\StringTok{ }\KeywordTok{sim_fit}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ n_try[n])}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

You now have a matrix of \texttt{TRUE} and \texttt{FALSE} elements that indicates whether a significant difference was found at the \(\alpha = 0.05\) level if the effect was truly as large as you care about. You can obtain the proportion of all the replicates at each sample size that resulted in a significant difference using the \texttt{mean()} function with \texttt{apply()}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{apply}\NormalTok{(out, }\DecValTok{2}\NormalTok{, mean) }\OperatorTok{~}\StringTok{ }\NormalTok{n_try, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Tagged Fish per Treatment"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of Finding Effect (Power)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-46-1} \end{center}

Even if you tagged 100 fish total, you would only have a 49\% chance of saying the effect (which truly is there!) is present under the null hypothesis testing framework.

Suppose you and your colleagues aren't relying on p-values in this case, and are purely interested in how precisely the \textbf{effect size} would be estimated. Adapt your function to determine how frequently you would be able to estimate the true mortality of the new method within +/- 5\% based on the point estimate only (the estimate for the tagging mortality of the new method must be between 0.2 and 0.3 for a successful study). Change your function to calculate this additional metric and re-run the analysis:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim_fit =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, }\DataTypeTok{p_old =} \FloatTok{0.10}\NormalTok{, }\DataTypeTok{p_new =} \FloatTok{0.25}\NormalTok{) \{}
  \CommentTok{# create the data}
\NormalTok{  dead_old =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_old)}
\NormalTok{  dead_new =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_new)}
  \CommentTok{# create the predictor variable}
\NormalTok{  method =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"old"}\NormalTok{, }\StringTok{"new"}\NormalTok{), }\DataTypeTok{each =}\NormalTok{ n)}
  \CommentTok{# create a data.frame to pass to glm}
\NormalTok{  df =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{dead =} \KeywordTok{c}\NormalTok{(dead_old, dead_new), }\DataTypeTok{method =}\NormalTok{ method)}
  \CommentTok{# relevel so old is the reference}
\NormalTok{  df}\OperatorTok{$}\NormalTok{method =}\StringTok{ }\KeywordTok{relevel}\NormalTok{(df}\OperatorTok{$}\NormalTok{method, }\DataTypeTok{ref =} \StringTok{"old"}\NormalTok{)}
  \CommentTok{# fit the model}
\NormalTok{  fit =}\StringTok{ }\KeywordTok{glm}\NormalTok{(dead }\OperatorTok{~}\StringTok{ }\NormalTok{method, }\DataTypeTok{data =}\NormalTok{ df, }\DataTypeTok{family =}\NormalTok{ binomial)}
  \CommentTok{# extract the p-value}
\NormalTok{  pval =}\StringTok{ }\KeywordTok{summary}\NormalTok{(fit)}\OperatorTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{]}
  \CommentTok{# determine if it was found to be significant}
\NormalTok{  sig_pval =}\StringTok{ }\NormalTok{pval }\OperatorTok{<}\StringTok{ }\FloatTok{0.05}
  \CommentTok{# obtain the estimated mortality rate for the new method}
\NormalTok{  p_new_est =}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit, }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{method =} \KeywordTok{c}\NormalTok{(}\StringTok{"new"}\NormalTok{)),}
                      \DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}
  
  \CommentTok{# determine if it is +/- 5% from the true value}
\NormalTok{  prc_est =}\StringTok{ }\NormalTok{p_new_est }\OperatorTok{>=}\StringTok{ }\NormalTok{(p_new }\OperatorTok{-}\StringTok{ }\FloatTok{0.05}\NormalTok{) }\OperatorTok{&}\StringTok{ }\NormalTok{p_new_est }\OperatorTok{<=}\StringTok{ }\NormalTok{(p_new }\OperatorTok{+}\StringTok{ }\FloatTok{0.05}\NormalTok{)}
  \CommentTok{# return a vector with these two elements}
  \KeywordTok{c}\NormalTok{(}\DataTypeTok{sig_pval =}\NormalTok{ sig_pval, }\DataTypeTok{prc_est =} \KeywordTok{unname}\NormalTok{(prc_est))}
\NormalTok{\}}

\CommentTok{# containers: }
\NormalTok{out_sig =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, I, N) }\CommentTok{# matrix with I rows and N columns}
\NormalTok{out_prc =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, I, N) }\CommentTok{# matrix with I rows and N columns}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{I) \{}
\NormalTok{    tmp =}\StringTok{ }\KeywordTok{sim_fit}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ n_try[n])     }\CommentTok{# run sim}
\NormalTok{    out_sig[i,n] =}\StringTok{ }\NormalTok{tmp[}\StringTok{"sig_pval"}\NormalTok{]  }\CommentTok{# extract and store significance metric}
\NormalTok{    out_prc[i,n] =}\StringTok{ }\NormalTok{tmp[}\StringTok{"prc_est"}\NormalTok{]   }\CommentTok{# extract and store precision metric}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{apply}\NormalTok{(out_sig, }\DecValTok{2}\NormalTok{, mean) }\OperatorTok{~}\StringTok{ }\NormalTok{n_try, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Tagged Fish per Treatment"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of Finding Effect (Power)"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{apply}\NormalTok{(out_prc, }\DecValTok{2}\NormalTok{, mean) }\OperatorTok{~}\StringTok{ }\NormalTok{n_try, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Tagged Fish per Treatment"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of a Precise Estimate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-47-1} \end{center}

It seems that even if you tagged 50 fish per treatment, you would have a 60\% chance of estimating that the mortality rate is between 0.2 and 0.3 if it was truly 0.25.

You and your colleagues consider these results and determine that you will need to somehow acquire more funds to tag more fish in the small-scale study in order to have a high level of confidence in the results.

\hypertarget{harv-ex}{%
\subsection{Harvest Policy Analysis}\label{harv-ex}}

In this example, you will simulate population dynamics under a more realistic model than in Sections \ref{for-loops} and \ref{adv-funcs} for the purpose of evaluating different harvest policies.

Suppose you are a fisheries research biologist, and a commercial fishery for pink salmon (\emph{Oncorhynchus gorbuscha}) takes place in your district. For the past 10 years, it has been fished with an exploitation rate of 40\% (40\% of the fish that return each year have been harvested, exploitation rate is abbreviated by \(U\)), resulting in an average annual harvest of 8.5 million fish. The management plan is up for evaluation this year, and your supervisor has asked you to prepare an analysis that determines if more harvest could be sustained if a different exploitation rate were to be used in the future.

Based on historical data, your best understanding implies that the stock is driven by Ricker spawner-recruit dynamics. That is, the total number of fish that return this year (recruits) is a function of the total number of fish that spawned (spawners) in the year of their birth. The Ricker model can be written this way:

\begin{equation}
  R_t = \alpha S_{t-1} e^{-\beta S_{t-1} + \varepsilon_t} ,\varepsilon_t \sim N(0,\sigma)
\label{eq:ricker-ch4}
\end{equation}

where \(\alpha\) is a parameter representing the maximum recruits per spawner (obtained at very low spawner abundances) and \(\beta\) is a measure of the strength of density-dependent mortality. Notice that the error term is in the exponent, which makes \(e^{\varepsilon_t}\) lognormal.

You have estimates of the parameters\footnote{In reality, these estimates would have substantial uncertainty that you would need to propagate through your harvest policy analysis. In this example, you will ignore this complication}:

\begin{itemize}
\tightlist
\item
  \(\alpha = 6\)
\item
  \(\beta = 1 \times 10^{-7}\)
\item
  \(\sigma = 0.4\)
\end{itemize}

You decide that you can build a policy analysis by simulating the stock forward through time under different exploitation rates. With enough iterations of the simulation, you will be able to see whether a different exploitation rate can provide more harvest than what is currently being extracted.

First, write a function for your population model. Your function must:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  take the parameters, dimensions (number of years), and the policy variable (\(U\)) as input arguments
\item
  simulate the population using Ricker dynamics
\item
  calculate and return the average harvest and escapement over the number of future years you simulated.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Step #1: name the function and give it some arguments}
\NormalTok{ricker_sim =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(ny, params, U) \{}
  \CommentTok{# extract the parameters out by name:}
\NormalTok{  alpha =}\StringTok{ }\NormalTok{params[}\StringTok{"alpha"}\NormalTok{]}
\NormalTok{  beta =}\StringTok{ }\NormalTok{params[}\StringTok{"beta"}\NormalTok{]}
\NormalTok{  sigma =}\StringTok{ }\NormalTok{params[}\StringTok{"sigma"}\NormalTok{]}
  \CommentTok{# create containers}
       \CommentTok{# this is a neat trick to condense your code:}
\NormalTok{  R =}\StringTok{ }\NormalTok{S =}\StringTok{ }\NormalTok{H =}\StringTok{ }\OtherTok{NULL}
  \CommentTok{# initialize the population in the first year}
    \CommentTok{# start the population at being fished at 40%}
    \CommentTok{# with lognormal error}
\NormalTok{  R[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\KeywordTok{log}\NormalTok{(alpha }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\FloatTok{0.4}\NormalTok{))}\OperatorTok{/}\NormalTok{(beta }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\FloatTok{0.4}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, sigma))}
\NormalTok{  S[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\NormalTok{R[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{U)}
\NormalTok{  H[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\NormalTok{R[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{U}
  
  \CommentTok{# carry simulation forward through time}
  \ControlFlowTok{for}\NormalTok{ (y }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{ny) \{}
    \CommentTok{# use the ricker function with random lognormal noise}
\NormalTok{    R[y] =}\StringTok{ }\NormalTok{S[y}\DecValTok{-1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{alpha }\OperatorTok{*}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{beta }\OperatorTok{*}\StringTok{ }\NormalTok{S[y}\DecValTok{-1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, sigma))}
    \CommentTok{#harvest and spawners are the same as before}
\NormalTok{    S[y] =}\StringTok{ }\NormalTok{R[y] }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{U)}
\NormalTok{    H[y] =}\StringTok{ }\NormalTok{R[y] }\OperatorTok{*}\StringTok{ }\NormalTok{U}
\NormalTok{  \}}
  \CommentTok{# wrap output in a list object}
  \KeywordTok{list}\NormalTok{(}
    \DataTypeTok{mean_H =} \KeywordTok{mean}\NormalTok{(H),}
    \DataTypeTok{mean_S =} \KeywordTok{mean}\NormalTok{(S)}
\NormalTok{    )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Use the function once:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{params =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DataTypeTok{alpha =} \DecValTok{6}\NormalTok{, }\DataTypeTok{beta =} \FloatTok{1e-7}\NormalTok{, }\DataTypeTok{sigma =} \FloatTok{0.4}\NormalTok{)}
\NormalTok{out =}\StringTok{ }\KeywordTok{ricker_sim}\NormalTok{(}\DataTypeTok{U =} \FloatTok{0.4}\NormalTok{, }\DataTypeTok{ny =} \DecValTok{20}\NormalTok{, }\DataTypeTok{params =}\NormalTok{ params)}
\CommentTok{#average annual harvest (in millions)}
\KeywordTok{round}\NormalTok{(out}\OperatorTok{$}\NormalTok{mean_H}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7.99
\end{verbatim}

If you completed the stochastic power analysis example (Section \ref{power-ex}), you might see where this is going. You are going to replicate applying a fixed policy many times to a random system. This is the Monte Carlo part of the analysis. The policy part is that you will compare the output from several candidate exploitation rates to inform a decision about which is best. This time, set up your analysis using \texttt{sapply()} (to iterate over different values of \(U\)) and \texttt{replicate()} (to iterate over different random populations fished at each \(U\)) instead of performing a nested \texttt{for()} loop as in previous examples:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U_try =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\NormalTok{n_rep =}\StringTok{ }\DecValTok{2000}
\NormalTok{H_out =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(U_try, }\ControlFlowTok{function}\NormalTok{(u) \{}
  \KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ n_rep, }\DataTypeTok{expr =}\NormalTok{ \{}
    \KeywordTok{ricker_sim}\NormalTok{(}\DataTypeTok{U =}\NormalTok{ u, }\DataTypeTok{ny =} \DecValTok{20}\NormalTok{, }\DataTypeTok{params =}\NormalTok{ params)}\OperatorTok{$}\NormalTok{mean_H}\OperatorTok{/}\FloatTok{1e6}
\NormalTok{  \})}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

The nested \texttt{replicate()} and \texttt{sapply()} method is a bit cleaner than a nested \texttt{for()} loop, but you have less control over the format of the output.

Plot the output of your simulations using a boxplot. To make things easier, give \texttt{H\_out} column names representing the exploitation rate:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colnames}\NormalTok{(H_out) =}\StringTok{ }\NormalTok{U_try}
\KeywordTok{boxplot}\NormalTok{(H_out, }\DataTypeTok{outline =}\NormalTok{ F,}
        \DataTypeTok{xlab =} \StringTok{"U"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Harvest (Millions of Fish)"}\NormalTok{,}
        \DataTypeTok{col =} \StringTok{"tomato"}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-53-1} \end{center}

It appears the stock could produce more harvest than its current 8.5 million fish per year if it was fished harder. However, your supervisors also do not want to see the escapement drop below three-quarters of what it has been in recent history (75\% of approximately 13 million fish). They ask you to obtain the expected average annual escapement as well as harvest. You can simply re-run the code above, but extracting \texttt{S\_mean} rather than \texttt{H\_mean}. Call this output \texttt{S\_out} and plot it just like harvest (if you're curious, this blue color is \texttt{col\ =\ "skyblue"}):

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-54-1} \end{center}

After seeing this information, your supervisor realizes they are faced with a trade-off: the stock could produce more with high exploitation rates, but they are concerned about pushing the stock too low would be unsustainable. They tell you to determine the probability that the average escapement would not be pushed below 75\% of 13 million at each exploitation rate, as well as the probability that the average annual harvests will be at least 20\% greater than they are currently (approximately 8.5 million fish). Given your output, this is easy:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# determine if each element meets escapement criterion}
\NormalTok{Smeet =}\StringTok{ }\NormalTok{S_out }\OperatorTok{>}\StringTok{ }\NormalTok{(}\FloatTok{0.75} \OperatorTok{*}\StringTok{ }\DecValTok{13}\NormalTok{)}
\CommentTok{# determine if each element meets harvest criterion}
\NormalTok{Hmeet =}\StringTok{ }\NormalTok{H_out }\OperatorTok{>}\StringTok{ }\NormalTok{(}\FloatTok{1.2} \OperatorTok{*}\StringTok{ }\FloatTok{8.5}\NormalTok{)}
\CommentTok{# calculate the probability of each occuring at a given exploitation rate}
  \CommentTok{# remember, mean of a logical vector calculate the proportion of TRUEs}
\NormalTok{p_Smeet =}\StringTok{ }\KeywordTok{apply}\NormalTok{(Smeet, }\DecValTok{2}\NormalTok{, mean)}
\NormalTok{p_Hmeet =}\StringTok{ }\KeywordTok{apply}\NormalTok{(Hmeet, }\DecValTok{2}\NormalTok{, mean)}
\end{Highlighting}
\end{Shaded}

You plot this for your supervisor as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# the U levels to highlight on plot}
\NormalTok{plot_U =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.05}\NormalTok{)}
\CommentTok{# create an empty plot}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(p_Smeet }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet, }\DataTypeTok{type =} \StringTok{"n"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Probability of Meeting Harvest Criterion"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of Meeting Escapement Criterion"}\NormalTok{)}
\CommentTok{# add gridlines}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.1}\NormalTok{), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.1}\NormalTok{), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\CommentTok{#draw on the tradeoff curve}
\KeywordTok{lines}\NormalTok{(p_Smeet }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\CommentTok{# add points and text for particular U policies}
\KeywordTok{points}\NormalTok{(p_Smeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U] }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U],}
       \DataTypeTok{pch =} \DecValTok{16}\NormalTok{, }\DataTypeTok{cex =} \FloatTok{1.5}\NormalTok{)}
\KeywordTok{text}\NormalTok{(p_Smeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U] }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U],}
     \DataTypeTok{labels =}\NormalTok{ U_try[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U], }\DataTypeTok{pos =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-56-1} \end{center}

Equipped with this analysis, your supervisor plans to go to the policy-makers with the recommendation of adjusting the exploitation rate policy to use \(U = 0.5\), because they think it balances the trade-off. Notice how if the status quo was maintained, your model suggests you would have complete certainty of staying where you are now: escapement will remain above 75\% of its current level with a 100\% chance, but you would have no chance of improving harvests to greater than 20\% of their current level. Small increases in the exploitation rate (e.g., from 0.4 to 0.45) have a reasonably large gain in harvest performance, but hardly any losses for the escapement criterion. Your supervisor is willing to live with a 90\% chance that the escapement will stay where they desire in order to gain a \textgreater80\% chance of obtaining the desired amount of increases in harvest.

The utility of using Monte Carlo methods in this example is the ability to calculate the probability of some event you are interested in. There are analytical (i.e., not simulation-based) solutions to predict the annual harvest and escapement from a fixed \(U\) from a population with parameters \(\alpha\) and \(\beta\), but by incorporating randomness, you were able to obtain the relative weights of outcomes other than the expectation under the deterministic Ricker model, thereby allowing the assignment of probabilities to meeting the two criteria.

\hypertarget{resample-examples}{%
\section{Resampling-Based Examples}\label{resample-examples}}

\hypertarget{boot-test-ex}{%
\subsection{The Bootstrap}\label{boot-test-ex}}

Say you have a fitted model from which you want to propagate the uncertainty in some derived quantity. Consider the case of the \textbf{von Bertalanffy growth model}. This is a non-linear model used to predict the size of an organism (weight or length) based on its age. The model can be written for a non-linear regression model (see Section \ref{nls}) as:

\begin{equation}
  L_i = L_{\infty}\left(1 - e^{-k(age_i-t_0)}\right) + \varepsilon_i, \varepsilon_i \sim N(0, \sigma)
\label{eq:vonB}
\end{equation}

where \(L_i\) and \(age_i\) are the observed length and age of individual \(i\), respectively, and \(L_{\infty}\), \(k\), and \(t_0\) are parameters to be estimated. The interpretations of the parameters are as follows:

\begin{itemize}
\tightlist
\item
  \(L_{\infty}\): the maximum average length achieved
\item
  \(k\): a growth coefficient linked to metabolic rate. It specifies the rate of increase in length as the fish ages early in life
\item
  \(t_0\): the theoretical age when length equals zero (the x-intercept).
\end{itemize}

Use the data set \texttt{growth.csv} for this example (see the \protect\hyperlink{data-sets}{instructions} on acquiring data files). Read in and plot the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"../Data/growth.csv"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(length }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ dat, }\DataTypeTok{pch =} \DecValTok{16}\NormalTok{, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-58-1} \end{center}

Due to a large amount of variability in individual growth rates, the relationship looks pretty noisy. Notice how you have mostly young fish in your sample: this is characteristic of ``random'' sampling of fish populations.

Suppose you would like to obtain the probability that an average-sized fish of each age is sexually mature. You know that fish of this species mature at approximately 450 mm, and you simply need to determine the fraction of all fish at each age that are greater than 450 mm. However, you don't have any observations for some ages (e.g., age 8), so you cannot simply calculate this fraction based on your raw data. You need to fit the von Bertalanffy growth model, then carry the statistical uncertainty from the fitted model forward to the predicted length-at-age. This would be difficult to obtain using only the coefficient estimates and their standard errors, because of the non-linear relationship between the \(x\) and \(y\) variables.

Enter the \textbf{bootstrap}, which is a Monte Carlo analysis using an observed data set and a model. The \textbf{pseudocode} for a bootstrap analysis is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Resample from the original data (with replacement)
\item
  Fit a model of interest
\item
  Derive some quantity of interest from the fitted model
\item
  Repeat steps 1 - 3 many times
\item
  Summarize the randomized quantities from step 4
\end{enumerate}

In this example, you will apply a bootstrap approach to obtain the distribution of expected fish lengths at each age, then use these distributions to quantify the probability that an averaged-sized fish of each age is mature (i.e., greater than 450 mm).

You will write a function for each of steps 1 - 3 above. The first is to resample the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{randomize =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(dat) \{}
  \CommentTok{# number of observed pairs}
\NormalTok{  n =}\StringTok{ }\KeywordTok{nrow}\NormalTok{(dat)}
  \CommentTok{# sample the rows to determine which will be kept}
\NormalTok{  keep =}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\NormalTok{n, }\DataTypeTok{size =}\NormalTok{ n, }\DataTypeTok{replace =}\NormalTok{ T)}
  \CommentTok{# retreive these rows from the data}
\NormalTok{  dat[keep,]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Notice the use of \texttt{replace\ =\ T} here: without this, there would be no bootstrap. You would just sample the same observations over and over, their order in the rows would just be shuffled. Next, write a function to fit the model (revisit Section \ref{nls} for more details on \texttt{nls()}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_vonB =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(dat) \{}
  \KeywordTok{nls}\NormalTok{(length }\OperatorTok{~}\StringTok{ }\NormalTok{linf }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{k }\OperatorTok{*}\StringTok{ }\NormalTok{(age }\OperatorTok{-}\StringTok{ }\NormalTok{t0))),}
      \DataTypeTok{data =}\NormalTok{ dat,}
      \DataTypeTok{start =} \KeywordTok{c}\NormalTok{(}\DataTypeTok{linf =} \DecValTok{600}\NormalTok{, }\DataTypeTok{k =} \FloatTok{0.3}\NormalTok{, }\DataTypeTok{t0 =} \FloatTok{-0.2}\NormalTok{)}
\NormalTok{      )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This function will return a fitted model object when executed. Next, write a function to predict mean length-at-age:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create a vector of ages}
\NormalTok{ages =}\StringTok{ }\KeywordTok{min}\NormalTok{(dat}\OperatorTok{$}\NormalTok{age)}\OperatorTok{:}\KeywordTok{max}\NormalTok{(dat}\OperatorTok{$}\NormalTok{age)}
\NormalTok{pred_vonB =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(fit) \{}
  \CommentTok{# extract the coefficients}
\NormalTok{  ests =}\StringTok{ }\KeywordTok{coef}\NormalTok{(fit)}
  \CommentTok{# predict length-at-age}
\NormalTok{  ests[}\StringTok{"linf"}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{ests[}\StringTok{"k"}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{(ages }\OperatorTok{-}\StringTok{ }\NormalTok{ests[}\StringTok{"t0"}\NormalTok{])))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Notice your function will use the object \texttt{ages} even though it was not defined in the function. This has to do with \textbf{lexical scoping} and \textbf{environments}, which are beyond the scope of this introductory material. If you'd like more details, see the section in \citet{adv-r-cite} on it\footnote{The section on \textbf{lexical scoping} is found here: \url{http://adv-r.had.co.nz/Functions.html\#lexical-scoping}}. Basically, if an object with the same name as one defined in the function exists outside of the function, the function will use the one that is defined within the function. If there is no object defined in the function with that name, it will look outside of the function for that object.

Now, use these three functions to perform one iteration:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pred_vonB}\NormalTok{(}\DataTypeTok{fit =} \KeywordTok{fit_vonB}\NormalTok{(}\DataTypeTok{dat =} \KeywordTok{randomize}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ dat)))}
\end{Highlighting}
\end{Shaded}

You can wrap this inside of a \texttt{replicate()} call to perform step 4 above:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\NormalTok{out =}\StringTok{ }\KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =} \DecValTok{100}\NormalTok{, }\DataTypeTok{expr =}\NormalTok{ \{}
  \KeywordTok{pred_vonB}\NormalTok{(}\DataTypeTok{fit =} \KeywordTok{fit_vonB}\NormalTok{(}\DataTypeTok{dat =} \KeywordTok{randomize}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ dat)))}
\NormalTok{\})}

\KeywordTok{dim}\NormalTok{(out)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  10 100
\end{verbatim}

It appears the rows are different ages and the columns are different bootstrapped iterations. Summarize the random lengths at each age:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summ =}\StringTok{ }\KeywordTok{apply}\NormalTok{(out, }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{c}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(x), }\KeywordTok{quantile}\NormalTok{(x, }\KeywordTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{))))}
\end{Highlighting}
\end{Shaded}

Plot the data, the summarized ranges of mean lengths, and the length at which all fish are assumed to be mature (450 mm)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(length }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ dat, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{16}\NormalTok{,}
     \DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(dat}\OperatorTok{$}\NormalTok{length, summ[}\StringTok{"97.5%"}\NormalTok{,])),}
     \DataTypeTok{ylab =} \StringTok{"Length (mm)"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Age (years)"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(summ[}\StringTok{"mean"}\NormalTok{,] }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(summ[}\StringTok{"2.5%"}\NormalTok{,] }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(summ[}\StringTok{"97.5%"}\NormalTok{,] }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{450}\NormalTok{, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-66-1} \end{center}

Obtain the fraction of iterations that resulted in the mean length-at-age being greater than 450 mm. This is interpreted as the probability that the average-sized fish of each age is mature:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p_mat =}\StringTok{ }\KeywordTok{apply}\NormalTok{(out, }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{mean}\NormalTok{(x }\OperatorTok{>}\StringTok{ }\DecValTok{450}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(p_mat }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{type =} \StringTok{"b"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{17}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Age (years)"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Probability of Average Fish Mature"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-68-1} \end{center}

This \textbf{maturity schedule} can be used by fishery managers in attempting to decide which ages should be allowed to be harvested and which should be allowed to grow more\footnote{possibly in a \textbf{yield-per-recruit} analysis}. Because each age has an associated expected length, managers can use what they know about the size selectivity of various gear types to set policies that attempt to target some ages more than others.

\hypertarget{perm-test-ex}{%
\subsection{Permutation Test}\label{perm-test-ex}}

In the previous example (Section \ref{boot-test-ex}), you learned about the bootstrap. A related Monte Carlo analysis is the \textbf{permutation test}. This is a non-parametric statistical test used to determine if there is a statistically-significant difference in the mean of some quantity between two populations. It is used in cases where the assumptions of a generalized linear model may not be met, but a p-value is still required.

The \textbf{pseudocode} for the permutation test is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculate the difference between means based on the original data set
\item
  Shuffle the group assignments randomly among the observations
\item
  Calculate the difference between the randomly-assigned groups
\item
  Repeat steps 2 - 3 many times. This builds the \textbf{null distribution}: the distribution of the test statistic (the difference) assuming the null hypothesis (that there is no difference) in means is true
\item
  Determine what fraction of the absolute differences were larger than the original difference. This constitutes a \textbf{two-tailed} p-value. One-tailed tests can also be derived using the same steps 1 - 4, which is left as an exercise.
\end{enumerate}

Use the data set \texttt{ponds.csv} for this example (see the \protect\hyperlink{data-sets}{instructions} on acquiring data files). This is the same data set used for \protect\hyperlink{ex1b}{Exercise 1B}, revisit that exercise for details on this hypothetical data set. Read in and plot the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"ponds.csv"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(chl.a }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{data =}\NormalTok{ dat)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-70-1} \end{center}

It appears as though there is a relatively strong signal indicating a difference. Use the permutation test to determine if it is statistically significant. Step 1 from the pseudocode is to calculate the observed difference between groups:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Dobs =}\StringTok{ }\KeywordTok{mean}\NormalTok{(dat}\OperatorTok{$}\NormalTok{chl.a[dat}\OperatorTok{$}\NormalTok{treatment }\OperatorTok{==}\StringTok{ "Add"}\NormalTok{]) }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(dat}\OperatorTok{$}\NormalTok{chl.a[dat}\OperatorTok{$}\NormalTok{treatment }\OperatorTok{==}\StringTok{ "Control"}\NormalTok{])}
\NormalTok{Dobs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.166
\end{verbatim}

Write a function to perform one iteration of steps 2 - 3 from the pseudocode:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# x is the group: Add or Control}
\CommentTok{# y is chl.a}
\NormalTok{perm =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y) \{}
  \CommentTok{# turn x to a character, easier to deal with}
\NormalTok{  x =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(x)}
  \CommentTok{# shuffle the x values:}
\NormalTok{  x_shuff =}\StringTok{ }\KeywordTok{sample}\NormalTok{(x)}
  \CommentTok{# calculate the mean of each group:}
\NormalTok{  x_bar_add =}\StringTok{ }\KeywordTok{mean}\NormalTok{(y[x_shuff }\OperatorTok{==}\StringTok{ "Add"}\NormalTok{])}
\NormalTok{  x_bar_ctl =}\StringTok{ }\KeywordTok{mean}\NormalTok{(y[x_shuff }\OperatorTok{==}\StringTok{ "Control"}\NormalTok{])}
  \CommentTok{# calculate the difference:}
\NormalTok{  x_bar_add }\OperatorTok{-}\StringTok{ }\NormalTok{x_bar_ctl}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Use your function once:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{perm}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{treatment, }\DataTypeTok{y =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{chl.a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10.648
\end{verbatim}

Perform step 4 from the pseudocode by replicating your \texttt{perm()} function many times:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Dnull =}\StringTok{ }\KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =} \DecValTok{5000}\NormalTok{, }\DataTypeTok{expr =} \KeywordTok{perm}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{treatment, }\DataTypeTok{y =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{chl.a))}
\end{Highlighting}
\end{Shaded}

Plot the distribution of the null test statistic and draw a line where the originally-observed difference falls:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(Dnull, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =}\NormalTok{ Dobs, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{3}\NormalTok{, }\DataTypeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-76-1} \end{center}

Notice the null distribution is centered on zero: this is because the null hypothesis is that there is no difference. The observation (blue line) falls way in the upper tail of the null distribution, indicating it is unlikely that an effect that large was observed by random chance. The two-tailed p-value can be calculated as:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\KeywordTok{abs}\NormalTok{(Dnull) }\OperatorTok{>=}\StringTok{ }\NormalTok{Dobs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

Very few (or zero) of the random data sets resulted in a difference greater than what was observed, indicating there is statistical support to the hypothesis that there is a non-zero difference between the two nutrient treatments.

\hypertarget{population-dynamics}{%
\section{Population dynamics}\label{population-dynamics}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{source}\NormalTok{(}\StringTok{"./R/Rcode/Final_report_Davidson2017.R"}\NormalTok{, }\DataTypeTok{echo =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## > library(boot)
## 
## > library(tidyverse)
## 
## > library(dplyr)
## 
## > library(ggplot2)
## 
## > library(qpcR)
## 
## > library(pwr)
## 
## > library(ggthemes)
## 
## > library(gridExtra)
## 
## > Data <- read.csv("./R/Data/RawCI.csv", header = T, 
## +     quote = "\"")
## 
## > Year <- unique(Data$Calves.1)
## 
## > year2010a <- c(3, 3, 2)
## 
## > year2010 <- filter(Data, Calves.1 < 2011)
## 
## > year2010 <- year2010$Interval.1[!is.na(year2010$Interval.1)]
## 
## > year2011a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2)
## 
## > year2011 <- filter(Data, Calves.1 < 2012)
## 
## > year2011 <- year2011$Interval.1[!is.na(year2011$Interval.1)]
## 
## > year2012a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2, 6, 4, 4, 4, 4, 4, 3, 3, 3, 3)
## 
## > year2012 <- filter(Data, Calves.1 < 2013)
## 
## > year2012 <- year2012$Interval.1[!is.na(year2012$Interval.1)]
## 
## > year2013a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2, 6, 4, 4, 4, 4, 4, 3, 3, 3, 3, 6, 5, 4, 4, 4, 4, 
## +     4, 3, 3, 3, 3, 3, 3, 3, 3, .... [TRUNCATED] 
## 
## > full <- c(Data$Interval.1, Data$Interval.2)
## 
## > year2013 <- full[!is.na(unlist(full))]
## 
## > mean2010 <- sum(year2010)/length(year2010)
## 
## > s2010 <- sd(year2010)
## 
## > SE2010 <- s2010/(sqrt(length(year2010)))
## 
## > n2010 <- (length(year2010))
## 
## > low.qt2010 <- mean2010 - (qt(0.975, length(year2010)) * 
## +     SE2010)
## 
## > high.qt2010 <- mean2010 + (qt(0.975, length(year2010)) * 
## +     SE2010)
## 
## > mean2011 <- sum(year2011)/length(year2011)
## 
## > s2011 <- sd(year2011)
## 
## > SE2011 <- s2011/(sqrt(length(year2011)))
## 
## > n2011 <- (length(year2011))
## 
## > low.qt2011 <- mean2011 - (qt(0.975, length(year2011)) * 
## +     SE2011)
## 
## > high.qt2011 <- mean2011 + (qt(0.975, length(year2011)) * 
## +     SE2011)
## 
## > mean2012 <- sum(year2012)/length(year2012)
## 
## > s2012 <- sd(year2012)
## 
## > SE2012 <- s2012/(sqrt(length(year2012)))
## 
## > n2012 <- (length(year2012))
## 
## > low.qt2012 <- mean2012 - (qt(0.975, length(year2012)) * 
## +     SE2012)
## 
## > high.qt2012 <- mean2012 + (qt(0.975, length(year2012)) * 
## +     SE2012)
## 
## > mean2013 <- sum(year2013)/length(year2013)
## 
## > s2013 <- sd(year2013)
## 
## > SE2013 <- s2013/(sqrt(length(year2013)))
## 
## > n2013 <- (length(year2013))
## 
## > low.qt2013 <- mean2013 - (qt(0.975, length(year2013)) * 
## +     SE2013)
## 
## > high.qt2013 <- mean2013 + (qt(0.975, length(year2013)) * 
## +     SE2013)
## 
## > n <- c(length(year2010), length(year2011), length(year2012), 
## +     length(year2013))
## 
## > mY <- c(mean(year2010), mean(year2011), mean(year2012), 
## +     mean(year2013))
## 
## > year <- Year
## 
## > low.qt <- c(low.qt2010, low.qt2011, low.qt2012, low.qt2013)
## 
## > high.qt <- c(high.qt2010, high.qt2011, high.qt2012, 
## +     high.qt2013)
## 
## > sd <- c(s2010, s2011, s2012, s2013)
## 
## > sum.dat <- cbind(year, n, mY, low.qt, high.qt, sd)
## 
## > sum.dat <- as.data.frame(sum.dat)
## 
## > library(knitr)
## 
## > kable(sum.dat, format = "markdown")
## 
## 
## | year|  n|       mY|   low.qt|  high.qt|        sd|
## |----:|--:|--------:|--------:|--------:|---------:|
## | 2010|  3| 2.666667| 1.605851| 3.727482| 0.5773503|
## | 2011| 15| 2.866667| 2.673022| 3.060312| 0.3518658|
## | 2012| 25| 3.240000| 2.919170| 3.560830| 0.7788881|
## | 2013| 45| 3.311111| 3.056488| 3.565734| 0.8480518|
## 
## > ggplot(sum.dat, aes(y = mY, x = year)) + geom_point() + 
## +     geom_line() + geom_errorbar(aes(ymin = low.qt, ymax = high.qt), 
## +     width = 0.1) + .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-1} \end{center}

\begin{verbatim}
## 
## > par(mfrow = c(2, 2))
## 
## > plot(factor(year2010), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "a)", sub = "Sample size 3", ylab = "Frequency", 
## +     xlab = "Calving interval", cex.main = 1.5, font.main = 4, 
## +     col.main = "bl ..." ... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2011), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "b)", sub = "Sample size 15", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2012), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "c)", sub = "Sample size 25", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2013), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-2} \end{center}

\begin{verbatim}
## 
## > title(main = "d)", sub = "Sample size 45", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > library(qpcR)
## 
## > rawdata <- qpcR:::cbind.na(year2010, year2011, year2012, 
## +     year2013)
## 
## > rawdata <- as.data.frame(rawdata)
## 
## > year2010 <- data.frame(year2010, year = c("2010"))
## 
## > year2010 <- rename(year2010, interval = year2010, 
## +     year = year)
## 
## > year2011 <- data.frame(year2011, year = c("2011"))
## 
## > year2011 <- rename(year2011, interval = year2011, 
## +     year = year)
## 
## > year2012 <- data.frame(year2012, year = c("2012"))
## 
## > year2012 <- rename(year2012, interval = year2012, 
## +     year = year)
## 
## > year2013 <- data.frame(year2013, year = c("2013"))
## 
## > year2013 <- rename(year2013, interval = year2013, 
## +     year = year)
## 
## > ggplotraw <- rbind(year2010, year2011, year2012, year2013)
## 
## > ggplotraw$interval <- as.numeric(as.character(ggplotraw$interval))
## 
## > ggplot(year2013, aes(x = interval)) + geom_bar(alpha = 1, 
## +     width = 0.9, fill = "black") + xlab(expression("Calving" ~ 
## +     "interval" ~ (ita .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-3} \end{center}

\begin{verbatim}
## 
## > RealCI <- as.numeric(year2013$interval)
## 
## > xlong <- RealCI
## 
## > meanlong <- sum(xlong)/length(xlong)
## 
## > slong <- sd(xlong)
## 
## > SElong <- slong/(sqrt(length(xlong)))
## 
## > nlong <- (length(xlong))
## 
## > lowqtlong <- meanlong - (qt(0.975, nlong) * SElong)
## 
## > highqtlong <- meanlong + (qt(0.975, nlong) * SElong)
## 
## > MedCI <- c(RealCI[RealCI < 5], 3, 3, 3, 3, 2, 3)
## 
## > xmed <- MedCI
## 
## > meanmed <- sum(xmed)/length(xmed)
## 
## > smed <- sd(xmed)
## 
## > SEmed <- smed/(sqrt(length(xmed)))
## 
## > nmed <- (length(xmed))
## 
## > lowqtmed <- meanmed - (qt(0.975, length(xmed)) * SEmed)
## 
## > highqtmed <- meanmed + (qt(0.975, length(xmed)) * 
## +     SEmed)
## 
## > LowCI <- c(RealCI[RealCI < 4], 3, 3, 3, 3, 3, 2, 2, 
## +     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)
## 
## > xshort <- LowCI
## 
## > meanshort <- mean(xshort)
## 
## > sshort <- sd(xshort)
## 
## > SEshort <- sshort/(sqrt(length(xshort)))
## 
## > lowqtshort <- meanshort - (qt(0.975, length(xshort)) * 
## +     SEshort)
## 
## > highqtshort <- meanshort + (qt(0.975, length(xshort)) * 
## +     SEshort)
## 
## > bdata <- qpcR:::cbind.na(RealCI, MedCI, LowCI)
## 
## > bdata <- as.data.frame(bdata)
## 
## > par(mfrow = c(1, 3))
## 
## > plot(factor(bdata$LowCI), main = "Lowest possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(bdata$MedCI), main = "Medium possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(bdata$RealCI), main = "Observed interval")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-4} \end{center}

\begin{verbatim}
## 
## > par(mfrow = c(3, 1))
## 
## > plot(density(as.numeric(as.character(LowCI)), bw = 0.5), 
## +     main = "Lowest possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(density(as.numeric(as.character(MedCI)), bw = 0.5), 
## +     main = "Medium possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(density(as.numeric(as.character(RealCI)), bw = 0.5), 
## +     main = "Observed interval")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-5} \end{center}

\begin{verbatim}
## 
## > Sumtable <- data.frame(variable = c("low.qt", "mean", 
## +     "high.qt", "sd", "SE"), short = c(lowqtshort, meanshort, 
## +     highqtshort, sshort, SE .... [TRUNCATED] 
## 
## > n <- c(length(LowCI), length(MedCI), length(year2013$interval))
## 
## > mY <- c(mean(LowCI), mean(MedCI), mean(year2013$interval))
## 
## > interval <- c("Low", "Medium", "Observed")
## 
## > low.qt <- c(lowqtshort, lowqtmed, low.qt2013)
## 
## > high.qt <- c(highqtshort, highqtmed, high.qt2013)
## 
## > sd <- c(sshort, smed, s2013)
## 
## > Sumtable <- cbind(interval, n, mY, low.qt, high.qt, 
## +     sd)
## 
## > Sumtable <- as.data.frame(Sumtable)
## 
## > Sumtable$n <- as.numeric(as.character(Sumtable$n))
## 
## > Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
## 
## > Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
## 
## > Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
## 
## > Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
## 
## > Sumtable$interval <- as.character(Sumtable$interval)
## 
## > ggplot(Sumtable, aes(y = mY, x = interval)) + geom_point(size = 5) + 
## +     geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05, 
## +       .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-6} \end{center}

\begin{verbatim}
## 
## > library(knitr)
## 
## > kable(Sumtable, format = "markdown", col.names = c("Interval", 
## +     "Sample size", "Mean", "Lower limit", "Higher limit", "SD"))
## 
## 
## |Interval | Sample size|     Mean| Lower limit| Higher limit|        SD|
## |:--------|-----------:|--------:|-----------:|------------:|---------:|
## |Low      |          58| 2.568966|    2.437666|     2.700265| 0.4995461|
## |Medium   |          48| 3.104167|    2.943089|     3.265244| 0.5550382|
## |Observed |          45| 3.311111|    3.056488|     3.565734| 0.8480518|
## 
## > library(knitr)
## 
## > srwdat <- read.csv(file = "./R/Data/srw_data.csv")
## 
## > kable(srwdat, format = "markdown", col.names = c("Sample size", 
## +     "Mean", "Lower limit", "Higher limit", "SE", "Author", "Location"))
## 
## 
## | Sample size| Mean| Lower limit| Higher limit|   SE|Author             |Location                          |
## |-----------:|----:|-----------:|------------:|----:|:------------------|:---------------------------------|
## |          NA| 3.12|        3.07|         3.17|   NA|Best et al. 2001   |South Africa                      |
## |        1504| 3.15|        3.11|         3.18|   NA|Best et al. 2005   |South Africa (1971-2003 Updated)  |
## |          NA| 3.16|        3.13|         3.19|   NA|Brandao et al 2010 |South Africa ( 1971-2006 Updated) |
## |          NA| 3.35|          NA|           NA| 0.05|Cooke et al. 2001  |Argentina                         |
## |         749| 3.42|          NA|           NA| 0.11|Cooke et al. 2003  |Argentina                         |
## |          NA| 3.63|          NA|           NA| 0.13|Burnell 2001       |Australia                         |
## 
## > SAreps <- 1500
## 
## > ARreps <- 800
## 
## > Aussiereps <- 2000
## 
## > low <- 1000
## 
## > verylow <- 100
## 
## > lowest <- 10
## 
## > par(mfrow = c(2, 3))
## 
## > plot(factor(sample(year2013$interval, lowest, replace = T)), 
## +     main = "3 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, verylow, replace = T)), 
## +     main = "10 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, low, replace = T)), 
## +     main = "30 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, Aussiereps, 
## +     replace = T)), main = "500 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, ARreps, replace = T)), 
## +     main = "800 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, SAreps, replace = T)), 
## +     main = "1500 intervals")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-7} \end{center}

\begin{verbatim}
## 
## > boots <- 1000
## 
## > n <- c(1:1000)
## 
## > var10 <- paste0("n_", 1:10)
## 
## > sample10 <- matrix(data = NA, ncol = lowest, nrow = boots)
## 
## > colnames(sample10) <- as.list(var10)
## 
## > for (i in 1:boots) {
## +     sample10[i, ] <- sample(year2013$interval, lowest, replace = T)
## + }
## 
## > sample10 <- as.data.frame(sample10)
## 
## > sample10 <- sample10 %>% mutate(mean10 = rowMeans(sample10))
## 
## > sample10t <- as.matrix(sample10)
## 
## > sample10t <- t(sample10t)
## 
## > var100 <- paste0("n_", 1:100)
## 
## > sample100 <- matrix(data = NA, ncol = verylow, nrow = boots)
## 
## > colnames(sample100) <- as.list(var100)
## 
## > for (i in 1:boots) {
## +     sample100[i, ] <- sample(year2013$interval, verylow, replace = T)
## + }
## 
## > sample100 <- as.data.frame(sample100)
## 
## > sample100 <- sample100 %>% mutate(mean100 = rowMeans(sample100))
## 
## > var500 <- paste0("n_", 1:500)
## 
## > sample500 <- matrix(data = NA, ncol = 500, nrow = boots)
## 
## > colnames(sample500) <- as.list(var500)
## 
## > for (i in 1:boots) {
## +     sample500[i, ] <- sample(year2013$interval, 500, replace = T)
## + }
## 
## > sample500 <- as.data.frame(sample500)
## 
## > sample500 <- sample500 %>% mutate(mean500 = rowMeans(sample500))
## 
## > var1000 <- paste0("n_", 1:1000)
## 
## > sample1000 <- matrix(data = NA, ncol = low, nrow = boots)
## 
## > colnames(sample1000) <- as.list(var1000)
## 
## > for (i in 1:boots) {
## +     sample1000[i, ] <- sample(year2013$interval, low, replace = T)
## + }
## 
## > sample1000 <- as.data.frame(sample1000)
## 
## > sample1000 <- sample1000 %>% mutate(mean1000 = rowMeans(sample1000))
## 
## > varA <- paste0("n_", 1:2000)
## 
## > sampleA <- matrix(data = NA, ncol = Aussiereps, nrow = boots)
## 
## > colnames(sampleA) <- as.list(varA)
## 
## > for (i in 1:boots) {
## +     sampleA[i, ] <- sample(year2013$interval, Aussiereps, replace = T)
## + }
## 
## > sampleA <- as.data.frame(sampleA)
## 
## > sampleA <- sampleA %>% mutate(meanA = rowMeans(sampleA))
## 
## > sampleAt <- t(sampleA)
## 
## > for (i in c(1:ncol(sampleA))) {
## +     sampleA[, i] <- as.numeric(as.character(sampleA[, i]))
## + }
## 
## > ab <- sort(sampleA$meanA)
## 
## > nab <- length(ab)
## 
## > ab2.5 <- ab[25]
## 
## > ab0.97.5 <- ab[975]
## 
## > ab <- sort(sampleA$meanA)
## 
## > nab <- length(ab)
## 
## > ab2.5 <- ab[25]
## 
## > ab0.97.5 <- ab[975]
## 
## > par(mfrow = c(1, 1))
## 
## > plot(density(sample10$mean10, bw = 0.05), col = "black", 
## +     lty = 1, main = "", lwd = 5, ylim = c(0, 8), xlim = c(2, 
## +         4.5), axes = FAL .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-8} \end{center}

\begin{verbatim}
## 
## > lines(density(sample100$mean100, bw = 0.05), col = "black", 
## +     lty = 2, lwd = 4)
## 
## > lines(density(sample500$mean500, bw = 0.05), col = "black", 
## +     lty = 3, lwd = 3)
## 
## > lines(density(sample1000$mean1000, bw = 0.05), col = "black", 
## +     lty = 4, lwd = 2)
## 
## > lines(density(sampleA$meanA, bw = 0.05), col = "black", 
## +     lty = 5, lwd = 1)
## 
## > legend("topright", title = "Legend", c("n=10, cv=8.12 ", 
## +     "n=100, cv=2.43", "n=500, c.v=1.15", "n=1000, cv=0.79", "n=2000, cv=0.56"), 
## +     b .... [TRUNCATED] 
## 
## > axis(1, lwd = 2)
## 
## > axis(2, lwd = 2)
## 
## > plot(density(sample10$mean10, bw = 0.05), col = "black", 
## +     lty = 3, main = "", lwd = 1, ylim = c(0, 8), xlim = c(2.5, 
## +         4.5), axes = F .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-9} \end{center}

\begin{verbatim}
## 
## > lines(density(sample100$mean100, bw = 0.05), col = "black", 
## +     lty = 4, lwd = 1)
## 
## > lines(density(sample500$mean500, bw = 0.05), col = "black", 
## +     lty = 5, lwd = 1)
## 
## > lines(density(sample1000$mean1000, bw = 0.05), col = "black", 
## +     lty = 2, lwd = 1)
## 
## > lines(density(sampleA$meanA, bw = 0.05), col = "black", 
## +     lty = 1, lwd = 2)
## 
## > legend(y = 8, x = 3.9, title = expression(bold("Sample size (n)")), 
## +     c(expression(italic("n") ~ "=" ~ "10"), expression(italic("n") ~ 
## +       .... [TRUNCATED] 
## 
## > axis(1, lwd = 2)
## 
## > axis(2, lwd = 2)
## 
## > rev.one <- bdata$RealCI[1:45]
## 
## > sample.true <- year2013$interval
## 
## > pwr.test.results <- power.t.test(n = 45, delta = seq(0, 
## +     0.99, 0.001), sd = sd(sample.true), alternative = "one.sided", 
## +     sig.level = 0.0 .... [TRUNCATED] 
## 
## > pwr.analysis <- as.data.frame(cbind(pwr.test.results$power, 
## +     pwr.test.results$delta))
## 
## > colnames(pwr.analysis) <- c("Power", "Mean.difference")
## 
## > pwr.analysis.1 <- pwr.analysis %>% mutate(Alpha = 1 - 
## +     Power, Mean.estimate = 3.31 + Mean.difference)
## 
## > a <- filter(pwr.analysis.1, Alpha < 0.05)
## 
## > a[1, ]
##       Power Mean.difference      Alpha Mean.estimate
## 1 0.9501505           0.593 0.04984946         3.903
## 
## > ggplot(data = pwr.analysis.1, aes(x = Mean.estimate, 
## +     y = Alpha)) + geom_line(size = 1.5) + geom_vline(xintercept = 3.903, 
## +     col = "blue" .... [TRUNCATED]
\end{verbatim}

\begin{verbatim}
## 
## > rev.one <- bdata$RealCI[1:45]
## 
## > sample.true <- year2013$interval
## 
## > diff <- 3.63 - 3.31
## 
## > pwr.test.results <- power.t.test(n = seq(1, 200, 1), 
## +     delta = diff, sd = sd(sample.true), alternative = "one.sided", 
## +     sig.level = 0.05)
\end{verbatim}

\begin{verbatim}
## Warning in qt(sig.level/tside, nu, lower.tail = FALSE): NaNs produced
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-10} \end{center}

\begin{verbatim}
## 
## > pwr.analysis <- as.data.frame(cbind(pwr.test.results$power, 
## +     pwr.test.results$n))
## 
## > colnames(pwr.analysis) <- c("Power", "Sample.size")
## 
## > pwr.analysis.1 <- pwr.analysis %>% mutate(Alpha = 1 - 
## +     Power)
## 
## > a <- filter(pwr.analysis.1, Alpha < 0.05)
## 
## > a[1, ]
##       Power Sample.size     Alpha
## 1 0.9503366         153 0.0496634
## 
## > ggplot(data = pwr.analysis.1, aes(x = Sample.size, 
## +     y = Alpha)) + geom_line(size = 1.5) + geom_vline(xintercept = 45, 
## +     col = "red") + ge .... [TRUNCATED]
\end{verbatim}

\begin{verbatim}
## Warning: Removed 1 rows containing missing values (geom_path).
\end{verbatim}

\begin{verbatim}
## 
## > dat <- read.csv("./R/Data/raw_observations_2012.csv")
## 
## > glimpse(dat)
## Observations: 180
## Variables: 10
## $ ID          <fct> AI06006, AI06007, AI06015, AI06022, AI06038, AI100...
## $ X2006       <int> 1, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2007       <int> 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2008       <int> 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,...
## $ X2009       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2010       <int> 0, 0, 2, 0, 0, 6, 6, 5, 5, 3, 4, 2, 5, 4, 5, 3, 2,...
## $ X2011       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2012       <int> 0, 1, 2, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 12, 0, 0, 0...
## $ total       <int> 2, 4, 8, 5, 3, 6, 7, 5, 5, 3, 9, 2, 5, 16, 6, 3, 2...
## $ X..yrs.seen <int> 2, 3, 5, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1,...
## 
## > head(dat)
##        ID X2006 X2007 X2008 X2009 X2010 X2011 X2012 total X..yrs.seen
## 1 AI06006     1     0     1     0     0     0     0     2           2
## 2 AI06007     2     1     0     0     0     0     1     4           3
## 3 AI06015     2     1     1     0     2     0     2     8           5
## 4 AI06022     1     0     0     0     0     0     4     5           2
## 5 AI06038     1     0     2     0     0     0     0     3           2
## 6 AI10040     0     0     0     0     6     0     0     6           1
## 
## > dat1 <- read.csv("./R/Data/RawCI.csv", header = T, 
## +     quote = "\"")
## 
## > glimpse(dat1)
## Observations: 41
## Variables: 8
## $ ID            <fct> AI10124, AI10070, AI10086, AI08340, AI08341, AI0...
## $ Yr.first.seen <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves        <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves.1      <int> 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, ...
## $ Calves.2      <int> 2013, 2013, 2013, NA, NA, NA, NA, NA, NA, NA, NA...
## $ Interval.1    <int> 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 6, ...
## $ Interval.2    <int> 3, 3, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ X             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
## 
## > dat3 <- dplyr::select(dat, ID, X2006:X2012) %>% gather(year, 
## +     count, X2006:X2012)
## 
## > dat4 <- full_join(dat3, dat1, by = "ID")
\end{verbatim}

\begin{verbatim}
## Warning: Column `ID` joining factors with different levels, coercing to
## character vector
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-11} \end{center}

\begin{verbatim}
## 
## > dat5 <- dplyr::select(dat4, ID, year, count, Yr.first.seen, 
## +     Calves, Calves.1, Calves.2)
## 
## > dat6 <- filter(dat5, count > 0)
## 
## > glimpse(dat6)
## Observations: 237
## Variables: 7
## $ ID            <chr> "AI06006", "AI06007", "AI06015", "AI06022", "AI0...
## $ year          <chr> "X2006", "X2006", "X2006", "X2006", "X2006", "X2...
## $ count         <int> 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
## $ Yr.first.seen <int> NA, NA, NA, 2006, NA, NA, NA, 2007, 2007, NA, NA...
## $ Calves        <int> NA, NA, NA, 2006, NA, NA, NA, 2007, 2007, NA, NA...
## $ Calves.1      <int> NA, NA, NA, 2012, NA, NA, NA, 2013, 2010, NA, NA...
## $ Calves.2      <int> NA, NA, NA, NA, NA, NA, NA, NA, 2013, NA, NA, 20...
## 
## > dat7 <- mutate(dat6, year = ifelse(year == "X2006", 
## +     "2006", year), year = ifelse(year == "X2007", "2007", year), 
## +     year = ifelse(year == .... [TRUNCATED] 
## 
## > a <- group_by(dat7, ID, Yr.first.seen) %>% mutate(mother = ifelse(Yr.first.seen > 
## +     0, 1, 0)) %>% filter(mother == 1) %>% ungroup() %>% dplyr:: .... [TRUNCATED] 
## 
## > a
## # A tibble: 1 x 4
##   ID      year  Calves Calves.1
##   <chr>   <chr>  <int>    <int>
## 1 AI09216 2007    2009     2011
## 
## > greater.than.2 <- sample.true[sample.true > 2]
## 
## > mean.2 <- sum(greater.than.2)/length(greater.than.2)
## 
## > s.2 <- sd(greater.than.2)
## 
## > SE.2 <- s2013/(sqrt(length(greater.than.2)))
## 
## > n.2 <- length(greater.than.2)
## 
## > low.qt.2 <- mean.2 - (qt(0.975, length(greater.than.2)) * 
## +     SE.2)
## 
## > high.qt.2 <- mean.2 + (qt(0.975, length(greater.than.2)) * 
## +     SE.2)
## 
## > Sumtable[4, ] <- c("miss2year", n.2, mean.2, low.qt.2, 
## +     high.qt.2, sd(greater.than.2))
## 
## > boots <- 1000
## 
## > n <- c(1:1000)
## 
## > detect1 <- 44
## 
## > detect2 <- 42
## 
## > detect3 <- 40
## 
## > sample2 <- rep(NA, 1000)
## 
## > sample5 <- rep(NA, 1000)
## 
## > sample10 <- rep(NA, 1000)
## 
## > for (i in 1:boots) {
## +     sample2[i] <- mean(sample(year2013$interval, detect1, replace = T))
## +     sample5[i] <- mean(sample(year2013$interval, de .... [TRUNCATED] 
## 
## > sample2 <- sort(sample2)
## 
## > sample2.2.5 <- sample2[25]
## 
## > sample2.50 <- sample2[500]
## 
## > sample2.975 <- sample2[975]
## 
## > sample5 <- sort(sample5)
## 
## > sample5.2.5 <- sample5[25]
## 
## > sample5.50 <- sample5[500]
## 
## > sample5.975 <- sample5[975]
## 
## > sample10 <- sort(sample10)
## 
## > sample10.2.5 <- sample10[25]
## 
## > sample10.50 <- sample10[500]
## 
## > sample10.975 <- sample10[975]
## 
## > Sumtable[5, ] <- c("detect1", detect1, sample2.50, 
## +     sample2.2.5, sample2.975, NA)
## 
## > Sumtable[6, ] <- c("detect2", detect2, sample5.50, 
## +     sample5.2.5, sample5.975, NA)
## 
## > Sumtable[7, ] <- c("detect5", detect3, sample10.50, 
## +     sample10.2.5, sample10.975, NA)
## 
## > length(Data$ID)
## [1] 41
## 
## > length(dat$ID)
## [1] 180
## 
## > glimpse(Data)
## Observations: 41
## Variables: 8
## $ ID            <fct> AI10124, AI10070, AI10086, AI08340, AI08341, AI0...
## $ Yr.first.seen <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves        <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves.1      <int> 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, ...
## $ Calves.2      <int> 2013, 2013, 2013, NA, NA, NA, NA, NA, NA, NA, NA...
## $ Interval.1    <int> 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 6, ...
## $ Interval.2    <int> 3, 3, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ X             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
## 
## > dat.detect <- dplyr::select(Data, ID, Calves, Calves.1, 
## +     Calves.2) %>% mutate(Calves = factor(Calves), Calves.1 = factor(Calves.1), 
## +     Cal .... [TRUNCATED] 
## 
## > a <- as.data.frame.matrix(table(Data$ID, Data$Calves))
## 
## > head(a)
##         2006 2007 2008 2009 2010 2011
## AI06022    1    0    0    0    0    0
## AI08340    0    0    1    0    0    0
## AI08341    0    0    1    0    0    0
## AI08343    0    0    1    0    0    0
## AI08355    0    0    1    0    0    0
## AI08362    0    0    1    0    0    0
## 
## > a[, 7] <- row.names(a)
## 
## > colnames(a)[1] <- "y2006"
## 
## > colnames(a)[2] <- "y2007"
## 
## > colnames(a)[3] <- "y2008"
## 
## > colnames(a)[4] <- "y2009"
## 
## > colnames(a)[5] <- "y2010"
## 
## > colnames(a)[6] <- "y2011"
## 
## > colnames(a)[7] <- "ID"
## 
## > a[, 8] <- 0
## 
## > colnames(a)[8] <- "y2012"
## 
## > a[, 9] <- 0
## 
## > colnames(a)[9] <- "y2013"
## 
## > a <- dplyr::select(a, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > b <- as.data.frame.matrix(table(Data$ID, Data$Calves.1))
## 
## > head(b)
##         2010 2011 2012 2013
## AI06022    0    0    1    0
## AI08340    0    1    0    0
## AI08341    0    1    0    0
## AI08343    0    0    0    1
## AI08355    0    1    0    0
## AI08362    0    1    0    0
## 
## > b[, 5] <- row.names(b)
## 
## > colnames(b)[5] <- "ID"
## 
## > b[, 6] <- 0
## 
## > colnames(b)[6] <- "y2006"
## 
## > b[, 7] <- 0
## 
## > colnames(b)[7] <- "y2007"
## 
## > b[, 8] <- 0
## 
## > colnames(b)[8] <- "y2008"
## 
## > b[, 9] <- 0
## 
## > colnames(b)[9] <- "y2009"
## 
## > colnames(b)[1] <- "y2010"
## 
## > colnames(b)[2] <- "y2011"
## 
## > colnames(b)[3] <- "y2012"
## 
## > colnames(b)[4] <- "y2013"
## 
## > b <- dplyr::select(b, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > c <- as.data.frame.matrix(table(Data$ID, Data$Calves.2))
## 
## > head(c)
##         2013
## AI06022    0
## AI08340    0
## AI08341    0
## AI08343    0
## AI08355    0
## AI08362    0
## 
## > colnames(c)[1] <- "y2013"
## 
## > c[, 2] <- row.names(c)
## 
## > colnames(c)[2] <- "ID"
## 
## > c[, 3] <- 0
## 
## > colnames(c)[3] <- "y2006"
## 
## > c[, 4] <- 0
## 
## > colnames(c)[4] <- "y2007"
## 
## > c[, 5] <- 0
## 
## > colnames(c)[5] <- "y2008"
## 
## > c[, 6] <- 0
## 
## > colnames(c)[6] <- "y2009"
## 
## > c[, 7] <- 0
## 
## > colnames(c)[7] <- "y2010"
## 
## > c[, 8] <- 0
## 
## > colnames(c)[8] <- "y2011"
## 
## > c[, 9] <- 0
## 
## > colnames(c)[9] <- "y2012"
## 
## > c <- dplyr::select(c, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > countdat <- rbind(a, b, c)
## 
## > glimpse(countdat)
## Observations: 123
## Variables: 9
## $ ID    <chr> "AI06022", "AI08340", "AI08341", "AI08343", "AI08355", "...
## $ y2006 <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2007 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2008 <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...
## $ y2009 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...
## $ y2010 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2011 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2012 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2013 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## 
## > full.dat <- group_by(countdat, ID) %>% summarise(y2006 = sum(y2006), 
## +     y2007 = sum(y2007), y2008 = sum(y2008), y2009 = sum(y2009), 
## +     y2010 .... [TRUNCATED] 
## 
## > 2012 - 2006
## [1] 6
## 
## > sort(Data$ID)
##  [1] AI06022 AI08340 AI08341 AI08343 AI08355 AI08362 AI08364 AI08365
##  [9] AI08372 AI08378 AI08379 AI08383 AI08386 AI08387 AI08390 AI08395
## [17] AI08403 AI09216 AI09217 AI09221 AI09224 AI09225 AI09247 AI09249
## [25] AI09259 AI09265 AI09289 AI10043 AI10056 AI10070 AI10085 AI10086
## [33] AI10102 AI10124 AI10144 AI10160 AI10167 AI10170 AI10177 AI11408
## [41] AI11430
## 41 Levels: AI06022 AI08340 AI08341 AI08343 AI08355 AI08362 ... AI11430
## 
## > filter(Data, ID == "AI06022")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI06022          2006   2006     2012       NA          6         NA NA
## 
## > filter(Data, ID == "AI08340")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI08340          2008   2008     2011       NA          3         NA NA
## 
## > filter(Data, ID == "AI08343")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI08343          2008   2008     2013       NA          5         NA NA
## 
## > head(Data)
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI10124          2007   2007     2010     2013          3          3 NA
## 2 AI10070          2008   2008     2010     2013          2          3 NA
## 3 AI10086          2007   2007     2010     2013          3          3 NA
## 4 AI08340          2008   2008     2011       NA          3         NA NA
## 5 AI08341          2008   2008     2011       NA          3         NA NA
## 6 AI08355          2008   2008     2011       NA          3         NA NA
## 
## > longer5.6 <- c(sample.true, 5, 6, 6)
## 
## > mean.56 <- sum(longer5.6)/length(longer5.6)
## 
## > s.56 <- sd(longer5.6)
## 
## > SE.56 <- s.56/(sqrt(length(longer5.6)))
## 
## > n.56 <- (length(longer5.6))
## 
## > low.qt.56 <- mean.56 - (qt(0.975, length(longer5.6)) * 
## +     SE.56)
## 
## > high.qt.56 <- mean.56 + (qt(0.975, length(longer5.6)) * 
## +     SE.56)
## 
## > Sumtable[8, ] <- c("longer.56", n.56, mean.56, low.qt.56, 
## +     high.qt.56, sd(longer5.6))
## 
## > Sumtable <- as.data.frame(Sumtable)
## 
## > Sumtable$n <- as.numeric(as.character(Sumtable$n))
## 
## > Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
## 
## > Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
## 
## > Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
## 
## > Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
## 
## > Sumtable$interval <- as.character(Sumtable$interval)
## 
## > library(knitr)
## 
## > kable(Sumtable, format = "markdown", col.names = c("Interval", 
## +     "Sample size", "Mean", "Lower limit", "Higher limit", "SD"))
## 
## 
## |Interval  | Sample size|     Mean| Lower limit| Higher limit|        SD|
## |:---------|-----------:|--------:|-----------:|------------:|---------:|
## |Low       |          58| 2.568966|    2.437666|     2.700265| 0.4995461|
## |Medium    |          48| 3.104167|    2.943089|     3.265244| 0.5550382|
## |Observed  |          45| 3.311111|    3.056488|     3.565734| 0.8480518|
## |miss2year |          41| 3.439024|    3.171549|     3.706499| 0.7761695|
## |detect1   |          44| 3.295454|    3.090909|     3.545454|        NA|
## |detect2   |          42| 3.309524|    3.071429|     3.571429|        NA|
## |detect5   |          40| 3.300000|    3.075000|     3.575000|        NA|
## |longer.56 |          48| 3.458333|    3.165307|     3.751360| 1.0097047|
## 
## > ggplot(Sumtable, aes(y = mY, x = interval)) + geom_point(size = 5) + 
## +     geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05, 
## +       .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-78-12} \end{center}

\hypertarget{plot-steps}{%
\subsection{Plot steps}\label{plot-steps}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## ----raw graph, echo=FALSE, message=FALSE, warning=FALSE-----------------}
\CommentTok{#plot data}
\KeywordTok{ggplot}\NormalTok{(sum.dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ mY, }\DataTypeTok{x =}\NormalTok{ year)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ low.qt, }\DataTypeTok{ymax =}\NormalTok{ high.qt), }\DataTypeTok{width =} \FloatTok{0.1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-79-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ## ----raw graph 2, echo=FALSE, fig.height=6, fig.width=6, message=FALSE, warning=FALSE----}
\CommentTok{# }
\CommentTok{# #PLOTS}
\CommentTok{# par(mfrow=c(2,2))}
\CommentTok{# }
\CommentTok{# plot(factor(year2010),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="a)",sub="Sample size 3", ylab="Frequency",xlab="Calving interval",}
\CommentTok{#       cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2011),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="b)",sub="Sample size 15", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2012),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="c)",sub="Sample size 25", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2013),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="d)",sub="Sample size 45", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----raw graph 3, echo=FALSE, fig.height=6, fig.width=6, message=TRUE, warning=TRUE----}
\CommentTok{# library(qpcR)}
\CommentTok{# #data in one way for plot}
\CommentTok{# rawdata <- qpcR:::cbind.na(year2010,year2011,year2012,year2013)}
\CommentTok{# rawdata <- as.data.frame(rawdata)}
\CommentTok{# }
\CommentTok{# #in correct format for ggplot2}
\CommentTok{# year2010 <- data.frame(year2010,year = c("2010"))}
\CommentTok{# year2010 <- rename(year2010, interval = year2010, year = year )}
\CommentTok{# year2011 <- data.frame(year2011,year = c("2011"))}
\CommentTok{# year2011 <- rename(year2011, interval = year2011, year = year )}
\CommentTok{# year2012 <- data.frame(year2012,year = c("2012"))}
\CommentTok{# year2012 <- rename(year2012, interval = year2012, year = year )}
\CommentTok{# year2013 <- data.frame(year2013,year = c("2013"))}
\CommentTok{# year2013 <- rename(year2013, interval = year2013, year = year )}
\CommentTok{# ggplotraw <- rbind(year2010,year2011,year2012, year2013)}
\CommentTok{# ggplotraw$interval <- as.numeric(as.character(ggplotraw$interval))}
\CommentTok{# }
\CommentTok{# #sort(year2013$interval) - sort(sample.true)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ggplot(year2013,aes(x = interval)) +}
\CommentTok{#     geom_bar(alpha = 1, width = 0.9,fill = "black") +}
\CommentTok{#     xlab(expression("Calving"~"interval"~(italic("years")))) +}
\CommentTok{#     ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +}
\CommentTok{#     scale_y_continuous(breaks = c(0,5,10,15,20,25,30), limits = c(0,30)) +}
\CommentTok{#     theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black"))}
\CommentTok{# #PLOTS}
\CommentTok{# #code to store figure}
\CommentTok{# # png("Figure_2_NZSRW_calving_interval_2017_highres.png", width = 12, height = 14.8, units = 'cm', res = 1200)}
\CommentTok{# # dev.off()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals, echo=FALSE, fig.height=10, message=FALSE, warning=FALSE----}
\CommentTok{# #################################Missing calving intervals################}
\CommentTok{# #Intervals modified by accounting for missed intervals}
\CommentTok{# #Bradford et al. 2008}
\CommentTok{# }
\CommentTok{# #Raw Data}
\CommentTok{# RealCI <- as.numeric(year2013$interval)}
\CommentTok{# }
\CommentTok{# #Confidence interval}
\CommentTok{# xlong <- RealCI}
\CommentTok{# meanlong<-sum(xlong)/length(xlong)}
\CommentTok{# slong<-sd(xlong)}
\CommentTok{# SElong<-slong/(sqrt(length(xlong)))}
\CommentTok{# nlong<-(length(xlong))}
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# #2 sided t value at the 95% level = 2.093}
\CommentTok{# lowqtlong <- meanlong-(qt(0.975,nlong)*SElong)}
\CommentTok{# highqtlong <- meanlong+(qt(0.975,nlong)*SElong)}
\CommentTok{# }
\CommentTok{# ####################MED CI########################################}
\CommentTok{# # 2x 6's and 1x 5 replaced with 3threes}
\CommentTok{# MedCI <- c(RealCI[RealCI < 5],3,3,3,3,2,3)}
\CommentTok{# #sort(MedCI)}
\CommentTok{# xmed<-MedCI}
\CommentTok{# meanmed<-sum(xmed)/length(xmed)}
\CommentTok{# smed<-sd(xmed)}
\CommentTok{# SEmed<-smed/(sqrt(length(xmed)))}
\CommentTok{# nmed<-(length(xmed))}
\CommentTok{# }
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# lowqtmed <- meanmed-(qt(0.975,length(xmed))*SEmed)}
\CommentTok{# highqtmed <- meanmed+(qt(0.975,length(xmed))*SEmed)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ############################SHORT CI##################################}
\CommentTok{# #6,5 replaced with 2 year intervals}
\CommentTok{# }
\CommentTok{# LowCI <- c(RealCI[RealCI < 4],3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)}
\CommentTok{# xshort<-LowCI}
\CommentTok{# meanshort<-mean(xshort)}
\CommentTok{# sshort<-sd(xshort)}
\CommentTok{# SEshort<-sshort/(sqrt(length(xshort)))}
\CommentTok{# }
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# lowqtshort <- meanshort-(qt(0.975,length(xshort))*SEshort)}
\CommentTok{# highqtshort <- meanshort+(qt(0.975,length(xshort))*SEshort)}
\CommentTok{# }
\CommentTok{# bdata <-qpcR:::cbind.na(RealCI,MedCI,LowCI)}
\CommentTok{# bdata <- as.data.frame(bdata)}
\CommentTok{# }
\CommentTok{# #Structure of data set}
\CommentTok{# #str(bdata)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot, echo=FALSE, fig.height=3.5, fig.width=5.5, message=FALSE, warning=FALSE----}
\CommentTok{# #Basic plots}
\CommentTok{# par(mfrow=c(1,3))}
\CommentTok{# plot(factor(bdata$LowCI),main="Lowest possible interval")}
\CommentTok{# plot(factor(bdata$MedCI), main="Medium possible interval")}
\CommentTok{# plot(factor(bdata$RealCI),main="Observed interval")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot2, fig.height=5.5, fig.width=4.5, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# #Density basic plots}
\CommentTok{# par(mfrow=c(3,1))}
\CommentTok{# plot(density(as.numeric(as.character(LowCI)),bw=.5), main="Lowest possible interval")}
\CommentTok{# plot(density(as.numeric(as.character(MedCI)),bw= 0.5), main="Medium possible interval")}
\CommentTok{# plot(density(as.numeric(as.character(RealCI)),bw = 0.5),main="Observed interval")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals table, fig.height=8, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# }
\CommentTok{# ###################################SUMMARY############################}
\CommentTok{# #Pull out important information}
\CommentTok{# Sumtable<-data.frame(variable = c("low.qt","mean","high.qt","sd", "SE"),                 short=c(lowqtshort,meanshort,highqtshort,sshort,SEshort),}
\CommentTok{#                      medium=c(lowqtmed,meanmed,highqtmed,smed,SEmed),}
\CommentTok{#                      real=c(lowqtlong,meanlong,highqtlong,slong,SElong))}
\CommentTok{# }
\CommentTok{# #Make dataframe to plot}
\CommentTok{# n <- c(length(LowCI),length(MedCI),length(year2013$interval))}
\CommentTok{# mY <- c(mean(LowCI),mean(MedCI),mean(year2013$interval))}
\CommentTok{# interval <-c("Low", "Medium","Observed")}
\CommentTok{# low.qt <- c(lowqtshort,lowqtmed,low.qt2013)}
\CommentTok{# high.qt <- c(highqtshort,highqtmed,high.qt2013)}
\CommentTok{# sd <- c(sshort,smed,s2013)}
\CommentTok{# Sumtable <- cbind(interval,n,mY,low.qt,high.qt,sd)}
\CommentTok{# Sumtable <-  as.data.frame(Sumtable)}
\CommentTok{# }
\CommentTok{#  Sumtable$n <- as.numeric(as.character(Sumtable$n))}
\CommentTok{#  Sumtable$mY <- as.numeric(as.character(Sumtable$mY))}
\CommentTok{#  Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))}
\CommentTok{#  Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))}
\CommentTok{#  Sumtable$sd <- as.numeric(as.character(Sumtable$sd))}
\CommentTok{#  Sumtable$interval <- as.character(Sumtable$interval)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot3, echo=FALSE, fig.height=4, message=FALSE, warning=FALSE----}
\CommentTok{# ggplot(Sumtable, aes(y = mY, x = interval)) +}
\CommentTok{#   geom_point(size = 5) +}
\CommentTok{#   geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +}
\CommentTok{#   scale_y_continuous(breaks = round(seq(2.3, 3.6, by = 0.2),1)) +}
\CommentTok{#   labs(y = "Mean calving interval",x = "Calving interval modification" ) +}
\CommentTok{#   geom_point(size = 3) +}
\CommentTok{#   theme_classic() +}
\CommentTok{#   theme_hc() +}
\CommentTok{#   theme(legend.position="none")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing_data_table, echo=FALSE--------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# }
\CommentTok{# kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----srw_data_table, echo=FALSE------------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# setwd("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data")}
\CommentTok{# srwdat <- read.csv(file = "srw_data.csv")}
\CommentTok{# }
\CommentTok{# #str(srwdat)}
\CommentTok{# kable(srwdat, format = "markdown",col.names = c("Sample size","Mean", "Lower limit", "Higher limit", "SE","Author", "Location"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap single, echo=FALSE, fig.height=5--------------------------}
\CommentTok{# ############################NZ Simple sample##############################}
\CommentTok{# #WITH replacement}
\CommentTok{# }
\CommentTok{# # to try and match number of intervals observed in other populations}
\CommentTok{# # find references}
\CommentTok{# SAreps <- 1500}
\CommentTok{# ARreps <- 800}
\CommentTok{# Aussiereps <- 2000}
\CommentTok{# low <- 1000}
\CommentTok{# verylow <- 100}
\CommentTok{# lowest <- 10}
\CommentTok{# }
\CommentTok{# #Very raw plots}
\CommentTok{# par(mfrow=c(2,3))}
\CommentTok{# plot(factor(sample(year2013$interval,lowest,replace=T)),main = "3 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,verylow,replace=T)),main = "10 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,low,replace=T)),main = "30 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,Aussiereps,replace=T)),main = "500 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,ARreps,replace=T)),main = "800 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,SAreps,replace=T)),main = "1500 intervals")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap_multiple, echo=FALSE--------------------------------------}
\CommentTok{# #do each one 1000 times}
\CommentTok{# boots <- 1000}
\CommentTok{# n <- c(1:1000)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ###########################n10}
\CommentTok{# var10 <- paste0("n_", 1:10)}
\CommentTok{# sample10 <-matrix(data = NA, ncol = lowest, nrow = boots)}
\CommentTok{# colnames(sample10) <- as.list(var10)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample10 [i, ] <- sample(year2013$interval,lowest,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample10 <- as.data.frame(sample10)}
\CommentTok{# sample10 <- sample10 %>%}
\CommentTok{#             mutate(mean10 = rowMeans(sample10))}
\CommentTok{# }
\CommentTok{# sample10t <- as.matrix(sample10)}
\CommentTok{# sample10t <-t(sample10t)}
\CommentTok{# }
\CommentTok{# #########################verylow sample size}
\CommentTok{# #set up variable names}
\CommentTok{# var100 <- paste0("n_", 1:100)}
\CommentTok{# }
\CommentTok{# sample100 <-matrix(data = NA, ncol = verylow, nrow = boots)}
\CommentTok{# colnames(sample100) <- as.list(var100)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample100 [i, ] <- sample(year2013$interval,verylow,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample100 <- as.data.frame(sample100)}
\CommentTok{# sample100 <- sample100 %>%}
\CommentTok{#             mutate(mean100 = rowMeans(sample100))}
\CommentTok{# }
\CommentTok{# #########################middle one}
\CommentTok{# #set up variable names}
\CommentTok{# var500 <- paste0("n_", 1:500)}
\CommentTok{# }
\CommentTok{# sample500 <-matrix(data = NA, ncol = 500, nrow = boots)}
\CommentTok{# colnames(sample500) <- as.list(var500)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample500 [i, ] <- sample(year2013$interval,500,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample500 <- as.data.frame(sample500)}
\CommentTok{# sample500 <- sample500 %>%}
\CommentTok{#             mutate(mean500 = rowMeans(sample500))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #########################low sample size}
\CommentTok{# #set up variable names}
\CommentTok{# var1000 <- paste0("n_", 1:1000)}
\CommentTok{# }
\CommentTok{# sample1000 <-matrix(data = NA, ncol = low, nrow = boots)}
\CommentTok{# colnames(sample1000) <- as.list(var1000)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample1000 [i, ] <- sample(year2013$interval,low,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample1000 <- as.data.frame(sample1000)}
\CommentTok{# sample1000 <- sample1000 %>%}
\CommentTok{#             mutate(mean1000 = rowMeans(sample1000))}
\CommentTok{# }
\CommentTok{# #########################AUS sample size}
\CommentTok{# #set up variable names}
\CommentTok{# varA <- paste0("n_", 1:2000)}
\CommentTok{# }
\CommentTok{# sampleA <-matrix(data = NA, ncol = Aussiereps, nrow =  boots)}
\CommentTok{# colnames(sampleA) <- as.list(varA)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sampleA [i, ] <- sample(year2013$interval,Aussiereps,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sampleA <- as.data.frame(sampleA)}
\CommentTok{# sampleA <- sampleA %>%}
\CommentTok{#             mutate(meanA = rowMeans(sampleA))}
\CommentTok{# }
\CommentTok{# sampleAt <- t(sampleA)}
\CommentTok{# }
\CommentTok{# for(i in c(1:ncol(sampleA))) \{}
\CommentTok{#     sampleA[,i] <- as.numeric(as.character(sampleA[,i]))}
\CommentTok{# \}}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #COnfidence intervals}
\CommentTok{# }
\CommentTok{# ab <- sort(sampleA$meanA)}
\CommentTok{# nab <- length(ab)}
\CommentTok{# #low = 25/1000}
\CommentTok{# ab2.5 <- ab[25]}
\CommentTok{# #high = 975/1000}
\CommentTok{# ab0.97.5 <- ab[975]}
\CommentTok{# }
\CommentTok{# ab <- sort(sampleA$meanA)}
\CommentTok{# nab <- length(ab)}
\CommentTok{# #low = 25/1000}
\CommentTok{# ab2.5 <- ab[25]}
\CommentTok{# #high = 975/1000}
\CommentTok{# ab0.97.5 <- ab[975]}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap plot2, fig.height=5, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# #plot the data over each other to look at change in density}
\CommentTok{# par(mfrow=c(1,1))}
\CommentTok{# #plot(density(sample3$mean3,bw = .15),lwd = 3,lyt = 5, main = "", xlab = "Calving interval", box = FALSE,axis = FALSE)}
\CommentTok{# }
\CommentTok{# plot(density(sample10$mean10,bw = .05),col ="black", lty = 1, main = "", lwd = 5,ylim = c(0,8),xlim = c(2,4.5), axes=FALSE,xlab = "Calving interval")}
\CommentTok{# lines(density(sample100$mean100,bw = .05),col ="black", lty = 2, lwd = 4)}
\CommentTok{# lines(density(sample500$mean500,bw = .05),col ="black", lty = 3, lwd = 3)}
\CommentTok{# lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 4, lwd = 2)}
\CommentTok{# lines(density(sampleA$meanA,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# legend('topright',title = "Legend", c("n=10, cv=8.12 ", "n=100, cv=2.43", "n=500, c.v=1.15", "n=1000, cv=0.79", "n=2000, cv=0.56"),bty = "n",}
\CommentTok{#   lty = c(1,2,3,4,5), lwd = c(5,4,3,2,1), cex=.75)}
\CommentTok{# axis(1,lwd=2)}
\CommentTok{# axis(2,lwd=2)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----final plot for publication1, echo=FALSE-----------------------------}
\CommentTok{# #final [plot]}
\CommentTok{# #size defined by NZJFMR}
\CommentTok{# #  195 mm (h) ? 148 mm (w).}
\CommentTok{# #ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +}
\CommentTok{# }
\CommentTok{# plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE, xlab = expression("Calving"~"interval"~(italic("years"))))}
\CommentTok{# lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)}
\CommentTok{# lines(density(sample500$mean500,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 2, lwd = 1)}
\CommentTok{# lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)}
\CommentTok{# legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",}
\CommentTok{#   lty = c(3,4,5,2,1), lwd = c(1,1,1,1,2), cex=1)}
\CommentTok{#  axis(1,lwd=2)}
\CommentTok{# axis(2,lwd=2)}
\CommentTok{# }
\CommentTok{# # PLOT CODE FOR PUBLICATION}
\CommentTok{# # png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_lowres.png", width = 14.8, height = 14.8, units = 'cm', res = 400)}
\CommentTok{# # dev.off()}
\CommentTok{# #}
\CommentTok{# #}
\CommentTok{# # png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_highres.png", width = 14.8, height = 14.8, units = 'cm', res = 1200)}
\CommentTok{# #}
\CommentTok{# # plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE,xlab = expression("Calving"~"interval"~(italic("years"))))}
\CommentTok{# # lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)}
\CommentTok{# # lines(density(sample500$mean500,bw = .05),col ="black", lty = 2, lwd = 1)}
\CommentTok{# # lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# # lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)}
\CommentTok{# # legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",}
\CommentTok{# #   lty = c(3,4,2,5,1), lwd = c(1,1,1,1,2), cex=1)}
\CommentTok{# # axis(1,lwd=2)}
\CommentTok{# # axis(2,lwd=2)}
\CommentTok{# #}
\CommentTok{# # dev.off()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_1, echo=TRUE----------------------------------------}
\CommentTok{# #observed sample}
\CommentTok{# rev.one <- bdata$RealCI[1:45]}
\CommentTok{# }
\CommentTok{# #sample 45 times}
\CommentTok{# sample.true <- year2013$interval}
\CommentTok{# }
\CommentTok{# #power analysis}
\CommentTok{# pwr.test.results <- power.t.test(n = 45,# sample size}
\CommentTok{#              delta = seq(0,0.99,0.001),  #difference between means}
\CommentTok{#              sd = sd(sample.true),      #observed variation}
\CommentTok{#              alternative = "one.sided", #observed test type}
\CommentTok{#              sig.level = 0.05)          #significance level}
\CommentTok{# }
\CommentTok{# #additional packages are avaliable for more complex analysis}
\CommentTok{# #but have not done this as don't think it is needed}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_1_plot, echo=FALSE, message=FALSE, warning=FALSE----}
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis <- as.data.frame(cbind(}
\CommentTok{#                               pwr.test.results$power,}
\CommentTok{#                               pwr.test.results$delta))}
\CommentTok{# }
\CommentTok{# colnames(pwr.analysis) <- c("Power","Mean.difference")}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis.1 <- pwr.analysis %>%}
\CommentTok{#   mutate(Alpha = 1- Power,}
\CommentTok{#          Mean.estimate = 3.31 + Mean.difference)}
\CommentTok{# # %>%}
\CommentTok{# #   select(Alpha,Mean.estimate)}
\CommentTok{# }
\CommentTok{# #work out where the cut-off is}
\CommentTok{# a <- filter(pwr.analysis.1, Alpha < 0.05)}
\CommentTok{# a[1,]}
\CommentTok{# }
\CommentTok{# #plot data}
\CommentTok{# ggplot(data = pwr.analysis.1, aes(x = Mean.estimate, y = Alpha)) +}
\CommentTok{#   geom_line(size = 1.5) +}
\CommentTok{#   geom_vline(xintercept = 3.903, col = "blue") +}
\CommentTok{#   geom_hline(yintercept = 0.05) +}
\CommentTok{#   theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black")) +}
\CommentTok{#   ggtitle("Raw data result plot (n = 45)")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_2_plot, echo=FALSE, message=FALSE, warning=FALSE----}
\CommentTok{# #observed sample}
\CommentTok{# rev.one <- bdata$RealCI[1:45]}
\CommentTok{# }
\CommentTok{# #sample 45 times}
\CommentTok{# sample.true <- year2013$interval}
\CommentTok{# }
\CommentTok{# #difference}
\CommentTok{# diff <- 3.63-3.31  #observed mean of australian population}
\CommentTok{# }
\CommentTok{# #power analysis}
\CommentTok{# pwr.test.results <- power.t.test(n = seq(1,200,1),# sample size}
\CommentTok{#              delta = diff,  #difference between means}
\CommentTok{#              sd = sd(sample.true),      #observed variation}
\CommentTok{#              alternative = "one.sided", #observed test type}
\CommentTok{#              sig.level = 0.05)          #significance level}
\CommentTok{# }
\CommentTok{# #additional packages are avaliable for more complex analysis}
\CommentTok{# #but have not done this as don't think it is needed}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis <- as.data.frame(cbind(}
\CommentTok{#                               pwr.test.results$power,}
\CommentTok{#                               pwr.test.results$n))}
\CommentTok{# }
\CommentTok{# colnames(pwr.analysis) <- c("Power","Sample.size")}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis.1 <- pwr.analysis %>%}
\CommentTok{#   mutate(Alpha = 1- Power)}
\CommentTok{# # %>%}
\CommentTok{# #   select(Alpha,Mean.estimate)}
\CommentTok{# }
\CommentTok{# #work out where the cut-off is}
\CommentTok{# a <- filter(pwr.analysis.1, Alpha < 0.05)}
\CommentTok{# a[1,]}
\CommentTok{# }
\CommentTok{# #plot data}
\CommentTok{# ggplot(data = pwr.analysis.1, aes(x = Sample.size, y = Alpha)) +}
\CommentTok{#   geom_line(size = 1.5) +}
\CommentTok{#   geom_vline(xintercept = 45, col = "red") +}
\CommentTok{#   geom_vline(xintercept = 153, col = "blue") +}
\CommentTok{#   geom_hline(yintercept = 0.05) +}
\CommentTok{#   scale_y_continuous(limits = c(0,1)) +}
\CommentTok{#   theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black")) +}
\CommentTok{#    ggtitle("Observed difference between Australian and NZ mean")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missed individuals 1, echo=FALSE------------------------------------}
\CommentTok{# dat <- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/raw_observations_2012.csv")}
\CommentTok{# #data structure}
\CommentTok{# glimpse(dat)}
\CommentTok{# head(dat)}
\CommentTok{# #And the second dataset}
\CommentTok{# dat1<- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/RawCI.csv", header=T, quote="\textbackslash{}"")}
\CommentTok{# #data structure}
\CommentTok{# glimpse(dat1)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missed individuals 2, echo=FALSE, message=FALSE, warning=FALSE------}
\CommentTok{# ##I can then modify this data to}
\CommentTok{# #restructure dataset of capture to long dataset}
\CommentTok{# dat3 <- dplyr::select(dat, ID, X2006:X2012)%>%}
\CommentTok{#                gather(year, count,X2006:X2012)}
\CommentTok{# }
\CommentTok{# #add data on calves}
\CommentTok{# dat4 <- full_join(dat3,dat1, by = "ID")}
\CommentTok{# dat5 <- dplyr::select(dat4,ID,year,count,Yr.first.seen,Calves,Calves.1,Calves.2)}
\CommentTok{# }
\CommentTok{# dat6 <- filter(dat5,count >0)}
\CommentTok{# glimpse(dat6)}
\CommentTok{# }
\CommentTok{# dat7 <- mutate(dat6, year = ifelse(year == "X2006","2006", year),}
\CommentTok{#             year = ifelse(year == "X2007","2007", year),}
\CommentTok{#             year = ifelse(year == "X2008","2008", year),}
\CommentTok{#             year = ifelse(year == "X2009","2009", year),}
\CommentTok{#             year = ifelse(year == "X2010","2010", year),}
\CommentTok{#             year = ifelse(year == "X2011","2011", year),}
\CommentTok{#             year = ifelse(year == "X2012","2012", year))}
\CommentTok{# }
\CommentTok{# a <- group_by(dat7, ID, Yr.first.seen) %>%}
\CommentTok{#   mutate(mother = ifelse(Yr.first.seen > 0, 1, 0)) %>%}
\CommentTok{#   filter(mother == 1) %>%}
\CommentTok{#   ungroup() %>%}
\CommentTok{#   dplyr::select(ID,year,Calves,Calves.1) %>%}
\CommentTok{#   filter(Calves.1<2013) %>%}
\CommentTok{#   filter(!year == Calves) %>%}
\CommentTok{# filter(!year ==Calves.1)}
\CommentTok{# }
\CommentTok{# a}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment3, echo=TRUE, message=FALSE, warning=FALSE-----------}
\CommentTok{# greater.than.2 <- sample.true[sample.true>2]}
\CommentTok{# }
\CommentTok{# #greater.than.2}
\CommentTok{# mean.2<-sum(greater.than.2)/length(greater.than.2)}
\CommentTok{# s.2<-sd(greater.than.2)}
\CommentTok{# SE.2<-s2013/(sqrt(length(greater.than.2)))}
\CommentTok{# n.2<-length(greater.than.2)}
\CommentTok{# low.qt.2<- mean.2-(qt(0.975,length(greater.than.2))*SE.2)}
\CommentTok{# high.qt.2 <- mean.2+(qt(0.975,length(greater.than.2))*SE.2)}
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[4,] <- c("miss2year",n.2,mean.2,low.qt.2,}
\CommentTok{#                   high.qt.2,sd(greater.than.2))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----different missing intervals 1, echo=TRUE----------------------------}
\CommentTok{# ########################### 2.2%}
\CommentTok{# #parameters}
\CommentTok{# boots <- 1000}
\CommentTok{# n <- c(1:1000)}
\CommentTok{# }
\CommentTok{# ###round all percentages upwards}
\CommentTok{# detect1 <- 44  # (45*1.02) - 45 = 0.9}
\CommentTok{# detect2 <- 42   #  (45*1.05) - 45 = 2.25}
\CommentTok{# detect3 <- 40  # (45*1.10) - 45 = 4.5}
\CommentTok{# }
\CommentTok{# sample2 <-rep(NA, 1000)}
\CommentTok{# sample5 <-rep(NA, 1000)}
\CommentTok{# sample10 <-rep(NA, 1000)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample2[i]<-mean(sample(year2013$interval,detect1,replace=T))}
\CommentTok{#                     sample5[i]<-mean(sample(year2013$interval,detect2,replace=T))}
\CommentTok{#                     sample10[i]<-mean(sample(year2013$interval,detect3,replace=T))}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# ######################estimates##############}
\CommentTok{# sample2 <- sort(sample2)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample2.2.5 <- sample2[25]}
\CommentTok{# #median}
\CommentTok{# sample2.50 <- sample2[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample2.975 <- sample2[975]}
\CommentTok{# }
\CommentTok{# sample5 <- sort(sample5)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample5.2.5 <- sample5[25]}
\CommentTok{# #median}
\CommentTok{# sample5.50 <- sample5[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample5.975 <- sample5[975]}
\CommentTok{# }
\CommentTok{# sample10 <- sort(sample10)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample10.2.5 <- sample10[25]}
\CommentTok{# #median}
\CommentTok{# sample10.50 <- sample10[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample10.975 <- sample10[975]}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[5,] <- c("detect1",detect1,sample2.50,sample2.2.5,sample2.975,NA)}
\CommentTok{# Sumtable[6,] <- c("detect2",detect2,sample5.50,sample5.2.5,sample5.975,NA)}
\CommentTok{# Sumtable[7,] <- c("detect5",detect3,sample10.50,sample10.2.5,sample10.975,NA)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----detection sim.2-----------------------------------------------------}
\CommentTok{# }
\CommentTok{# #be very careful as Dat is just IDS and no id of females with calves}
\CommentTok{# #BUT Data is identified females...}
\CommentTok{# length(Data$ID)}
\CommentTok{# length(dat$ID)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# glimpse(Data)}
\CommentTok{# dat.detect <- dplyr::select(Data,ID,Calves,Calves.1, Calves.2) %>%}
\CommentTok{#                   mutate(Calves = factor(Calves),}
\CommentTok{#                          Calves.1 = factor(Calves.1),}
\CommentTok{#                          Calves.2 = factor(Calves.2))}
\CommentTok{# }
\CommentTok{# a <- as.data.frame.matrix(table(Data$ID,Data$Calves))}
\CommentTok{# head(a)}
\CommentTok{# a[,7] <-row.names(a)}
\CommentTok{# colnames(a)[1] <- "y2006"}
\CommentTok{# colnames(a)[2] <- "y2007"}
\CommentTok{# colnames(a)[3] <- "y2008"}
\CommentTok{# colnames(a)[4] <- "y2009"}
\CommentTok{# colnames(a)[5] <- "y2010"}
\CommentTok{# colnames(a)[6] <- "y2011"}
\CommentTok{# colnames(a)[7] <- "ID"}
\CommentTok{# a[,8] <- 0}
\CommentTok{# colnames(a)[8] <- "y2012"}
\CommentTok{# a[,9] <- 0}
\CommentTok{# colnames(a)[9] <- "y2013"}
\CommentTok{# a <- dplyr::select(a,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012, y2013)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# b <- as.data.frame.matrix(table(Data$ID,Data$Calves.1))}
\CommentTok{# head(b)}
\CommentTok{# b[,5] <-row.names(b)}
\CommentTok{# colnames(b)[5] <- "ID"}
\CommentTok{# b[,6] <- 0}
\CommentTok{# colnames(b)[6] <- "y2006"}
\CommentTok{# b[,7] <- 0}
\CommentTok{# colnames(b)[7] <- "y2007"}
\CommentTok{# b[,8] <- 0}
\CommentTok{# colnames(b)[8] <- "y2008"}
\CommentTok{# b[,9] <- 0}
\CommentTok{# colnames(b)[9] <- "y2009"}
\CommentTok{# colnames(b)[1] <- "y2010"}
\CommentTok{# colnames(b)[2] <- "y2011"}
\CommentTok{# colnames(b)[3] <- "y2012"}
\CommentTok{# colnames(b)[4] <- "y2013"}
\CommentTok{# b <- dplyr::select(b,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012, y2013)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# c <- as.data.frame.matrix(table(Data$ID,Data$Calves.2))}
\CommentTok{# head(c)}
\CommentTok{# colnames(c)[1] <- "y2013"}
\CommentTok{# c[,2] <-row.names(c)}
\CommentTok{# colnames(c)[2] <- "ID"}
\CommentTok{# c[,3] <- 0}
\CommentTok{# colnames(c)[3] <- "y2006"}
\CommentTok{# c[,4] <- 0}
\CommentTok{# colnames(c)[4] <- "y2007"}
\CommentTok{# c[,5] <- 0}
\CommentTok{# colnames(c)[5] <- "y2008"}
\CommentTok{# c[,6] <- 0}
\CommentTok{# colnames(c)[6] <- "y2009"}
\CommentTok{# c[,7] <- 0}
\CommentTok{# colnames(c)[7] <- "y2010"}
\CommentTok{# c[,8] <- 0}
\CommentTok{# colnames(c)[8] <- "y2011"}
\CommentTok{# c[,9] <- 0}
\CommentTok{# colnames(c)[9] <- "y2012"}
\CommentTok{# }
\CommentTok{# c <- dplyr::select(c,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012,y2013)}
\CommentTok{# }
\CommentTok{# countdat <- rbind(a,b,c)}
\CommentTok{# glimpse(countdat)}
\CommentTok{# head(full.dat)}
\CommentTok{# }
\CommentTok{# full.dat <- group_by(countdat, ID) %>%}
\CommentTok{#   summarise(y2006 = sum(y2006),}
\CommentTok{#             y2007 = sum(y2007),}
\CommentTok{#             y2008 = sum(y2008),}
\CommentTok{#             y2009 = sum(y2009),}
\CommentTok{#             y2010 = sum(y2010),}
\CommentTok{#             y2011 = sum(y2011),}
\CommentTok{#             y2012 = sum(y2012),}
\CommentTok{#             y2013 = sum(y2013))}
\CommentTok{# }
\CommentTok{# 2012-2006}
\CommentTok{# }
\CommentTok{# ##checking....}
\CommentTok{# }
\CommentTok{# sort(Data$ID)}
\CommentTok{# filter(Data, ID == "AI06022")}
\CommentTok{# filter(Data, ID == "AI08340")}
\CommentTok{# filter(Data, ID == "AI08343")}
\CommentTok{# }
\CommentTok{# head(Data)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# # glimpse(c)}
\CommentTok{# # Data$Calves.1,}
\CommentTok{# # # Spread and gather are complements}
\CommentTok{# # df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))}
\CommentTok{# # df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----different missing intervals 2---------------------------------------}
\CommentTok{# longer5.6 <- c(sample.true,5,6,6)}
\CommentTok{# }
\CommentTok{# #greater.than.2}
\CommentTok{# mean.56<-sum(longer5.6)/length(longer5.6)}
\CommentTok{# s.56<-sd(longer5.6)}
\CommentTok{# SE.56<-s.56/(sqrt(length(longer5.6)))}
\CommentTok{# n.56<-(length(longer5.6))}
\CommentTok{# low.qt.56<- mean.56-(qt(0.975,length(longer5.6))*SE.56)}
\CommentTok{# high.qt.56 <- mean.56+(qt(0.975,length(longer5.6))*SE.56)}
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[8,] <- c("longer.56",n.56,mean.56,low.qt.56,high.qt.56,sd(longer5.6))}
\CommentTok{# }
\CommentTok{# ###sort out numbering in dataframe}
\CommentTok{# Sumtable <-  as.data.frame(Sumtable)}
\CommentTok{# }
\CommentTok{#  Sumtable$n <- as.numeric(as.character(Sumtable$n))}
\CommentTok{#  Sumtable$mY <- as.numeric(as.character(Sumtable$mY))}
\CommentTok{#  Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))}
\CommentTok{#  Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))}
\CommentTok{#  Sumtable$sd <- as.numeric(as.character(Sumtable$sd))}
\CommentTok{#  Sumtable$interval <- as.character(Sumtable$interval)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing_data_table 2, echo=FALSE------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# }
\CommentTok{# kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment3_plot, echo=FALSE-----------------------------------}
\CommentTok{# ggplot(Sumtable, aes(y = mY, x = interval)) +}
\CommentTok{#   geom_point(size = 5) +}
\CommentTok{#   geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +}
\CommentTok{#   scale_y_continuous(breaks = round(seq(2.3, 5, by = 0.2),1)) +}
\CommentTok{#   labs(y = "Mean calving interval",x = "Calving interval modification" ) +}
\CommentTok{#   geom_point(size = 3) +}
\CommentTok{#   theme_classic() +}
\CommentTok{#   theme_hc() +}
\CommentTok{#   theme(legend.position="none")}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{exercise-4}{%
\section{Exercise 4}\label{exercise-4}}

In these exercises, you will be adapting the code written in this chapter to investigate slightly different questions. You should create a new R script \texttt{Ex4.R} in your working directory for these exercises so your chapter code is left unchanged. Exercise 4A is based solely on the required material and Exercises 4B - 4F are based on the example cases. You should work through each example before attempting each of the later exercises.

\emph{The solutions to this exercise are found at the end of this book (\protect\hyperlink{ex4a-answers}{here}). You are \textbf{strongly recommended} to make a good attempt at completing this exercise on your own and only look at the solutions when you are truly stumped.}

\hypertarget{exercise-4a-required-material-only}{%
\subsection*{Exercise 4A: Required Material Only}\label{exercise-4a-required-material-only}}
\addcontentsline{toc}{subsection}{Exercise 4A: Required Material Only}

These questions are based on the material in Sections \ref{randomness} - \ref{mc-summaries} only.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate flipping an unfair coin (probability of heads = 0.6) 100 times using \texttt{rbinom()}. Count the number of heads and tails.
\item
  Simulate flipping the same unfair coin 100 times, but using \texttt{sample()} instead. Determine what fraction of the flips resulted in heads.
\item
  Simulate rolling a fair 6-sided die 100 times using \texttt{sample()}. Determine what fraction of the rolls resulted in an even number.
\item
  Simulate rolling the same die 100 times, but use the function \texttt{rmultinom()} instead. Look at the help file for details on how to use this function. Determine what fraction of the rolls resulted in an odd number.
\end{enumerate}

\protect\hyperlink{ex4a-answers}{Solutions}

\hypertarget{exercise-4b-test-rnorm}{%
\subsection*{\texorpdfstring{Exercise 4B: Test \texttt{rnorm}}{Exercise 4B: Test rnorm}}\label{exercise-4b-test-rnorm}}
\addcontentsline{toc}{subsection}{Exercise 4B: Test \texttt{rnorm}}

These questions will require you to adapt the code written in Section \ref{rnorm-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adapt this example to investigate another univariate probability distribution, like \texttt{-lnorm()}, \texttt{-pois()}, or \texttt{-beta()}. See the help files (e.g., \texttt{?rpois}) for details on how to use each function.
\end{enumerate}

\protect\hyperlink{ex4b-answers}{Solutions}

\hypertarget{exercise-4c-stochastic-power-analysis}{%
\subsection*{Exercise 4C: Stochastic Power Analysis}\label{exercise-4c-stochastic-power-analysis}}
\addcontentsline{toc}{subsection}{Exercise 4C: Stochastic Power Analysis}

These questions will require you to adapt the code written in Section \ref{power-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What sample size \texttt{n} do you need to have a power of 0.8 of detecting a significant difference between the two tagging methods?
\item
  How do the inferences from the power analysis change if you are interested in \texttt{p\_new\ =\ 0.4} instead of \texttt{p\_new\ =\ 0.25}? Do you need to tag more or fewer fish in this case?
\item
  Your analysis takes a bit of time to run so you are interested in tracking its progress. Add a progress message to your nested \texttt{for()} loop that will print the sample size currently being analyzed:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}r}\StringTok{"}\NormalTok{, }\StringTok{"Sample Size = "}\NormalTok{, n_try[n])}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{I) \{}
\NormalTok{    ...}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\protect\hyperlink{ex4c-answers}{Solutions}

\hypertarget{exercise-4d-harvest-policy-analysis}{%
\subsection*{Exercise 4D: Harvest Policy Analysis}\label{exercise-4d-harvest-policy-analysis}}
\addcontentsline{toc}{subsection}{Exercise 4D: Harvest Policy Analysis}

These questions will require you to adapt the code written in Section \ref{harv-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add an argument to \texttt{ricker\_sim()} that will give the user an option to create a plot that shows the time series of recruitment, harvest, and escapement all on the same plot. Set the default to be to not plot the result, in case you forget to turn it off before performing the Monte Carlo analysis.
\item
  Add an \emph{error handler} to \texttt{ricker\_sim()} that will cause the function to return an error \texttt{if()} the names of the vector passed to the \texttt{param} argument aren't what the function is expecting. You can use \texttt{stop("Error\ Message\ Goes\ Here")} to have your function stop and return an error.
\item
  How do the results of the trade-off analysis differ if the process error was larger (a larger value of \(\sigma\))?
\item
  Add implementation error to the harvest policy. That is, if the target exploitation rate is \(U\), make the real exploitation rate in year \(y\) be: \(U_y \sim Beta(a,b)\), where \(a = 100U\) and \(b = 100(1-U)\). You can make there be more implementation error by inserting a smaller number other than 100 here. How does this affect the trade-off analysis?
\end{enumerate}

\protect\hyperlink{ex4d-answers}{Solutions}

\hypertarget{exercise-4e-the-bootstrap}{%
\subsection*{Exercise 4E: The Bootstrap}\label{exercise-4e-the-bootstrap}}
\addcontentsline{toc}{subsection}{Exercise 4E: The Bootstrap}

These questions will require you to adapt the code written in Section \ref{boot-test-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replicate the bootstrap analysis, but adapt it for the linear regression example in Section \ref{regression}. Stop at the step where you summarize the 95\% interval range.
\item
  Compare the 95\% bootstrap confidence intervals to the intervals you get by running the \texttt{predict()} function on the original data set with the argument \texttt{interval\ =\ "confidence"}.
\end{enumerate}

\protect\hyperlink{ex4e-answers}{Solutions}

\hypertarget{exercise-4f-permutation-tests}{%
\subsection*{Exercise 4F: Permutation Tests}\label{exercise-4f-permutation-tests}}
\addcontentsline{toc}{subsection}{Exercise 4F: Permutation Tests}

These questions will require you to adapt the code written in Section \ref{perm-test-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adapt the code to perform a permutation test for the difference in each of the zooplankton densities between treatments. Don't forget to fix the missing value in the \texttt{chao} variable. See \protect\hyperlink{ex1b}{Exercise 2} for more details on this.
\item
  Adapt the code to perform a permutation test for another data set used in this book where there are observations of both a categorical variable and a continuous variable. The data sets \texttt{sockeye.csv}, \texttt{growth.csv}, or \texttt{creel.csv} should be good starting points.
\item
  Add a calculation of the p-value for a one-tailed test (i.e., that the difference in means is greater or less than zero). Steps 1 - 4 are the same: all you need is \texttt{Dnull} and \texttt{Dobs}. Don't be afraid to Google this if you are confused.
\end{enumerate}

\protect\hyperlink{ex4f-answers}{Solutions}

\hypertarget{calves}{%
\chapter{Calving interval example}\label{calves}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{source}\NormalTok{(}\StringTok{"./R/Rcode/Final_report_Davidson2017.R"}\NormalTok{, }\DataTypeTok{echo =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## > library(boot)
## 
## > library(tidyverse)
## 
## > library(dplyr)
## 
## > library(ggplot2)
## 
## > library(qpcR)
## 
## > library(pwr)
## 
## > library(ggthemes)
## 
## > library(gridExtra)
## 
## > Data <- read.csv("./R/Data/RawCI.csv", header = T, 
## +     quote = "\"")
## 
## > Year <- unique(Data$Calves.1)
## 
## > year2010a <- c(3, 3, 2)
## 
## > year2010 <- filter(Data, Calves.1 < 2011)
## 
## > year2010 <- year2010$Interval.1[!is.na(year2010$Interval.1)]
## 
## > year2011a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2)
## 
## > year2011 <- filter(Data, Calves.1 < 2012)
## 
## > year2011 <- year2011$Interval.1[!is.na(year2011$Interval.1)]
## 
## > year2012a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2, 6, 4, 4, 4, 4, 4, 3, 3, 3, 3)
## 
## > year2012 <- filter(Data, Calves.1 < 2013)
## 
## > year2012 <- year2012$Interval.1[!is.na(year2012$Interval.1)]
## 
## > year2013a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2, 6, 4, 4, 4, 4, 4, 3, 3, 3, 3, 6, 5, 4, 4, 4, 4, 
## +     4, 3, 3, 3, 3, 3, 3, 3, 3, .... [TRUNCATED] 
## 
## > full <- c(Data$Interval.1, Data$Interval.2)
## 
## > year2013 <- full[!is.na(unlist(full))]
## 
## > mean2010 <- sum(year2010)/length(year2010)
## 
## > s2010 <- sd(year2010)
## 
## > SE2010 <- s2010/(sqrt(length(year2010)))
## 
## > n2010 <- (length(year2010))
## 
## > low.qt2010 <- mean2010 - (qt(0.975, length(year2010)) * 
## +     SE2010)
## 
## > high.qt2010 <- mean2010 + (qt(0.975, length(year2010)) * 
## +     SE2010)
## 
## > mean2011 <- sum(year2011)/length(year2011)
## 
## > s2011 <- sd(year2011)
## 
## > SE2011 <- s2011/(sqrt(length(year2011)))
## 
## > n2011 <- (length(year2011))
## 
## > low.qt2011 <- mean2011 - (qt(0.975, length(year2011)) * 
## +     SE2011)
## 
## > high.qt2011 <- mean2011 + (qt(0.975, length(year2011)) * 
## +     SE2011)
## 
## > mean2012 <- sum(year2012)/length(year2012)
## 
## > s2012 <- sd(year2012)
## 
## > SE2012 <- s2012/(sqrt(length(year2012)))
## 
## > n2012 <- (length(year2012))
## 
## > low.qt2012 <- mean2012 - (qt(0.975, length(year2012)) * 
## +     SE2012)
## 
## > high.qt2012 <- mean2012 + (qt(0.975, length(year2012)) * 
## +     SE2012)
## 
## > mean2013 <- sum(year2013)/length(year2013)
## 
## > s2013 <- sd(year2013)
## 
## > SE2013 <- s2013/(sqrt(length(year2013)))
## 
## > n2013 <- (length(year2013))
## 
## > low.qt2013 <- mean2013 - (qt(0.975, length(year2013)) * 
## +     SE2013)
## 
## > high.qt2013 <- mean2013 + (qt(0.975, length(year2013)) * 
## +     SE2013)
## 
## > n <- c(length(year2010), length(year2011), length(year2012), 
## +     length(year2013))
## 
## > mY <- c(mean(year2010), mean(year2011), mean(year2012), 
## +     mean(year2013))
## 
## > year <- Year
## 
## > low.qt <- c(low.qt2010, low.qt2011, low.qt2012, low.qt2013)
## 
## > high.qt <- c(high.qt2010, high.qt2011, high.qt2012, 
## +     high.qt2013)
## 
## > sd <- c(s2010, s2011, s2012, s2013)
## 
## > sum.dat <- cbind(year, n, mY, low.qt, high.qt, sd)
## 
## > sum.dat <- as.data.frame(sum.dat)
## 
## > library(knitr)
## 
## > kable(sum.dat, format = "markdown")
## 
## 
## | year|  n|       mY|   low.qt|  high.qt|        sd|
## |----:|--:|--------:|--------:|--------:|---------:|
## | 2010|  3| 2.666667| 1.605851| 3.727482| 0.5773503|
## | 2011| 15| 2.866667| 2.673022| 3.060312| 0.3518658|
## | 2012| 25| 3.240000| 2.919170| 3.560830| 0.7788881|
## | 2013| 45| 3.311111| 3.056488| 3.565734| 0.8480518|
## 
## > ggplot(sum.dat, aes(y = mY, x = year)) + geom_point() + 
## +     geom_line() + geom_errorbar(aes(ymin = low.qt, ymax = high.qt), 
## +     width = 0.1) + .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-1} \end{center}

\begin{verbatim}
## 
## > par(mfrow = c(2, 2))
## 
## > plot(factor(year2010), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "a)", sub = "Sample size 3", ylab = "Frequency", 
## +     xlab = "Calving interval", cex.main = 1.5, font.main = 4, 
## +     col.main = "bl ..." ... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2011), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "b)", sub = "Sample size 15", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2012), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "c)", sub = "Sample size 25", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2013), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-2} \end{center}

\begin{verbatim}
## 
## > title(main = "d)", sub = "Sample size 45", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > library(qpcR)
## 
## > rawdata <- qpcR:::cbind.na(year2010, year2011, year2012, 
## +     year2013)
## 
## > rawdata <- as.data.frame(rawdata)
## 
## > year2010 <- data.frame(year2010, year = c("2010"))
## 
## > year2010 <- rename(year2010, interval = year2010, 
## +     year = year)
## 
## > year2011 <- data.frame(year2011, year = c("2011"))
## 
## > year2011 <- rename(year2011, interval = year2011, 
## +     year = year)
## 
## > year2012 <- data.frame(year2012, year = c("2012"))
## 
## > year2012 <- rename(year2012, interval = year2012, 
## +     year = year)
## 
## > year2013 <- data.frame(year2013, year = c("2013"))
## 
## > year2013 <- rename(year2013, interval = year2013, 
## +     year = year)
## 
## > ggplotraw <- rbind(year2010, year2011, year2012, year2013)
## 
## > ggplotraw$interval <- as.numeric(as.character(ggplotraw$interval))
## 
## > ggplot(year2013, aes(x = interval)) + geom_bar(alpha = 1, 
## +     width = 0.9, fill = "black") + xlab(expression("Calving" ~ 
## +     "interval" ~ (ita .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-3} \end{center}

\begin{verbatim}
## 
## > RealCI <- as.numeric(year2013$interval)
## 
## > xlong <- RealCI
## 
## > meanlong <- sum(xlong)/length(xlong)
## 
## > slong <- sd(xlong)
## 
## > SElong <- slong/(sqrt(length(xlong)))
## 
## > nlong <- (length(xlong))
## 
## > lowqtlong <- meanlong - (qt(0.975, nlong) * SElong)
## 
## > highqtlong <- meanlong + (qt(0.975, nlong) * SElong)
## 
## > MedCI <- c(RealCI[RealCI < 5], 3, 3, 3, 3, 2, 3)
## 
## > xmed <- MedCI
## 
## > meanmed <- sum(xmed)/length(xmed)
## 
## > smed <- sd(xmed)
## 
## > SEmed <- smed/(sqrt(length(xmed)))
## 
## > nmed <- (length(xmed))
## 
## > lowqtmed <- meanmed - (qt(0.975, length(xmed)) * SEmed)
## 
## > highqtmed <- meanmed + (qt(0.975, length(xmed)) * 
## +     SEmed)
## 
## > LowCI <- c(RealCI[RealCI < 4], 3, 3, 3, 3, 3, 2, 2, 
## +     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)
## 
## > xshort <- LowCI
## 
## > meanshort <- mean(xshort)
## 
## > sshort <- sd(xshort)
## 
## > SEshort <- sshort/(sqrt(length(xshort)))
## 
## > lowqtshort <- meanshort - (qt(0.975, length(xshort)) * 
## +     SEshort)
## 
## > highqtshort <- meanshort + (qt(0.975, length(xshort)) * 
## +     SEshort)
## 
## > bdata <- qpcR:::cbind.na(RealCI, MedCI, LowCI)
## 
## > bdata <- as.data.frame(bdata)
## 
## > par(mfrow = c(1, 3))
## 
## > plot(factor(bdata$LowCI), main = "Lowest possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(bdata$MedCI), main = "Medium possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(bdata$RealCI), main = "Observed interval")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-4} \end{center}

\begin{verbatim}
## 
## > par(mfrow = c(3, 1))
## 
## > plot(density(as.numeric(as.character(LowCI)), bw = 0.5), 
## +     main = "Lowest possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(density(as.numeric(as.character(MedCI)), bw = 0.5), 
## +     main = "Medium possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(density(as.numeric(as.character(RealCI)), bw = 0.5), 
## +     main = "Observed interval")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-5} \end{center}

\begin{verbatim}
## 
## > Sumtable <- data.frame(variable = c("low.qt", "mean", 
## +     "high.qt", "sd", "SE"), short = c(lowqtshort, meanshort, 
## +     highqtshort, sshort, SE .... [TRUNCATED] 
## 
## > n <- c(length(LowCI), length(MedCI), length(year2013$interval))
## 
## > mY <- c(mean(LowCI), mean(MedCI), mean(year2013$interval))
## 
## > interval <- c("Low", "Medium", "Observed")
## 
## > low.qt <- c(lowqtshort, lowqtmed, low.qt2013)
## 
## > high.qt <- c(highqtshort, highqtmed, high.qt2013)
## 
## > sd <- c(sshort, smed, s2013)
## 
## > Sumtable <- cbind(interval, n, mY, low.qt, high.qt, 
## +     sd)
## 
## > Sumtable <- as.data.frame(Sumtable)
## 
## > Sumtable$n <- as.numeric(as.character(Sumtable$n))
## 
## > Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
## 
## > Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
## 
## > Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
## 
## > Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
## 
## > Sumtable$interval <- as.character(Sumtable$interval)
## 
## > ggplot(Sumtable, aes(y = mY, x = interval)) + geom_point(size = 5) + 
## +     geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05, 
## +       .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-6} \end{center}

\begin{verbatim}
## 
## > library(knitr)
## 
## > kable(Sumtable, format = "markdown", col.names = c("Interval", 
## +     "Sample size", "Mean", "Lower limit", "Higher limit", "SD"))
## 
## 
## |Interval | Sample size|     Mean| Lower limit| Higher limit|        SD|
## |:--------|-----------:|--------:|-----------:|------------:|---------:|
## |Low      |          58| 2.568966|    2.437666|     2.700265| 0.4995461|
## |Medium   |          48| 3.104167|    2.943089|     3.265244| 0.5550382|
## |Observed |          45| 3.311111|    3.056488|     3.565734| 0.8480518|
## 
## > library(knitr)
## 
## > srwdat <- read.csv(file = "./R/Data/srw_data.csv")
## 
## > kable(srwdat, format = "markdown", col.names = c("Sample size", 
## +     "Mean", "Lower limit", "Higher limit", "SE", "Author", "Location"))
## 
## 
## | Sample size| Mean| Lower limit| Higher limit|   SE|Author             |Location                          |
## |-----------:|----:|-----------:|------------:|----:|:------------------|:---------------------------------|
## |          NA| 3.12|        3.07|         3.17|   NA|Best et al. 2001   |South Africa                      |
## |        1504| 3.15|        3.11|         3.18|   NA|Best et al. 2005   |South Africa (1971-2003 Updated)  |
## |          NA| 3.16|        3.13|         3.19|   NA|Brandao et al 2010 |South Africa ( 1971-2006 Updated) |
## |          NA| 3.35|          NA|           NA| 0.05|Cooke et al. 2001  |Argentina                         |
## |         749| 3.42|          NA|           NA| 0.11|Cooke et al. 2003  |Argentina                         |
## |          NA| 3.63|          NA|           NA| 0.13|Burnell 2001       |Australia                         |
## 
## > SAreps <- 1500
## 
## > ARreps <- 800
## 
## > Aussiereps <- 2000
## 
## > low <- 1000
## 
## > verylow <- 100
## 
## > lowest <- 10
## 
## > par(mfrow = c(2, 3))
## 
## > plot(factor(sample(year2013$interval, lowest, replace = T)), 
## +     main = "3 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, verylow, replace = T)), 
## +     main = "10 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, low, replace = T)), 
## +     main = "30 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, Aussiereps, 
## +     replace = T)), main = "500 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, ARreps, replace = T)), 
## +     main = "800 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, SAreps, replace = T)), 
## +     main = "1500 intervals")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-7} \end{center}

\begin{verbatim}
## 
## > boots <- 1000
## 
## > n <- c(1:1000)
## 
## > var10 <- paste0("n_", 1:10)
## 
## > sample10 <- matrix(data = NA, ncol = lowest, nrow = boots)
## 
## > colnames(sample10) <- as.list(var10)
## 
## > for (i in 1:boots) {
## +     sample10[i, ] <- sample(year2013$interval, lowest, replace = T)
## + }
## 
## > sample10 <- as.data.frame(sample10)
## 
## > sample10 <- sample10 %>% mutate(mean10 = rowMeans(sample10))
## 
## > sample10t <- as.matrix(sample10)
## 
## > sample10t <- t(sample10t)
## 
## > var100 <- paste0("n_", 1:100)
## 
## > sample100 <- matrix(data = NA, ncol = verylow, nrow = boots)
## 
## > colnames(sample100) <- as.list(var100)
## 
## > for (i in 1:boots) {
## +     sample100[i, ] <- sample(year2013$interval, verylow, replace = T)
## + }
## 
## > sample100 <- as.data.frame(sample100)
## 
## > sample100 <- sample100 %>% mutate(mean100 = rowMeans(sample100))
## 
## > var500 <- paste0("n_", 1:500)
## 
## > sample500 <- matrix(data = NA, ncol = 500, nrow = boots)
## 
## > colnames(sample500) <- as.list(var500)
## 
## > for (i in 1:boots) {
## +     sample500[i, ] <- sample(year2013$interval, 500, replace = T)
## + }
## 
## > sample500 <- as.data.frame(sample500)
## 
## > sample500 <- sample500 %>% mutate(mean500 = rowMeans(sample500))
## 
## > var1000 <- paste0("n_", 1:1000)
## 
## > sample1000 <- matrix(data = NA, ncol = low, nrow = boots)
## 
## > colnames(sample1000) <- as.list(var1000)
## 
## > for (i in 1:boots) {
## +     sample1000[i, ] <- sample(year2013$interval, low, replace = T)
## + }
## 
## > sample1000 <- as.data.frame(sample1000)
## 
## > sample1000 <- sample1000 %>% mutate(mean1000 = rowMeans(sample1000))
## 
## > varA <- paste0("n_", 1:2000)
## 
## > sampleA <- matrix(data = NA, ncol = Aussiereps, nrow = boots)
## 
## > colnames(sampleA) <- as.list(varA)
## 
## > for (i in 1:boots) {
## +     sampleA[i, ] <- sample(year2013$interval, Aussiereps, replace = T)
## + }
## 
## > sampleA <- as.data.frame(sampleA)
## 
## > sampleA <- sampleA %>% mutate(meanA = rowMeans(sampleA))
## 
## > sampleAt <- t(sampleA)
## 
## > for (i in c(1:ncol(sampleA))) {
## +     sampleA[, i] <- as.numeric(as.character(sampleA[, i]))
## + }
## 
## > ab <- sort(sampleA$meanA)
## 
## > nab <- length(ab)
## 
## > ab2.5 <- ab[25]
## 
## > ab0.97.5 <- ab[975]
## 
## > ab <- sort(sampleA$meanA)
## 
## > nab <- length(ab)
## 
## > ab2.5 <- ab[25]
## 
## > ab0.97.5 <- ab[975]
## 
## > par(mfrow = c(1, 1))
## 
## > plot(density(sample10$mean10, bw = 0.05), col = "black", 
## +     lty = 1, main = "", lwd = 5, ylim = c(0, 8), xlim = c(2, 
## +         4.5), axes = FAL .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-8} \end{center}

\begin{verbatim}
## 
## > lines(density(sample100$mean100, bw = 0.05), col = "black", 
## +     lty = 2, lwd = 4)
## 
## > lines(density(sample500$mean500, bw = 0.05), col = "black", 
## +     lty = 3, lwd = 3)
## 
## > lines(density(sample1000$mean1000, bw = 0.05), col = "black", 
## +     lty = 4, lwd = 2)
## 
## > lines(density(sampleA$meanA, bw = 0.05), col = "black", 
## +     lty = 5, lwd = 1)
## 
## > legend("topright", title = "Legend", c("n=10, cv=8.12 ", 
## +     "n=100, cv=2.43", "n=500, c.v=1.15", "n=1000, cv=0.79", "n=2000, cv=0.56"), 
## +     b .... [TRUNCATED] 
## 
## > axis(1, lwd = 2)
## 
## > axis(2, lwd = 2)
## 
## > plot(density(sample10$mean10, bw = 0.05), col = "black", 
## +     lty = 3, main = "", lwd = 1, ylim = c(0, 8), xlim = c(2.5, 
## +         4.5), axes = F .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-9} \end{center}

\begin{verbatim}
## 
## > lines(density(sample100$mean100, bw = 0.05), col = "black", 
## +     lty = 4, lwd = 1)
## 
## > lines(density(sample500$mean500, bw = 0.05), col = "black", 
## +     lty = 5, lwd = 1)
## 
## > lines(density(sample1000$mean1000, bw = 0.05), col = "black", 
## +     lty = 2, lwd = 1)
## 
## > lines(density(sampleA$meanA, bw = 0.05), col = "black", 
## +     lty = 1, lwd = 2)
## 
## > legend(y = 8, x = 3.9, title = expression(bold("Sample size (n)")), 
## +     c(expression(italic("n") ~ "=" ~ "10"), expression(italic("n") ~ 
## +       .... [TRUNCATED] 
## 
## > axis(1, lwd = 2)
## 
## > axis(2, lwd = 2)
## 
## > rev.one <- bdata$RealCI[1:45]
## 
## > sample.true <- year2013$interval
## 
## > pwr.test.results <- power.t.test(n = 45, delta = seq(0, 
## +     0.99, 0.001), sd = sd(sample.true), alternative = "one.sided", 
## +     sig.level = 0.0 .... [TRUNCATED] 
## 
## > pwr.analysis <- as.data.frame(cbind(pwr.test.results$power, 
## +     pwr.test.results$delta))
## 
## > colnames(pwr.analysis) <- c("Power", "Mean.difference")
## 
## > pwr.analysis.1 <- pwr.analysis %>% mutate(Alpha = 1 - 
## +     Power, Mean.estimate = 3.31 + Mean.difference)
## 
## > a <- filter(pwr.analysis.1, Alpha < 0.05)
## 
## > a[1, ]
##       Power Mean.difference      Alpha Mean.estimate
## 1 0.9501505           0.593 0.04984946         3.903
## 
## > ggplot(data = pwr.analysis.1, aes(x = Mean.estimate, 
## +     y = Alpha)) + geom_line(size = 1.5) + geom_vline(xintercept = 3.903, 
## +     col = "blue" .... [TRUNCATED]
\end{verbatim}

\begin{verbatim}
## 
## > rev.one <- bdata$RealCI[1:45]
## 
## > sample.true <- year2013$interval
## 
## > diff <- 3.63 - 3.31
## 
## > pwr.test.results <- power.t.test(n = seq(1, 200, 1), 
## +     delta = diff, sd = sd(sample.true), alternative = "one.sided", 
## +     sig.level = 0.05)
\end{verbatim}

\begin{verbatim}
## Warning in qt(sig.level/tside, nu, lower.tail = FALSE): NaNs produced
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-10} \end{center}

\begin{verbatim}
## 
## > pwr.analysis <- as.data.frame(cbind(pwr.test.results$power, 
## +     pwr.test.results$n))
## 
## > colnames(pwr.analysis) <- c("Power", "Sample.size")
## 
## > pwr.analysis.1 <- pwr.analysis %>% mutate(Alpha = 1 - 
## +     Power)
## 
## > a <- filter(pwr.analysis.1, Alpha < 0.05)
## 
## > a[1, ]
##       Power Sample.size     Alpha
## 1 0.9503366         153 0.0496634
## 
## > ggplot(data = pwr.analysis.1, aes(x = Sample.size, 
## +     y = Alpha)) + geom_line(size = 1.5) + geom_vline(xintercept = 45, 
## +     col = "red") + ge .... [TRUNCATED]
\end{verbatim}

\begin{verbatim}
## Warning: Removed 1 rows containing missing values (geom_path).
\end{verbatim}

\begin{verbatim}
## 
## > dat <- read.csv("./R/Data/raw_observations_2012.csv")
## 
## > glimpse(dat)
## Observations: 180
## Variables: 10
## $ ID          <fct> AI06006, AI06007, AI06015, AI06022, AI06038, AI100...
## $ X2006       <int> 1, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2007       <int> 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2008       <int> 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,...
## $ X2009       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2010       <int> 0, 0, 2, 0, 0, 6, 6, 5, 5, 3, 4, 2, 5, 4, 5, 3, 2,...
## $ X2011       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2012       <int> 0, 1, 2, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 12, 0, 0, 0...
## $ total       <int> 2, 4, 8, 5, 3, 6, 7, 5, 5, 3, 9, 2, 5, 16, 6, 3, 2...
## $ X..yrs.seen <int> 2, 3, 5, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1,...
## 
## > head(dat)
##        ID X2006 X2007 X2008 X2009 X2010 X2011 X2012 total X..yrs.seen
## 1 AI06006     1     0     1     0     0     0     0     2           2
## 2 AI06007     2     1     0     0     0     0     1     4           3
## 3 AI06015     2     1     1     0     2     0     2     8           5
## 4 AI06022     1     0     0     0     0     0     4     5           2
## 5 AI06038     1     0     2     0     0     0     0     3           2
## 6 AI10040     0     0     0     0     6     0     0     6           1
## 
## > dat1 <- read.csv("./R/Data/RawCI.csv", header = T, 
## +     quote = "\"")
## 
## > glimpse(dat1)
## Observations: 41
## Variables: 8
## $ ID            <fct> AI10124, AI10070, AI10086, AI08340, AI08341, AI0...
## $ Yr.first.seen <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves        <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves.1      <int> 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, ...
## $ Calves.2      <int> 2013, 2013, 2013, NA, NA, NA, NA, NA, NA, NA, NA...
## $ Interval.1    <int> 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 6, ...
## $ Interval.2    <int> 3, 3, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ X             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
## 
## > dat3 <- dplyr::select(dat, ID, X2006:X2012) %>% gather(year, 
## +     count, X2006:X2012)
## 
## > dat4 <- full_join(dat3, dat1, by = "ID")
\end{verbatim}

\begin{verbatim}
## Warning: Column `ID` joining factors with different levels, coercing to
## character vector
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-11} \end{center}

\begin{verbatim}
## 
## > dat5 <- dplyr::select(dat4, ID, year, count, Yr.first.seen, 
## +     Calves, Calves.1, Calves.2)
## 
## > dat6 <- filter(dat5, count > 0)
## 
## > glimpse(dat6)
## Observations: 237
## Variables: 7
## $ ID            <chr> "AI06006", "AI06007", "AI06015", "AI06022", "AI0...
## $ year          <chr> "X2006", "X2006", "X2006", "X2006", "X2006", "X2...
## $ count         <int> 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
## $ Yr.first.seen <int> NA, NA, NA, 2006, NA, NA, NA, 2007, 2007, NA, NA...
## $ Calves        <int> NA, NA, NA, 2006, NA, NA, NA, 2007, 2007, NA, NA...
## $ Calves.1      <int> NA, NA, NA, 2012, NA, NA, NA, 2013, 2010, NA, NA...
## $ Calves.2      <int> NA, NA, NA, NA, NA, NA, NA, NA, 2013, NA, NA, 20...
## 
## > dat7 <- mutate(dat6, year = ifelse(year == "X2006", 
## +     "2006", year), year = ifelse(year == "X2007", "2007", year), 
## +     year = ifelse(year == .... [TRUNCATED] 
## 
## > a <- group_by(dat7, ID, Yr.first.seen) %>% mutate(mother = ifelse(Yr.first.seen > 
## +     0, 1, 0)) %>% filter(mother == 1) %>% ungroup() %>% dplyr:: .... [TRUNCATED] 
## 
## > a
## # A tibble: 1 x 4
##   ID      year  Calves Calves.1
##   <chr>   <chr>  <int>    <int>
## 1 AI09216 2007    2009     2011
## 
## > greater.than.2 <- sample.true[sample.true > 2]
## 
## > mean.2 <- sum(greater.than.2)/length(greater.than.2)
## 
## > s.2 <- sd(greater.than.2)
## 
## > SE.2 <- s2013/(sqrt(length(greater.than.2)))
## 
## > n.2 <- length(greater.than.2)
## 
## > low.qt.2 <- mean.2 - (qt(0.975, length(greater.than.2)) * 
## +     SE.2)
## 
## > high.qt.2 <- mean.2 + (qt(0.975, length(greater.than.2)) * 
## +     SE.2)
## 
## > Sumtable[4, ] <- c("miss2year", n.2, mean.2, low.qt.2, 
## +     high.qt.2, sd(greater.than.2))
## 
## > boots <- 1000
## 
## > n <- c(1:1000)
## 
## > detect1 <- 44
## 
## > detect2 <- 42
## 
## > detect3 <- 40
## 
## > sample2 <- rep(NA, 1000)
## 
## > sample5 <- rep(NA, 1000)
## 
## > sample10 <- rep(NA, 1000)
## 
## > for (i in 1:boots) {
## +     sample2[i] <- mean(sample(year2013$interval, detect1, replace = T))
## +     sample5[i] <- mean(sample(year2013$interval, de .... [TRUNCATED] 
## 
## > sample2 <- sort(sample2)
## 
## > sample2.2.5 <- sample2[25]
## 
## > sample2.50 <- sample2[500]
## 
## > sample2.975 <- sample2[975]
## 
## > sample5 <- sort(sample5)
## 
## > sample5.2.5 <- sample5[25]
## 
## > sample5.50 <- sample5[500]
## 
## > sample5.975 <- sample5[975]
## 
## > sample10 <- sort(sample10)
## 
## > sample10.2.5 <- sample10[25]
## 
## > sample10.50 <- sample10[500]
## 
## > sample10.975 <- sample10[975]
## 
## > Sumtable[5, ] <- c("detect1", detect1, sample2.50, 
## +     sample2.2.5, sample2.975, NA)
## 
## > Sumtable[6, ] <- c("detect2", detect2, sample5.50, 
## +     sample5.2.5, sample5.975, NA)
## 
## > Sumtable[7, ] <- c("detect5", detect3, sample10.50, 
## +     sample10.2.5, sample10.975, NA)
## 
## > length(Data$ID)
## [1] 41
## 
## > length(dat$ID)
## [1] 180
## 
## > glimpse(Data)
## Observations: 41
## Variables: 8
## $ ID            <fct> AI10124, AI10070, AI10086, AI08340, AI08341, AI0...
## $ Yr.first.seen <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves        <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves.1      <int> 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, ...
## $ Calves.2      <int> 2013, 2013, 2013, NA, NA, NA, NA, NA, NA, NA, NA...
## $ Interval.1    <int> 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 6, ...
## $ Interval.2    <int> 3, 3, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ X             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
## 
## > dat.detect <- dplyr::select(Data, ID, Calves, Calves.1, 
## +     Calves.2) %>% mutate(Calves = factor(Calves), Calves.1 = factor(Calves.1), 
## +     Cal .... [TRUNCATED] 
## 
## > a <- as.data.frame.matrix(table(Data$ID, Data$Calves))
## 
## > head(a)
##         2006 2007 2008 2009 2010 2011
## AI06022    1    0    0    0    0    0
## AI08340    0    0    1    0    0    0
## AI08341    0    0    1    0    0    0
## AI08343    0    0    1    0    0    0
## AI08355    0    0    1    0    0    0
## AI08362    0    0    1    0    0    0
## 
## > a[, 7] <- row.names(a)
## 
## > colnames(a)[1] <- "y2006"
## 
## > colnames(a)[2] <- "y2007"
## 
## > colnames(a)[3] <- "y2008"
## 
## > colnames(a)[4] <- "y2009"
## 
## > colnames(a)[5] <- "y2010"
## 
## > colnames(a)[6] <- "y2011"
## 
## > colnames(a)[7] <- "ID"
## 
## > a[, 8] <- 0
## 
## > colnames(a)[8] <- "y2012"
## 
## > a[, 9] <- 0
## 
## > colnames(a)[9] <- "y2013"
## 
## > a <- dplyr::select(a, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > b <- as.data.frame.matrix(table(Data$ID, Data$Calves.1))
## 
## > head(b)
##         2010 2011 2012 2013
## AI06022    0    0    1    0
## AI08340    0    1    0    0
## AI08341    0    1    0    0
## AI08343    0    0    0    1
## AI08355    0    1    0    0
## AI08362    0    1    0    0
## 
## > b[, 5] <- row.names(b)
## 
## > colnames(b)[5] <- "ID"
## 
## > b[, 6] <- 0
## 
## > colnames(b)[6] <- "y2006"
## 
## > b[, 7] <- 0
## 
## > colnames(b)[7] <- "y2007"
## 
## > b[, 8] <- 0
## 
## > colnames(b)[8] <- "y2008"
## 
## > b[, 9] <- 0
## 
## > colnames(b)[9] <- "y2009"
## 
## > colnames(b)[1] <- "y2010"
## 
## > colnames(b)[2] <- "y2011"
## 
## > colnames(b)[3] <- "y2012"
## 
## > colnames(b)[4] <- "y2013"
## 
## > b <- dplyr::select(b, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > c <- as.data.frame.matrix(table(Data$ID, Data$Calves.2))
## 
## > head(c)
##         2013
## AI06022    0
## AI08340    0
## AI08341    0
## AI08343    0
## AI08355    0
## AI08362    0
## 
## > colnames(c)[1] <- "y2013"
## 
## > c[, 2] <- row.names(c)
## 
## > colnames(c)[2] <- "ID"
## 
## > c[, 3] <- 0
## 
## > colnames(c)[3] <- "y2006"
## 
## > c[, 4] <- 0
## 
## > colnames(c)[4] <- "y2007"
## 
## > c[, 5] <- 0
## 
## > colnames(c)[5] <- "y2008"
## 
## > c[, 6] <- 0
## 
## > colnames(c)[6] <- "y2009"
## 
## > c[, 7] <- 0
## 
## > colnames(c)[7] <- "y2010"
## 
## > c[, 8] <- 0
## 
## > colnames(c)[8] <- "y2011"
## 
## > c[, 9] <- 0
## 
## > colnames(c)[9] <- "y2012"
## 
## > c <- dplyr::select(c, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > countdat <- rbind(a, b, c)
## 
## > glimpse(countdat)
## Observations: 123
## Variables: 9
## $ ID    <chr> "AI06022", "AI08340", "AI08341", "AI08343", "AI08355", "...
## $ y2006 <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2007 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2008 <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...
## $ y2009 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...
## $ y2010 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2011 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2012 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2013 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## 
## > full.dat <- group_by(countdat, ID) %>% summarise(y2006 = sum(y2006), 
## +     y2007 = sum(y2007), y2008 = sum(y2008), y2009 = sum(y2009), 
## +     y2010 .... [TRUNCATED] 
## 
## > 2012 - 2006
## [1] 6
## 
## > sort(Data$ID)
##  [1] AI06022 AI08340 AI08341 AI08343 AI08355 AI08362 AI08364 AI08365
##  [9] AI08372 AI08378 AI08379 AI08383 AI08386 AI08387 AI08390 AI08395
## [17] AI08403 AI09216 AI09217 AI09221 AI09224 AI09225 AI09247 AI09249
## [25] AI09259 AI09265 AI09289 AI10043 AI10056 AI10070 AI10085 AI10086
## [33] AI10102 AI10124 AI10144 AI10160 AI10167 AI10170 AI10177 AI11408
## [41] AI11430
## 41 Levels: AI06022 AI08340 AI08341 AI08343 AI08355 AI08362 ... AI11430
## 
## > filter(Data, ID == "AI06022")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI06022          2006   2006     2012       NA          6         NA NA
## 
## > filter(Data, ID == "AI08340")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI08340          2008   2008     2011       NA          3         NA NA
## 
## > filter(Data, ID == "AI08343")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI08343          2008   2008     2013       NA          5         NA NA
## 
## > head(Data)
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI10124          2007   2007     2010     2013          3          3 NA
## 2 AI10070          2008   2008     2010     2013          2          3 NA
## 3 AI10086          2007   2007     2010     2013          3          3 NA
## 4 AI08340          2008   2008     2011       NA          3         NA NA
## 5 AI08341          2008   2008     2011       NA          3         NA NA
## 6 AI08355          2008   2008     2011       NA          3         NA NA
## 
## > longer5.6 <- c(sample.true, 5, 6, 6)
## 
## > mean.56 <- sum(longer5.6)/length(longer5.6)
## 
## > s.56 <- sd(longer5.6)
## 
## > SE.56 <- s.56/(sqrt(length(longer5.6)))
## 
## > n.56 <- (length(longer5.6))
## 
## > low.qt.56 <- mean.56 - (qt(0.975, length(longer5.6)) * 
## +     SE.56)
## 
## > high.qt.56 <- mean.56 + (qt(0.975, length(longer5.6)) * 
## +     SE.56)
## 
## > Sumtable[8, ] <- c("longer.56", n.56, mean.56, low.qt.56, 
## +     high.qt.56, sd(longer5.6))
## 
## > Sumtable <- as.data.frame(Sumtable)
## 
## > Sumtable$n <- as.numeric(as.character(Sumtable$n))
## 
## > Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
## 
## > Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
## 
## > Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
## 
## > Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
## 
## > Sumtable$interval <- as.character(Sumtable$interval)
## 
## > library(knitr)
## 
## > kable(Sumtable, format = "markdown", col.names = c("Interval", 
## +     "Sample size", "Mean", "Lower limit", "Higher limit", "SD"))
## 
## 
## |Interval  | Sample size|     Mean| Lower limit| Higher limit|        SD|
## |:---------|-----------:|--------:|-----------:|------------:|---------:|
## |Low       |          58| 2.568966|    2.437666|     2.700265| 0.4995461|
## |Medium    |          48| 3.104167|    2.943089|     3.265244| 0.5550382|
## |Observed  |          45| 3.311111|    3.056488|     3.565734| 0.8480518|
## |miss2year |          41| 3.439024|    3.171549|     3.706499| 0.7761695|
## |detect1   |          44| 3.318182|    3.068182|     3.568182|        NA|
## |detect2   |          42| 3.285714|    3.071429|     3.571429|        NA|
## |detect5   |          40| 3.325000|    3.050000|     3.600000|        NA|
## |longer.56 |          48| 3.458333|    3.165307|     3.751360| 1.0097047|
## 
## > ggplot(Sumtable, aes(y = mY, x = interval)) + geom_point(size = 5) + 
## +     geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05, 
## +       .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-81-12} \end{center}

\hypertarget{plot-steps-1}{%
\subsection{Plot steps}\label{plot-steps-1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## ----raw graph, echo=FALSE, message=FALSE, warning=FALSE-----------------}
\CommentTok{#plot data}
\KeywordTok{ggplot}\NormalTok{(sum.dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ mY, }\DataTypeTok{x =}\NormalTok{ year)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ low.qt, }\DataTypeTok{ymax =}\NormalTok{ high.qt), }\DataTypeTok{width =} \FloatTok{0.1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-82-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ## ----raw graph 2, echo=FALSE, fig.height=6, fig.width=6, message=FALSE, warning=FALSE----}
\CommentTok{# }
\CommentTok{# #PLOTS}
\CommentTok{# par(mfrow=c(2,2))}
\CommentTok{# }
\CommentTok{# plot(factor(year2010),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="a)",sub="Sample size 3", ylab="Frequency",xlab="Calving interval",}
\CommentTok{#       cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2011),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="b)",sub="Sample size 15", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2012),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="c)",sub="Sample size 25", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2013),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="d)",sub="Sample size 45", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----raw graph 3, echo=FALSE, fig.height=6, fig.width=6, message=TRUE, warning=TRUE----}
\CommentTok{# library(qpcR)}
\CommentTok{# #data in one way for plot}
\CommentTok{# rawdata <- qpcR:::cbind.na(year2010,year2011,year2012,year2013)}
\CommentTok{# rawdata <- as.data.frame(rawdata)}
\CommentTok{# }
\CommentTok{# #in correct format for ggplot2}
\CommentTok{# year2010 <- data.frame(year2010,year = c("2010"))}
\CommentTok{# year2010 <- rename(year2010, interval = year2010, year = year )}
\CommentTok{# year2011 <- data.frame(year2011,year = c("2011"))}
\CommentTok{# year2011 <- rename(year2011, interval = year2011, year = year )}
\CommentTok{# year2012 <- data.frame(year2012,year = c("2012"))}
\CommentTok{# year2012 <- rename(year2012, interval = year2012, year = year )}
\CommentTok{# year2013 <- data.frame(year2013,year = c("2013"))}
\CommentTok{# year2013 <- rename(year2013, interval = year2013, year = year )}
\CommentTok{# ggplotraw <- rbind(year2010,year2011,year2012, year2013)}
\CommentTok{# ggplotraw$interval <- as.numeric(as.character(ggplotraw$interval))}
\CommentTok{# }
\CommentTok{# #sort(year2013$interval) - sort(sample.true)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ggplot(year2013,aes(x = interval)) +}
\CommentTok{#     geom_bar(alpha = 1, width = 0.9,fill = "black") +}
\CommentTok{#     xlab(expression("Calving"~"interval"~(italic("years")))) +}
\CommentTok{#     ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +}
\CommentTok{#     scale_y_continuous(breaks = c(0,5,10,15,20,25,30), limits = c(0,30)) +}
\CommentTok{#     theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black"))}
\CommentTok{# #PLOTS}
\CommentTok{# #code to store figure}
\CommentTok{# # png("Figure_2_NZSRW_calving_interval_2017_highres.png", width = 12, height = 14.8, units = 'cm', res = 1200)}
\CommentTok{# # dev.off()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals, echo=FALSE, fig.height=10, message=FALSE, warning=FALSE----}
\CommentTok{# #################################Missing calving intervals################}
\CommentTok{# #Intervals modified by accounting for missed intervals}
\CommentTok{# #Bradford et al. 2008}
\CommentTok{# }
\CommentTok{# #Raw Data}
\CommentTok{# RealCI <- as.numeric(year2013$interval)}
\CommentTok{# }
\CommentTok{# #Confidence interval}
\CommentTok{# xlong <- RealCI}
\CommentTok{# meanlong<-sum(xlong)/length(xlong)}
\CommentTok{# slong<-sd(xlong)}
\CommentTok{# SElong<-slong/(sqrt(length(xlong)))}
\CommentTok{# nlong<-(length(xlong))}
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# #2 sided t value at the 95% level = 2.093}
\CommentTok{# lowqtlong <- meanlong-(qt(0.975,nlong)*SElong)}
\CommentTok{# highqtlong <- meanlong+(qt(0.975,nlong)*SElong)}
\CommentTok{# }
\CommentTok{# ####################MED CI########################################}
\CommentTok{# # 2x 6's and 1x 5 replaced with 3threes}
\CommentTok{# MedCI <- c(RealCI[RealCI < 5],3,3,3,3,2,3)}
\CommentTok{# #sort(MedCI)}
\CommentTok{# xmed<-MedCI}
\CommentTok{# meanmed<-sum(xmed)/length(xmed)}
\CommentTok{# smed<-sd(xmed)}
\CommentTok{# SEmed<-smed/(sqrt(length(xmed)))}
\CommentTok{# nmed<-(length(xmed))}
\CommentTok{# }
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# lowqtmed <- meanmed-(qt(0.975,length(xmed))*SEmed)}
\CommentTok{# highqtmed <- meanmed+(qt(0.975,length(xmed))*SEmed)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ############################SHORT CI##################################}
\CommentTok{# #6,5 replaced with 2 year intervals}
\CommentTok{# }
\CommentTok{# LowCI <- c(RealCI[RealCI < 4],3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)}
\CommentTok{# xshort<-LowCI}
\CommentTok{# meanshort<-mean(xshort)}
\CommentTok{# sshort<-sd(xshort)}
\CommentTok{# SEshort<-sshort/(sqrt(length(xshort)))}
\CommentTok{# }
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# lowqtshort <- meanshort-(qt(0.975,length(xshort))*SEshort)}
\CommentTok{# highqtshort <- meanshort+(qt(0.975,length(xshort))*SEshort)}
\CommentTok{# }
\CommentTok{# bdata <-qpcR:::cbind.na(RealCI,MedCI,LowCI)}
\CommentTok{# bdata <- as.data.frame(bdata)}
\CommentTok{# }
\CommentTok{# #Structure of data set}
\CommentTok{# #str(bdata)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot, echo=FALSE, fig.height=3.5, fig.width=5.5, message=FALSE, warning=FALSE----}
\CommentTok{# #Basic plots}
\CommentTok{# par(mfrow=c(1,3))}
\CommentTok{# plot(factor(bdata$LowCI),main="Lowest possible interval")}
\CommentTok{# plot(factor(bdata$MedCI), main="Medium possible interval")}
\CommentTok{# plot(factor(bdata$RealCI),main="Observed interval")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot2, fig.height=5.5, fig.width=4.5, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# #Density basic plots}
\CommentTok{# par(mfrow=c(3,1))}
\CommentTok{# plot(density(as.numeric(as.character(LowCI)),bw=.5), main="Lowest possible interval")}
\CommentTok{# plot(density(as.numeric(as.character(MedCI)),bw= 0.5), main="Medium possible interval")}
\CommentTok{# plot(density(as.numeric(as.character(RealCI)),bw = 0.5),main="Observed interval")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals table, fig.height=8, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# }
\CommentTok{# ###################################SUMMARY############################}
\CommentTok{# #Pull out important information}
\CommentTok{# Sumtable<-data.frame(variable = c("low.qt","mean","high.qt","sd", "SE"),                 short=c(lowqtshort,meanshort,highqtshort,sshort,SEshort),}
\CommentTok{#                      medium=c(lowqtmed,meanmed,highqtmed,smed,SEmed),}
\CommentTok{#                      real=c(lowqtlong,meanlong,highqtlong,slong,SElong))}
\CommentTok{# }
\CommentTok{# #Make dataframe to plot}
\CommentTok{# n <- c(length(LowCI),length(MedCI),length(year2013$interval))}
\CommentTok{# mY <- c(mean(LowCI),mean(MedCI),mean(year2013$interval))}
\CommentTok{# interval <-c("Low", "Medium","Observed")}
\CommentTok{# low.qt <- c(lowqtshort,lowqtmed,low.qt2013)}
\CommentTok{# high.qt <- c(highqtshort,highqtmed,high.qt2013)}
\CommentTok{# sd <- c(sshort,smed,s2013)}
\CommentTok{# Sumtable <- cbind(interval,n,mY,low.qt,high.qt,sd)}
\CommentTok{# Sumtable <-  as.data.frame(Sumtable)}
\CommentTok{# }
\CommentTok{#  Sumtable$n <- as.numeric(as.character(Sumtable$n))}
\CommentTok{#  Sumtable$mY <- as.numeric(as.character(Sumtable$mY))}
\CommentTok{#  Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))}
\CommentTok{#  Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))}
\CommentTok{#  Sumtable$sd <- as.numeric(as.character(Sumtable$sd))}
\CommentTok{#  Sumtable$interval <- as.character(Sumtable$interval)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot3, echo=FALSE, fig.height=4, message=FALSE, warning=FALSE----}
\CommentTok{# ggplot(Sumtable, aes(y = mY, x = interval)) +}
\CommentTok{#   geom_point(size = 5) +}
\CommentTok{#   geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +}
\CommentTok{#   scale_y_continuous(breaks = round(seq(2.3, 3.6, by = 0.2),1)) +}
\CommentTok{#   labs(y = "Mean calving interval",x = "Calving interval modification" ) +}
\CommentTok{#   geom_point(size = 3) +}
\CommentTok{#   theme_classic() +}
\CommentTok{#   theme_hc() +}
\CommentTok{#   theme(legend.position="none")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing_data_table, echo=FALSE--------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# }
\CommentTok{# kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----srw_data_table, echo=FALSE------------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# setwd("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data")}
\CommentTok{# srwdat <- read.csv(file = "srw_data.csv")}
\CommentTok{# }
\CommentTok{# #str(srwdat)}
\CommentTok{# kable(srwdat, format = "markdown",col.names = c("Sample size","Mean", "Lower limit", "Higher limit", "SE","Author", "Location"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap single, echo=FALSE, fig.height=5--------------------------}
\CommentTok{# ############################NZ Simple sample##############################}
\CommentTok{# #WITH replacement}
\CommentTok{# }
\CommentTok{# # to try and match number of intervals observed in other populations}
\CommentTok{# # find references}
\CommentTok{# SAreps <- 1500}
\CommentTok{# ARreps <- 800}
\CommentTok{# Aussiereps <- 2000}
\CommentTok{# low <- 1000}
\CommentTok{# verylow <- 100}
\CommentTok{# lowest <- 10}
\CommentTok{# }
\CommentTok{# #Very raw plots}
\CommentTok{# par(mfrow=c(2,3))}
\CommentTok{# plot(factor(sample(year2013$interval,lowest,replace=T)),main = "3 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,verylow,replace=T)),main = "10 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,low,replace=T)),main = "30 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,Aussiereps,replace=T)),main = "500 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,ARreps,replace=T)),main = "800 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,SAreps,replace=T)),main = "1500 intervals")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap_multiple, echo=FALSE--------------------------------------}
\CommentTok{# #do each one 1000 times}
\CommentTok{# boots <- 1000}
\CommentTok{# n <- c(1:1000)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ###########################n10}
\CommentTok{# var10 <- paste0("n_", 1:10)}
\CommentTok{# sample10 <-matrix(data = NA, ncol = lowest, nrow = boots)}
\CommentTok{# colnames(sample10) <- as.list(var10)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample10 [i, ] <- sample(year2013$interval,lowest,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample10 <- as.data.frame(sample10)}
\CommentTok{# sample10 <- sample10 %>%}
\CommentTok{#             mutate(mean10 = rowMeans(sample10))}
\CommentTok{# }
\CommentTok{# sample10t <- as.matrix(sample10)}
\CommentTok{# sample10t <-t(sample10t)}
\CommentTok{# }
\CommentTok{# #########################verylow sample size}
\CommentTok{# #set up variable names}
\CommentTok{# var100 <- paste0("n_", 1:100)}
\CommentTok{# }
\CommentTok{# sample100 <-matrix(data = NA, ncol = verylow, nrow = boots)}
\CommentTok{# colnames(sample100) <- as.list(var100)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample100 [i, ] <- sample(year2013$interval,verylow,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample100 <- as.data.frame(sample100)}
\CommentTok{# sample100 <- sample100 %>%}
\CommentTok{#             mutate(mean100 = rowMeans(sample100))}
\CommentTok{# }
\CommentTok{# #########################middle one}
\CommentTok{# #set up variable names}
\CommentTok{# var500 <- paste0("n_", 1:500)}
\CommentTok{# }
\CommentTok{# sample500 <-matrix(data = NA, ncol = 500, nrow = boots)}
\CommentTok{# colnames(sample500) <- as.list(var500)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample500 [i, ] <- sample(year2013$interval,500,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample500 <- as.data.frame(sample500)}
\CommentTok{# sample500 <- sample500 %>%}
\CommentTok{#             mutate(mean500 = rowMeans(sample500))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #########################low sample size}
\CommentTok{# #set up variable names}
\CommentTok{# var1000 <- paste0("n_", 1:1000)}
\CommentTok{# }
\CommentTok{# sample1000 <-matrix(data = NA, ncol = low, nrow = boots)}
\CommentTok{# colnames(sample1000) <- as.list(var1000)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample1000 [i, ] <- sample(year2013$interval,low,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample1000 <- as.data.frame(sample1000)}
\CommentTok{# sample1000 <- sample1000 %>%}
\CommentTok{#             mutate(mean1000 = rowMeans(sample1000))}
\CommentTok{# }
\CommentTok{# #########################AUS sample size}
\CommentTok{# #set up variable names}
\CommentTok{# varA <- paste0("n_", 1:2000)}
\CommentTok{# }
\CommentTok{# sampleA <-matrix(data = NA, ncol = Aussiereps, nrow =  boots)}
\CommentTok{# colnames(sampleA) <- as.list(varA)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sampleA [i, ] <- sample(year2013$interval,Aussiereps,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sampleA <- as.data.frame(sampleA)}
\CommentTok{# sampleA <- sampleA %>%}
\CommentTok{#             mutate(meanA = rowMeans(sampleA))}
\CommentTok{# }
\CommentTok{# sampleAt <- t(sampleA)}
\CommentTok{# }
\CommentTok{# for(i in c(1:ncol(sampleA))) \{}
\CommentTok{#     sampleA[,i] <- as.numeric(as.character(sampleA[,i]))}
\CommentTok{# \}}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #COnfidence intervals}
\CommentTok{# }
\CommentTok{# ab <- sort(sampleA$meanA)}
\CommentTok{# nab <- length(ab)}
\CommentTok{# #low = 25/1000}
\CommentTok{# ab2.5 <- ab[25]}
\CommentTok{# #high = 975/1000}
\CommentTok{# ab0.97.5 <- ab[975]}
\CommentTok{# }
\CommentTok{# ab <- sort(sampleA$meanA)}
\CommentTok{# nab <- length(ab)}
\CommentTok{# #low = 25/1000}
\CommentTok{# ab2.5 <- ab[25]}
\CommentTok{# #high = 975/1000}
\CommentTok{# ab0.97.5 <- ab[975]}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap plot2, fig.height=5, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# #plot the data over each other to look at change in density}
\CommentTok{# par(mfrow=c(1,1))}
\CommentTok{# #plot(density(sample3$mean3,bw = .15),lwd = 3,lyt = 5, main = "", xlab = "Calving interval", box = FALSE,axis = FALSE)}
\CommentTok{# }
\CommentTok{# plot(density(sample10$mean10,bw = .05),col ="black", lty = 1, main = "", lwd = 5,ylim = c(0,8),xlim = c(2,4.5), axes=FALSE,xlab = "Calving interval")}
\CommentTok{# lines(density(sample100$mean100,bw = .05),col ="black", lty = 2, lwd = 4)}
\CommentTok{# lines(density(sample500$mean500,bw = .05),col ="black", lty = 3, lwd = 3)}
\CommentTok{# lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 4, lwd = 2)}
\CommentTok{# lines(density(sampleA$meanA,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# legend('topright',title = "Legend", c("n=10, cv=8.12 ", "n=100, cv=2.43", "n=500, c.v=1.15", "n=1000, cv=0.79", "n=2000, cv=0.56"),bty = "n",}
\CommentTok{#   lty = c(1,2,3,4,5), lwd = c(5,4,3,2,1), cex=.75)}
\CommentTok{# axis(1,lwd=2)}
\CommentTok{# axis(2,lwd=2)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----final plot for publication1, echo=FALSE-----------------------------}
\CommentTok{# #final [plot]}
\CommentTok{# #size defined by NZJFMR}
\CommentTok{# #  195 mm (h) ? 148 mm (w).}
\CommentTok{# #ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +}
\CommentTok{# }
\CommentTok{# plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE, xlab = expression("Calving"~"interval"~(italic("years"))))}
\CommentTok{# lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)}
\CommentTok{# lines(density(sample500$mean500,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 2, lwd = 1)}
\CommentTok{# lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)}
\CommentTok{# legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",}
\CommentTok{#   lty = c(3,4,5,2,1), lwd = c(1,1,1,1,2), cex=1)}
\CommentTok{#  axis(1,lwd=2)}
\CommentTok{# axis(2,lwd=2)}
\CommentTok{# }
\CommentTok{# # PLOT CODE FOR PUBLICATION}
\CommentTok{# # png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_lowres.png", width = 14.8, height = 14.8, units = 'cm', res = 400)}
\CommentTok{# # dev.off()}
\CommentTok{# #}
\CommentTok{# #}
\CommentTok{# # png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_highres.png", width = 14.8, height = 14.8, units = 'cm', res = 1200)}
\CommentTok{# #}
\CommentTok{# # plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE,xlab = expression("Calving"~"interval"~(italic("years"))))}
\CommentTok{# # lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)}
\CommentTok{# # lines(density(sample500$mean500,bw = .05),col ="black", lty = 2, lwd = 1)}
\CommentTok{# # lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# # lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)}
\CommentTok{# # legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",}
\CommentTok{# #   lty = c(3,4,2,5,1), lwd = c(1,1,1,1,2), cex=1)}
\CommentTok{# # axis(1,lwd=2)}
\CommentTok{# # axis(2,lwd=2)}
\CommentTok{# #}
\CommentTok{# # dev.off()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_1, echo=TRUE----------------------------------------}
\CommentTok{# #observed sample}
\CommentTok{# rev.one <- bdata$RealCI[1:45]}
\CommentTok{# }
\CommentTok{# #sample 45 times}
\CommentTok{# sample.true <- year2013$interval}
\CommentTok{# }
\CommentTok{# #power analysis}
\CommentTok{# pwr.test.results <- power.t.test(n = 45,# sample size}
\CommentTok{#              delta = seq(0,0.99,0.001),  #difference between means}
\CommentTok{#              sd = sd(sample.true),      #observed variation}
\CommentTok{#              alternative = "one.sided", #observed test type}
\CommentTok{#              sig.level = 0.05)          #significance level}
\CommentTok{# }
\CommentTok{# #additional packages are avaliable for more complex analysis}
\CommentTok{# #but have not done this as don't think it is needed}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_1_plot, echo=FALSE, message=FALSE, warning=FALSE----}
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis <- as.data.frame(cbind(}
\CommentTok{#                               pwr.test.results$power,}
\CommentTok{#                               pwr.test.results$delta))}
\CommentTok{# }
\CommentTok{# colnames(pwr.analysis) <- c("Power","Mean.difference")}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis.1 <- pwr.analysis %>%}
\CommentTok{#   mutate(Alpha = 1- Power,}
\CommentTok{#          Mean.estimate = 3.31 + Mean.difference)}
\CommentTok{# # %>%}
\CommentTok{# #   select(Alpha,Mean.estimate)}
\CommentTok{# }
\CommentTok{# #work out where the cut-off is}
\CommentTok{# a <- filter(pwr.analysis.1, Alpha < 0.05)}
\CommentTok{# a[1,]}
\CommentTok{# }
\CommentTok{# #plot data}
\CommentTok{# ggplot(data = pwr.analysis.1, aes(x = Mean.estimate, y = Alpha)) +}
\CommentTok{#   geom_line(size = 1.5) +}
\CommentTok{#   geom_vline(xintercept = 3.903, col = "blue") +}
\CommentTok{#   geom_hline(yintercept = 0.05) +}
\CommentTok{#   theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black")) +}
\CommentTok{#   ggtitle("Raw data result plot (n = 45)")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_2_plot, echo=FALSE, message=FALSE, warning=FALSE----}
\CommentTok{# #observed sample}
\CommentTok{# rev.one <- bdata$RealCI[1:45]}
\CommentTok{# }
\CommentTok{# #sample 45 times}
\CommentTok{# sample.true <- year2013$interval}
\CommentTok{# }
\CommentTok{# #difference}
\CommentTok{# diff <- 3.63-3.31  #observed mean of australian population}
\CommentTok{# }
\CommentTok{# #power analysis}
\CommentTok{# pwr.test.results <- power.t.test(n = seq(1,200,1),# sample size}
\CommentTok{#              delta = diff,  #difference between means}
\CommentTok{#              sd = sd(sample.true),      #observed variation}
\CommentTok{#              alternative = "one.sided", #observed test type}
\CommentTok{#              sig.level = 0.05)          #significance level}
\CommentTok{# }
\CommentTok{# #additional packages are avaliable for more complex analysis}
\CommentTok{# #but have not done this as don't think it is needed}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis <- as.data.frame(cbind(}
\CommentTok{#                               pwr.test.results$power,}
\CommentTok{#                               pwr.test.results$n))}
\CommentTok{# }
\CommentTok{# colnames(pwr.analysis) <- c("Power","Sample.size")}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis.1 <- pwr.analysis %>%}
\CommentTok{#   mutate(Alpha = 1- Power)}
\CommentTok{# # %>%}
\CommentTok{# #   select(Alpha,Mean.estimate)}
\CommentTok{# }
\CommentTok{# #work out where the cut-off is}
\CommentTok{# a <- filter(pwr.analysis.1, Alpha < 0.05)}
\CommentTok{# a[1,]}
\CommentTok{# }
\CommentTok{# #plot data}
\CommentTok{# ggplot(data = pwr.analysis.1, aes(x = Sample.size, y = Alpha)) +}
\CommentTok{#   geom_line(size = 1.5) +}
\CommentTok{#   geom_vline(xintercept = 45, col = "red") +}
\CommentTok{#   geom_vline(xintercept = 153, col = "blue") +}
\CommentTok{#   geom_hline(yintercept = 0.05) +}
\CommentTok{#   scale_y_continuous(limits = c(0,1)) +}
\CommentTok{#   theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black")) +}
\CommentTok{#    ggtitle("Observed difference between Australian and NZ mean")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missed individuals 1, echo=FALSE------------------------------------}
\CommentTok{# dat <- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/raw_observations_2012.csv")}
\CommentTok{# #data structure}
\CommentTok{# glimpse(dat)}
\CommentTok{# head(dat)}
\CommentTok{# #And the second dataset}
\CommentTok{# dat1<- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/RawCI.csv", header=T, quote="\textbackslash{}"")}
\CommentTok{# #data structure}
\CommentTok{# glimpse(dat1)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missed individuals 2, echo=FALSE, message=FALSE, warning=FALSE------}
\CommentTok{# ##I can then modify this data to}
\CommentTok{# #restructure dataset of capture to long dataset}
\CommentTok{# dat3 <- dplyr::select(dat, ID, X2006:X2012)%>%}
\CommentTok{#                gather(year, count,X2006:X2012)}
\CommentTok{# }
\CommentTok{# #add data on calves}
\CommentTok{# dat4 <- full_join(dat3,dat1, by = "ID")}
\CommentTok{# dat5 <- dplyr::select(dat4,ID,year,count,Yr.first.seen,Calves,Calves.1,Calves.2)}
\CommentTok{# }
\CommentTok{# dat6 <- filter(dat5,count >0)}
\CommentTok{# glimpse(dat6)}
\CommentTok{# }
\CommentTok{# dat7 <- mutate(dat6, year = ifelse(year == "X2006","2006", year),}
\CommentTok{#             year = ifelse(year == "X2007","2007", year),}
\CommentTok{#             year = ifelse(year == "X2008","2008", year),}
\CommentTok{#             year = ifelse(year == "X2009","2009", year),}
\CommentTok{#             year = ifelse(year == "X2010","2010", year),}
\CommentTok{#             year = ifelse(year == "X2011","2011", year),}
\CommentTok{#             year = ifelse(year == "X2012","2012", year))}
\CommentTok{# }
\CommentTok{# a <- group_by(dat7, ID, Yr.first.seen) %>%}
\CommentTok{#   mutate(mother = ifelse(Yr.first.seen > 0, 1, 0)) %>%}
\CommentTok{#   filter(mother == 1) %>%}
\CommentTok{#   ungroup() %>%}
\CommentTok{#   dplyr::select(ID,year,Calves,Calves.1) %>%}
\CommentTok{#   filter(Calves.1<2013) %>%}
\CommentTok{#   filter(!year == Calves) %>%}
\CommentTok{# filter(!year ==Calves.1)}
\CommentTok{# }
\CommentTok{# a}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment3, echo=TRUE, message=FALSE, warning=FALSE-----------}
\CommentTok{# greater.than.2 <- sample.true[sample.true>2]}
\CommentTok{# }
\CommentTok{# #greater.than.2}
\CommentTok{# mean.2<-sum(greater.than.2)/length(greater.than.2)}
\CommentTok{# s.2<-sd(greater.than.2)}
\CommentTok{# SE.2<-s2013/(sqrt(length(greater.than.2)))}
\CommentTok{# n.2<-length(greater.than.2)}
\CommentTok{# low.qt.2<- mean.2-(qt(0.975,length(greater.than.2))*SE.2)}
\CommentTok{# high.qt.2 <- mean.2+(qt(0.975,length(greater.than.2))*SE.2)}
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[4,] <- c("miss2year",n.2,mean.2,low.qt.2,}
\CommentTok{#                   high.qt.2,sd(greater.than.2))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----different missing intervals 1, echo=TRUE----------------------------}
\CommentTok{# ########################### 2.2%}
\CommentTok{# #parameters}
\CommentTok{# boots <- 1000}
\CommentTok{# n <- c(1:1000)}
\CommentTok{# }
\CommentTok{# ###round all percentages upwards}
\CommentTok{# detect1 <- 44  # (45*1.02) - 45 = 0.9}
\CommentTok{# detect2 <- 42   #  (45*1.05) - 45 = 2.25}
\CommentTok{# detect3 <- 40  # (45*1.10) - 45 = 4.5}
\CommentTok{# }
\CommentTok{# sample2 <-rep(NA, 1000)}
\CommentTok{# sample5 <-rep(NA, 1000)}
\CommentTok{# sample10 <-rep(NA, 1000)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample2[i]<-mean(sample(year2013$interval,detect1,replace=T))}
\CommentTok{#                     sample5[i]<-mean(sample(year2013$interval,detect2,replace=T))}
\CommentTok{#                     sample10[i]<-mean(sample(year2013$interval,detect3,replace=T))}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# ######################estimates##############}
\CommentTok{# sample2 <- sort(sample2)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample2.2.5 <- sample2[25]}
\CommentTok{# #median}
\CommentTok{# sample2.50 <- sample2[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample2.975 <- sample2[975]}
\CommentTok{# }
\CommentTok{# sample5 <- sort(sample5)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample5.2.5 <- sample5[25]}
\CommentTok{# #median}
\CommentTok{# sample5.50 <- sample5[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample5.975 <- sample5[975]}
\CommentTok{# }
\CommentTok{# sample10 <- sort(sample10)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample10.2.5 <- sample10[25]}
\CommentTok{# #median}
\CommentTok{# sample10.50 <- sample10[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample10.975 <- sample10[975]}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[5,] <- c("detect1",detect1,sample2.50,sample2.2.5,sample2.975,NA)}
\CommentTok{# Sumtable[6,] <- c("detect2",detect2,sample5.50,sample5.2.5,sample5.975,NA)}
\CommentTok{# Sumtable[7,] <- c("detect5",detect3,sample10.50,sample10.2.5,sample10.975,NA)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----detection sim.2-----------------------------------------------------}
\CommentTok{# }
\CommentTok{# #be very careful as Dat is just IDS and no id of females with calves}
\CommentTok{# #BUT Data is identified females...}
\CommentTok{# length(Data$ID)}
\CommentTok{# length(dat$ID)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# glimpse(Data)}
\CommentTok{# dat.detect <- dplyr::select(Data,ID,Calves,Calves.1, Calves.2) %>%}
\CommentTok{#                   mutate(Calves = factor(Calves),}
\CommentTok{#                          Calves.1 = factor(Calves.1),}
\CommentTok{#                          Calves.2 = factor(Calves.2))}
\CommentTok{# }
\CommentTok{# a <- as.data.frame.matrix(table(Data$ID,Data$Calves))}
\CommentTok{# head(a)}
\CommentTok{# a[,7] <-row.names(a)}
\CommentTok{# colnames(a)[1] <- "y2006"}
\CommentTok{# colnames(a)[2] <- "y2007"}
\CommentTok{# colnames(a)[3] <- "y2008"}
\CommentTok{# colnames(a)[4] <- "y2009"}
\CommentTok{# colnames(a)[5] <- "y2010"}
\CommentTok{# colnames(a)[6] <- "y2011"}
\CommentTok{# colnames(a)[7] <- "ID"}
\CommentTok{# a[,8] <- 0}
\CommentTok{# colnames(a)[8] <- "y2012"}
\CommentTok{# a[,9] <- 0}
\CommentTok{# colnames(a)[9] <- "y2013"}
\CommentTok{# a <- dplyr::select(a,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012, y2013)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# b <- as.data.frame.matrix(table(Data$ID,Data$Calves.1))}
\CommentTok{# head(b)}
\CommentTok{# b[,5] <-row.names(b)}
\CommentTok{# colnames(b)[5] <- "ID"}
\CommentTok{# b[,6] <- 0}
\CommentTok{# colnames(b)[6] <- "y2006"}
\CommentTok{# b[,7] <- 0}
\CommentTok{# colnames(b)[7] <- "y2007"}
\CommentTok{# b[,8] <- 0}
\CommentTok{# colnames(b)[8] <- "y2008"}
\CommentTok{# b[,9] <- 0}
\CommentTok{# colnames(b)[9] <- "y2009"}
\CommentTok{# colnames(b)[1] <- "y2010"}
\CommentTok{# colnames(b)[2] <- "y2011"}
\CommentTok{# colnames(b)[3] <- "y2012"}
\CommentTok{# colnames(b)[4] <- "y2013"}
\CommentTok{# b <- dplyr::select(b,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012, y2013)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# c <- as.data.frame.matrix(table(Data$ID,Data$Calves.2))}
\CommentTok{# head(c)}
\CommentTok{# colnames(c)[1] <- "y2013"}
\CommentTok{# c[,2] <-row.names(c)}
\CommentTok{# colnames(c)[2] <- "ID"}
\CommentTok{# c[,3] <- 0}
\CommentTok{# colnames(c)[3] <- "y2006"}
\CommentTok{# c[,4] <- 0}
\CommentTok{# colnames(c)[4] <- "y2007"}
\CommentTok{# c[,5] <- 0}
\CommentTok{# colnames(c)[5] <- "y2008"}
\CommentTok{# c[,6] <- 0}
\CommentTok{# colnames(c)[6] <- "y2009"}
\CommentTok{# c[,7] <- 0}
\CommentTok{# colnames(c)[7] <- "y2010"}
\CommentTok{# c[,8] <- 0}
\CommentTok{# colnames(c)[8] <- "y2011"}
\CommentTok{# c[,9] <- 0}
\CommentTok{# colnames(c)[9] <- "y2012"}
\CommentTok{# }
\CommentTok{# c <- dplyr::select(c,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012,y2013)}
\CommentTok{# }
\CommentTok{# countdat <- rbind(a,b,c)}
\CommentTok{# glimpse(countdat)}
\CommentTok{# head(full.dat)}
\CommentTok{# }
\CommentTok{# full.dat <- group_by(countdat, ID) %>%}
\CommentTok{#   summarise(y2006 = sum(y2006),}
\CommentTok{#             y2007 = sum(y2007),}
\CommentTok{#             y2008 = sum(y2008),}
\CommentTok{#             y2009 = sum(y2009),}
\CommentTok{#             y2010 = sum(y2010),}
\CommentTok{#             y2011 = sum(y2011),}
\CommentTok{#             y2012 = sum(y2012),}
\CommentTok{#             y2013 = sum(y2013))}
\CommentTok{# }
\CommentTok{# 2012-2006}
\CommentTok{# }
\CommentTok{# ##checking....}
\CommentTok{# }
\CommentTok{# sort(Data$ID)}
\CommentTok{# filter(Data, ID == "AI06022")}
\CommentTok{# filter(Data, ID == "AI08340")}
\CommentTok{# filter(Data, ID == "AI08343")}
\CommentTok{# }
\CommentTok{# head(Data)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# # glimpse(c)}
\CommentTok{# # Data$Calves.1,}
\CommentTok{# # # Spread and gather are complements}
\CommentTok{# # df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))}
\CommentTok{# # df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----different missing intervals 2---------------------------------------}
\CommentTok{# longer5.6 <- c(sample.true,5,6,6)}
\CommentTok{# }
\CommentTok{# #greater.than.2}
\CommentTok{# mean.56<-sum(longer5.6)/length(longer5.6)}
\CommentTok{# s.56<-sd(longer5.6)}
\CommentTok{# SE.56<-s.56/(sqrt(length(longer5.6)))}
\CommentTok{# n.56<-(length(longer5.6))}
\CommentTok{# low.qt.56<- mean.56-(qt(0.975,length(longer5.6))*SE.56)}
\CommentTok{# high.qt.56 <- mean.56+(qt(0.975,length(longer5.6))*SE.56)}
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[8,] <- c("longer.56",n.56,mean.56,low.qt.56,high.qt.56,sd(longer5.6))}
\CommentTok{# }
\CommentTok{# ###sort out numbering in dataframe}
\CommentTok{# Sumtable <-  as.data.frame(Sumtable)}
\CommentTok{# }
\CommentTok{#  Sumtable$n <- as.numeric(as.character(Sumtable$n))}
\CommentTok{#  Sumtable$mY <- as.numeric(as.character(Sumtable$mY))}
\CommentTok{#  Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))}
\CommentTok{#  Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))}
\CommentTok{#  Sumtable$sd <- as.numeric(as.character(Sumtable$sd))}
\CommentTok{#  Sumtable$interval <- as.character(Sumtable$interval)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing_data_table 2, echo=FALSE------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# }
\CommentTok{# kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment3_plot, echo=FALSE-----------------------------------}
\CommentTok{# ggplot(Sumtable, aes(y = mY, x = interval)) +}
\CommentTok{#   geom_point(size = 5) +}
\CommentTok{#   geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +}
\CommentTok{#   scale_y_continuous(breaks = round(seq(2.3, 5, by = 0.2),1)) +}
\CommentTok{#   labs(y = "Mean calving interval",x = "Calving interval modification" ) +}
\CommentTok{#   geom_point(size = 3) +}
\CommentTok{#   theme_classic() +}
\CommentTok{#   theme_hc() +}
\CommentTok{#   theme(legend.position="none")}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{exercise-4-1}{%
\section{Exercise 4}\label{exercise-4-1}}

In these exercises, you will be adapting the code written in this chapter to investigate slightly different questions. You should create a new R script \texttt{Ex4.R} in your working directory for these exercises so your chapter code is left unchanged. Exercise 4A is based solely on the required material and Exercises 4B - 4F are based on the example cases. You should work through each example before attempting each of the later exercises.

\emph{The solutions to this exercise are found at the end of this book (\protect\hyperlink{ex4a-answers}{here}). You are \textbf{strongly recommended} to make a good attempt at completing this exercise on your own and only look at the solutions when you are truly stumped.}

\hypertarget{exercise-4a-required-material-only-1}{%
\subsection*{Exercise 4A: Required Material Only}\label{exercise-4a-required-material-only-1}}
\addcontentsline{toc}{subsection}{Exercise 4A: Required Material Only}

These questions are based on the material in Sections \ref{randomness} - \ref{mc-summaries} only.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate flipping an unfair coin (probability of heads = 0.6) 100 times using \texttt{rbinom()}. Count the number of heads and tails.
\item
  Simulate flipping the same unfair coin 100 times, but using \texttt{sample()} instead. Determine what fraction of the flips resulted in heads.
\item
  Simulate rolling a fair 6-sided die 100 times using \texttt{sample()}. Determine what fraction of the rolls resulted in an even number.
\item
  Simulate rolling the same die 100 times, but use the function \texttt{rmultinom()} instead. Look at the help file for details on how to use this function. Determine what fraction of the rolls resulted in an odd number.
\end{enumerate}

\protect\hyperlink{ex4a-answers}{Solutions}

\hypertarget{exercise-4b-test-rnorm-1}{%
\subsection*{\texorpdfstring{Exercise 4B: Test \texttt{rnorm}}{Exercise 4B: Test rnorm}}\label{exercise-4b-test-rnorm-1}}
\addcontentsline{toc}{subsection}{Exercise 4B: Test \texttt{rnorm}}

These questions will require you to adapt the code written in Section \ref{rnorm-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adapt this example to investigate another univariate probability distribution, like \texttt{-lnorm()}, \texttt{-pois()}, or \texttt{-beta()}. See the help files (e.g., \texttt{?rpois}) for details on how to use each function.
\end{enumerate}

\protect\hyperlink{ex4b-answers}{Solutions}

\hypertarget{exercise-4c-stochastic-power-analysis-1}{%
\subsection*{Exercise 4C: Stochastic Power Analysis}\label{exercise-4c-stochastic-power-analysis-1}}
\addcontentsline{toc}{subsection}{Exercise 4C: Stochastic Power Analysis}

These questions will require you to adapt the code written in Section \ref{power-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What sample size \texttt{n} do you need to have a power of 0.8 of detecting a significant difference between the two tagging methods?
\item
  How do the inferences from the power analysis change if you are interested in \texttt{p\_new\ =\ 0.4} instead of \texttt{p\_new\ =\ 0.25}? Do you need to tag more or fewer fish in this case?
\item
  Your analysis takes a bit of time to run so you are interested in tracking its progress. Add a progress message to your nested \texttt{for()} loop that will print the sample size currently being analyzed:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}r}\StringTok{"}\NormalTok{, }\StringTok{"Sample Size = "}\NormalTok{, n_try[n])}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{I) \{}
\NormalTok{    ...}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\protect\hyperlink{ex4c-answers}{Solutions}

\hypertarget{exercise-4d-harvest-policy-analysis-1}{%
\subsection*{Exercise 4D: Harvest Policy Analysis}\label{exercise-4d-harvest-policy-analysis-1}}
\addcontentsline{toc}{subsection}{Exercise 4D: Harvest Policy Analysis}

These questions will require you to adapt the code written in Section \ref{harv-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add an argument to \texttt{ricker\_sim()} that will give the user an option to create a plot that shows the time series of recruitment, harvest, and escapement all on the same plot. Set the default to be to not plot the result, in case you forget to turn it off before performing the Monte Carlo analysis.
\item
  Add an \emph{error handler} to \texttt{ricker\_sim()} that will cause the function to return an error \texttt{if()} the names of the vector passed to the \texttt{param} argument aren't what the function is expecting. You can use \texttt{stop("Error\ Message\ Goes\ Here")} to have your function stop and return an error.
\item
  How do the results of the trade-off analysis differ if the process error was larger (a larger value of \(\sigma\))?
\item
  Add implementation error to the harvest policy. That is, if the target exploitation rate is \(U\), make the real exploitation rate in year \(y\) be: \(U_y \sim Beta(a,b)\), where \(a = 100U\) and \(b = 100(1-U)\). You can make there be more implementation error by inserting a smaller number other than 100 here. How does this affect the trade-off analysis?
\end{enumerate}

\protect\hyperlink{ex4d-answers}{Solutions}

\hypertarget{exercise-4e-the-bootstrap-1}{%
\subsection*{Exercise 4E: The Bootstrap}\label{exercise-4e-the-bootstrap-1}}
\addcontentsline{toc}{subsection}{Exercise 4E: The Bootstrap}

These questions will require you to adapt the code written in Section \ref{boot-test-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replicate the bootstrap analysis, but adapt it for the linear regression example in Section \ref{regression}. Stop at the step where you summarize the 95\% interval range.
\item
  Compare the 95\% bootstrap confidence intervals to the intervals you get by running the \texttt{predict()} function on the original data set with the argument \texttt{interval\ =\ "confidence"}.
\end{enumerate}

\protect\hyperlink{ex4e-answers}{Solutions}

\hypertarget{exercise-4f-permutation-tests-1}{%
\subsection*{Exercise 4F: Permutation Tests}\label{exercise-4f-permutation-tests-1}}
\addcontentsline{toc}{subsection}{Exercise 4F: Permutation Tests}

These questions will require you to adapt the code written in Section \ref{perm-test-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adapt the code to perform a permutation test for the difference in each of the zooplankton densities between treatments. Don't forget to fix the missing value in the \texttt{chao} variable. See \protect\hyperlink{ex1b}{Exercise 2} for more details on this.
\item
  Adapt the code to perform a permutation test for another data set used in this book where there are observations of both a categorical variable and a continuous variable. The data sets \texttt{sockeye.csv}, \texttt{growth.csv}, or \texttt{creel.csv} should be good starting points.
\item
  Add a calculation of the p-value for a one-tailed test (i.e., that the difference in means is greater or less than zero). Steps 1 - 4 are the same: all you need is \texttt{Dnull} and \texttt{Dobs}. Don't be afraid to Google this if you are confused.
\end{enumerate}

\protect\hyperlink{ex4f-answers}{Solutions}

\hypertarget{ch6}{%
\chapter{Matrix population models}\label{ch6}}

\hypertarget{sim-examples}{%
\chapter{Simulation-Based Examples}\label{sim-examples}}

\hypertarget{rnorm-ex}{%
\subsection{\texorpdfstring{Test \texttt{rnorm}}{Test rnorm}}\label{rnorm-ex}}

In this example, you will verify that the function \texttt{rnorm()} works the same way that \texttt{qnorm()} and \texttt{pnorm()} indicate that it should work. That is, you will verify that random deviates generated using \texttt{rnorm()} have the same properties as the true normal distribution given by \texttt{qnorm()} and \texttt{pnorm()}. Hopefully it will also reinforce the way the random, quantile, and cumulative distribution functions work in R.

First, specify the mean and standard deviation for this example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu =}\StringTok{ }\DecValTok{500}\NormalTok{; sig =}\StringTok{ }\DecValTok{30}
\end{Highlighting}
\end{Shaded}

Now make up \texttt{n} (any number of your choosing, something greater than 10) random deviates from this normal distribution:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{random =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, mu, sig)}
\end{Highlighting}
\end{Shaded}

Test the quantiles (obtain the values that \texttt{p} * 100\% of the quantities fall below, both for random numbers and from the \texttt{qnorm()} function):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.99}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\NormalTok{random_q =}\StringTok{ }\KeywordTok{quantile}\NormalTok{(random, p)}
\NormalTok{normal_q =}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(p, mu, sig)}
\KeywordTok{plot}\NormalTok{(normal_q }\OperatorTok{~}\StringTok{ }\NormalTok{random_q); }\KeywordTok{abline}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-87-1} \end{center}

The fact that all the quantiles fall around the 1:1 line suggests the \texttt{n} random samples are indeed from a normal distribution. Any deviations you see are due to sampling errors. If you increase \texttt{n} to \texttt{n\ =\ 1e6} (one million), you'll see no deviations. This is called a \textbf{q-q plot}, and is frequently used to assess the fit of data to a distribution.

Now test the random values in their agreement with the \texttt{pnorm()} function. Plot the cumulative density functions for the truly normal curve and the one approximated by the random deviates:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{400}\NormalTok{, }\DecValTok{600}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{random_cdf =}\StringTok{ }\KeywordTok{ecdf}\NormalTok{(random)}
\NormalTok{random_p =}\StringTok{ }\KeywordTok{random_cdf}\NormalTok{(q)}
\NormalTok{normal_p =}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(q, mu, sig)}
\KeywordTok{plot}\NormalTok{(normal_p }\OperatorTok{~}\StringTok{ }\NormalTok{q, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{)}
\KeywordTok{points}\NormalTok{(random_p }\OperatorTok{~}\StringTok{ }\NormalTok{q, }\DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-89-1} \end{center}

The \texttt{ecdf()} function obtains the empirical cumulative density function (which is just \texttt{pnorm()} for a sample). It allows you to plug in any random variable and obtain the probability of having one less than it.

\hypertarget{power-ex}{%
\subsection{Stochastic Power Analysis}\label{power-ex}}

A \textbf{power analysis} is one where the analyst wishes to determine how much power they will have to detect an effect. Power is inversely related to the probability of making a Type II Error: failing to reject a false null hypothesis\footnote{English: concluding there is no effect when there truly is one}. In other words, having high power means that you have a high chance of detecting an effect if an effect truly exists. Power is a function of the effect size, the sample size \texttt{n}, and the variability in the data. Strong effects are easier to detect than weak ones, more samples increase the test's sensitivity (the ability to detect weak effects), and lower variability results in more power.

You can conduct a power analysis using stochastic simulation (i.e., a Monte Carlo analysis). Here, you will write a power analysis to determine how likely are you to be able to correctly identify what you deem to be a biologically-meaningful difference in survival between two tagging procedures.

You know one tagging procedure has approximately a 10\% mortality rate (10\% of tagged fish die within the first 12 hours as result of the tagging process). Another cheaper, and less labor-intensive method has been proposed, but before implementing it, your agency wishes to determine if it will have a meaningful impact on the reliability of the study or on the ability of the crew to tag enough individuals that will survive long enough to be useful. You and your colleagues determine that if the mortality rate of the new tagging method reaches 25\%, then gains in time and cost-efficiency would be offset by needing to tag more fish (because more will die). You have decided to perform a small-scale study to determine if using the new method could result in 25\% or more mortality. The study will tag \texttt{n} individuals using both methods (new and old) and track the fraction that survived after 12 hours. Before performing the study however, you deem it important to determine how large \texttt{n} needs to be to answer this question. You decide to use a stochastic power analysis to help your research group. The small-scale study can tag a total of at most 100 fish with the currently available resources. Could you tag fewer than 100 total individuals and still have a high probability of detecting a statistically significant difference in mortality?

The stochastic power analysis approach works like this (this is called \textbf{psuedocode}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate data under the reality that the difference is real with \texttt{n} observations per treatment, where \texttt{n\ \textless{}\ 100/2}
\item
  Fit the model that will be used when the real data are collected to the simulated data
\item
  Determine if the difference was detected with a significant p-value
\item
  Replicate steps 1 - 3 many times
\item
  Replicate step 4 while varying \texttt{n} over the interval from 10 to 50
\item
  Determine what fraction of the p-values were deemed significant at each \texttt{n}
\end{enumerate}

Step 2 will require fitting a generalized linear model; for a review, revisit Section \ref{glms} (specifically Section \ref{logis-regression} on logistic regression).

First, create a function that will generate data, fit the model, and determine if the p-value is significant (steps 1-3 above):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim_fit =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, }\DataTypeTok{p_old =} \FloatTok{0.10}\NormalTok{, }\DataTypeTok{p_new =} \FloatTok{0.25}\NormalTok{) \{}
  
  \CommentTok{### step 1: create the data }\AlertTok{###}
  \CommentTok{# generate random response data}
\NormalTok{  dead_old =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_old)}
\NormalTok{  dead_new =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_new)}
  \CommentTok{# create the predictor variable}
\NormalTok{  method =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"old"}\NormalTok{, }\StringTok{"new"}\NormalTok{), }\DataTypeTok{each =}\NormalTok{ n)}
  \CommentTok{# create a data.frame to pass to glm}
\NormalTok{  df =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{dead =} \KeywordTok{c}\NormalTok{(dead_old, dead_new), }\DataTypeTok{method =}\NormalTok{ method)}
  \CommentTok{# relevel so old is the reference}
\NormalTok{  df}\OperatorTok{$}\NormalTok{method =}\StringTok{ }\KeywordTok{relevel}\NormalTok{(df}\OperatorTok{$}\NormalTok{method, }\DataTypeTok{ref =} \StringTok{"old"}\NormalTok{)}
  
  \CommentTok{### step 2: fit the model }\AlertTok{###}
\NormalTok{  fit =}\StringTok{ }\KeywordTok{glm}\NormalTok{(dead }\OperatorTok{~}\StringTok{ }\NormalTok{method, }\DataTypeTok{data =}\NormalTok{ df, }\DataTypeTok{family =}\NormalTok{ binomial)}
  
  \CommentTok{### step 3: determine if a sig. p-value was found }\AlertTok{###}
  \CommentTok{# extract the p-value}
\NormalTok{  pval =}\StringTok{ }\KeywordTok{summary}\NormalTok{(fit)}\OperatorTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{]}
  \CommentTok{# determine if it was found to be significant}
\NormalTok{  pval }\OperatorTok{<}\StringTok{ }\FloatTok{0.05}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Next, for steps 4 and 5, set up a \textbf{nested \texttt{for} loop}. This will have two loops: one that loops over sample sizes (step 5) and one that loops over replicates of each sample size (step 4). First, create the looping objects and containers:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{I =}\StringTok{ }\DecValTok{500}  \CommentTok{# the number of replicates at each sample size}
\NormalTok{n_try =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{10}\NormalTok{)  }\CommentTok{# the test sample sizes}
\NormalTok{N =}\StringTok{ }\KeywordTok{length}\NormalTok{(n_try)        }\CommentTok{# count them}
\CommentTok{# container: }
\NormalTok{out =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, I, N) }\CommentTok{# matrix with I rows and N columns}
\end{Highlighting}
\end{Shaded}

Now perform the nested loop. The inner-loop iterations will be completed for each element of \texttt{n} in the sequence \texttt{1:N}. The output (which is one element: \texttt{TRUE} or \texttt{FALSE} based on the significance of the p-value) is stored in the corresponding row and column for that iteration of that sample size.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{I) \{}
\NormalTok{    out[i,n] =}\StringTok{ }\KeywordTok{sim_fit}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ n_try[n])}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

You now have a matrix of \texttt{TRUE} and \texttt{FALSE} elements that indicates whether a significant difference was found at the \(\alpha = 0.05\) level if the effect was truly as large as you care about. You can obtain the proportion of all the replicates at each sample size that resulted in a significant difference using the \texttt{mean()} function with \texttt{apply()}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{apply}\NormalTok{(out, }\DecValTok{2}\NormalTok{, mean) }\OperatorTok{~}\StringTok{ }\NormalTok{n_try, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Tagged Fish per Treatment"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of Finding Effect (Power)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-95-1} \end{center}

Even if you tagged 100 fish total, you would only have a 49\% chance of saying the effect (which truly is there!) is present under the null hypothesis testing framework.

Suppose you and your colleagues aren't relying on p-values in this case, and are purely interested in how precisely the \textbf{effect size} would be estimated. Adapt your function to determine how frequently you would be able to estimate the true mortality of the new method within +/- 5\% based on the point estimate only (the estimate for the tagging mortality of the new method must be between 0.2 and 0.3 for a successful study). Change your function to calculate this additional metric and re-run the analysis:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim_fit =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, }\DataTypeTok{p_old =} \FloatTok{0.10}\NormalTok{, }\DataTypeTok{p_new =} \FloatTok{0.25}\NormalTok{) \{}
  \CommentTok{# create the data}
\NormalTok{  dead_old =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_old)}
\NormalTok{  dead_new =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ p_new)}
  \CommentTok{# create the predictor variable}
\NormalTok{  method =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"old"}\NormalTok{, }\StringTok{"new"}\NormalTok{), }\DataTypeTok{each =}\NormalTok{ n)}
  \CommentTok{# create a data.frame to pass to glm}
\NormalTok{  df =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{dead =} \KeywordTok{c}\NormalTok{(dead_old, dead_new), }\DataTypeTok{method =}\NormalTok{ method)}
  \CommentTok{# relevel so old is the reference}
\NormalTok{  df}\OperatorTok{$}\NormalTok{method =}\StringTok{ }\KeywordTok{relevel}\NormalTok{(df}\OperatorTok{$}\NormalTok{method, }\DataTypeTok{ref =} \StringTok{"old"}\NormalTok{)}
  \CommentTok{# fit the model}
\NormalTok{  fit =}\StringTok{ }\KeywordTok{glm}\NormalTok{(dead }\OperatorTok{~}\StringTok{ }\NormalTok{method, }\DataTypeTok{data =}\NormalTok{ df, }\DataTypeTok{family =}\NormalTok{ binomial)}
  \CommentTok{# extract the p-value}
\NormalTok{  pval =}\StringTok{ }\KeywordTok{summary}\NormalTok{(fit)}\OperatorTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{]}
  \CommentTok{# determine if it was found to be significant}
\NormalTok{  sig_pval =}\StringTok{ }\NormalTok{pval }\OperatorTok{<}\StringTok{ }\FloatTok{0.05}
  \CommentTok{# obtain the estimated mortality rate for the new method}
\NormalTok{  p_new_est =}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit, }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{method =} \KeywordTok{c}\NormalTok{(}\StringTok{"new"}\NormalTok{)),}
                      \DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}
  
  \CommentTok{# determine if it is +/- 5% from the true value}
\NormalTok{  prc_est =}\StringTok{ }\NormalTok{p_new_est }\OperatorTok{>=}\StringTok{ }\NormalTok{(p_new }\OperatorTok{-}\StringTok{ }\FloatTok{0.05}\NormalTok{) }\OperatorTok{&}\StringTok{ }\NormalTok{p_new_est }\OperatorTok{<=}\StringTok{ }\NormalTok{(p_new }\OperatorTok{+}\StringTok{ }\FloatTok{0.05}\NormalTok{)}
  \CommentTok{# return a vector with these two elements}
  \KeywordTok{c}\NormalTok{(}\DataTypeTok{sig_pval =}\NormalTok{ sig_pval, }\DataTypeTok{prc_est =} \KeywordTok{unname}\NormalTok{(prc_est))}
\NormalTok{\}}

\CommentTok{# containers: }
\NormalTok{out_sig =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, I, N) }\CommentTok{# matrix with I rows and N columns}
\NormalTok{out_prc =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, I, N) }\CommentTok{# matrix with I rows and N columns}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{I) \{}
\NormalTok{    tmp =}\StringTok{ }\KeywordTok{sim_fit}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ n_try[n])     }\CommentTok{# run sim}
\NormalTok{    out_sig[i,n] =}\StringTok{ }\NormalTok{tmp[}\StringTok{"sig_pval"}\NormalTok{]  }\CommentTok{# extract and store significance metric}
\NormalTok{    out_prc[i,n] =}\StringTok{ }\NormalTok{tmp[}\StringTok{"prc_est"}\NormalTok{]   }\CommentTok{# extract and store precision metric}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{apply}\NormalTok{(out_sig, }\DecValTok{2}\NormalTok{, mean) }\OperatorTok{~}\StringTok{ }\NormalTok{n_try, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Tagged Fish per Treatment"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of Finding Effect (Power)"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{apply}\NormalTok{(out_prc, }\DecValTok{2}\NormalTok{, mean) }\OperatorTok{~}\StringTok{ }\NormalTok{n_try, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Tagged Fish per Treatment"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of a Precise Estimate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-96-1} \end{center}

It seems that even if you tagged 50 fish per treatment, you would have a 63\% chance of estimating that the mortality rate is between 0.2 and 0.3 if it was truly 0.25.

You and your colleagues consider these results and determine that you will need to somehow acquire more funds to tag more fish in the small-scale study in order to have a high level of confidence in the results.

\hypertarget{harv-ex}{%
\subsection{Harvest Policy Analysis}\label{harv-ex}}

In this example, you will simulate population dynamics under a more realistic model than in Sections \ref{for-loops} and \ref{adv-funcs} for the purpose of evaluating different harvest policies.

Suppose you are a fisheries research biologist, and a commercial fishery for pink salmon (\emph{Oncorhynchus gorbuscha}) takes place in your district. For the past 10 years, it has been fished with an exploitation rate of 40\% (40\% of the fish that return each year have been harvested, exploitation rate is abbreviated by \(U\)), resulting in an average annual harvest of 8.5 million fish. The management plan is up for evaluation this year, and your supervisor has asked you to prepare an analysis that determines if more harvest could be sustained if a different exploitation rate were to be used in the future.

Based on historical data, your best understanding implies that the stock is driven by Ricker spawner-recruit dynamics. That is, the total number of fish that return this year (recruits) is a function of the total number of fish that spawned (spawners) in the year of their birth. The Ricker model can be written this way:

\begin{equation}
  R_t = \alpha S_{t-1} e^{-\beta S_{t-1} + \varepsilon_t} ,\varepsilon_t \sim N(0,\sigma)
\label{eq:ricker-ch4}
\end{equation}

where \(\alpha\) is a parameter representing the maximum recruits per spawner (obtained at very low spawner abundances) and \(\beta\) is a measure of the strength of density-dependent mortality. Notice that the error term is in the exponent, which makes \(e^{\varepsilon_t}\) lognormal.

You have estimates of the parameters\footnote{In reality, these estimates would have substantial uncertainty that you would need to propagate through your harvest policy analysis. In this example, you will ignore this complication}:

\begin{itemize}
\tightlist
\item
  \(\alpha = 6\)
\item
  \(\beta = 1 \times 10^{-7}\)
\item
  \(\sigma = 0.4\)
\end{itemize}

You decide that you can build a policy analysis by simulating the stock forward through time under different exploitation rates. With enough iterations of the simulation, you will be able to see whether a different exploitation rate can provide more harvest than what is currently being extracted.

First, write a function for your population model. Your function must:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  take the parameters, dimensions (number of years), and the policy variable (\(U\)) as input arguments
\item
  simulate the population using Ricker dynamics
\item
  calculate and return the average harvest and escapement over the number of future years you simulated.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Step #1: name the function and give it some arguments}
\NormalTok{ricker_sim =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(ny, params, U) \{}
  \CommentTok{# extract the parameters out by name:}
\NormalTok{  alpha =}\StringTok{ }\NormalTok{params[}\StringTok{"alpha"}\NormalTok{]}
\NormalTok{  beta =}\StringTok{ }\NormalTok{params[}\StringTok{"beta"}\NormalTok{]}
\NormalTok{  sigma =}\StringTok{ }\NormalTok{params[}\StringTok{"sigma"}\NormalTok{]}
  \CommentTok{# create containers}
       \CommentTok{# this is a neat trick to condense your code:}
\NormalTok{  R =}\StringTok{ }\NormalTok{S =}\StringTok{ }\NormalTok{H =}\StringTok{ }\OtherTok{NULL}
  \CommentTok{# initialize the population in the first year}
    \CommentTok{# start the population at being fished at 40%}
    \CommentTok{# with lognormal error}
\NormalTok{  R[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\KeywordTok{log}\NormalTok{(alpha }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\FloatTok{0.4}\NormalTok{))}\OperatorTok{/}\NormalTok{(beta }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\FloatTok{0.4}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, sigma))}
\NormalTok{  S[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\NormalTok{R[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{U)}
\NormalTok{  H[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\NormalTok{R[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{U}
  
  \CommentTok{# carry simulation forward through time}
  \ControlFlowTok{for}\NormalTok{ (y }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{ny) \{}
    \CommentTok{# use the ricker function with random lognormal noise}
\NormalTok{    R[y] =}\StringTok{ }\NormalTok{S[y}\DecValTok{-1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{alpha }\OperatorTok{*}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{beta }\OperatorTok{*}\StringTok{ }\NormalTok{S[y}\DecValTok{-1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, sigma))}
    \CommentTok{#harvest and spawners are the same as before}
\NormalTok{    S[y] =}\StringTok{ }\NormalTok{R[y] }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{U)}
\NormalTok{    H[y] =}\StringTok{ }\NormalTok{R[y] }\OperatorTok{*}\StringTok{ }\NormalTok{U}
\NormalTok{  \}}
  \CommentTok{# wrap output in a list object}
  \KeywordTok{list}\NormalTok{(}
    \DataTypeTok{mean_H =} \KeywordTok{mean}\NormalTok{(H),}
    \DataTypeTok{mean_S =} \KeywordTok{mean}\NormalTok{(S)}
\NormalTok{    )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Use the function once:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{params =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DataTypeTok{alpha =} \DecValTok{6}\NormalTok{, }\DataTypeTok{beta =} \FloatTok{1e-7}\NormalTok{, }\DataTypeTok{sigma =} \FloatTok{0.4}\NormalTok{)}
\NormalTok{out =}\StringTok{ }\KeywordTok{ricker_sim}\NormalTok{(}\DataTypeTok{U =} \FloatTok{0.4}\NormalTok{, }\DataTypeTok{ny =} \DecValTok{20}\NormalTok{, }\DataTypeTok{params =}\NormalTok{ params)}
\CommentTok{#average annual harvest (in millions)}
\KeywordTok{round}\NormalTok{(out}\OperatorTok{$}\NormalTok{mean_H}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.88
\end{verbatim}

If you completed the stochastic power analysis example (Section \ref{power-ex}), you might see where this is going. You are going to replicate applying a fixed policy many times to a random system. This is the Monte Carlo part of the analysis. The policy part is that you will compare the output from several candidate exploitation rates to inform a decision about which is best. This time, set up your analysis using \texttt{sapply()} (to iterate over different values of \(U\)) and \texttt{replicate()} (to iterate over different random populations fished at each \(U\)) instead of performing a nested \texttt{for()} loop as in previous examples:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U_try =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\NormalTok{n_rep =}\StringTok{ }\DecValTok{2000}
\NormalTok{H_out =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(U_try, }\ControlFlowTok{function}\NormalTok{(u) \{}
  \KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ n_rep, }\DataTypeTok{expr =}\NormalTok{ \{}
    \KeywordTok{ricker_sim}\NormalTok{(}\DataTypeTok{U =}\NormalTok{ u, }\DataTypeTok{ny =} \DecValTok{20}\NormalTok{, }\DataTypeTok{params =}\NormalTok{ params)}\OperatorTok{$}\NormalTok{mean_H}\OperatorTok{/}\FloatTok{1e6}
\NormalTok{  \})}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

The nested \texttt{replicate()} and \texttt{sapply()} method is a bit cleaner than a nested \texttt{for()} loop, but you have less control over the format of the output.

Plot the output of your simulations using a boxplot. To make things easier, give \texttt{H\_out} column names representing the exploitation rate:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colnames}\NormalTok{(H_out) =}\StringTok{ }\NormalTok{U_try}
\KeywordTok{boxplot}\NormalTok{(H_out, }\DataTypeTok{outline =}\NormalTok{ F,}
        \DataTypeTok{xlab =} \StringTok{"U"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Harvest (Millions of Fish)"}\NormalTok{,}
        \DataTypeTok{col =} \StringTok{"tomato"}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-102-1} \end{center}

It appears the stock could produce more harvest than its current 8.5 million fish per year if it was fished harder. However, your supervisors also do not want to see the escapement drop below three-quarters of what it has been in recent history (75\% of approximately 13 million fish). They ask you to obtain the expected average annual escapement as well as harvest. You can simply re-run the code above, but extracting \texttt{S\_mean} rather than \texttt{H\_mean}. Call this output \texttt{S\_out} and plot it just like harvest (if you're curious, this blue color is \texttt{col\ =\ "skyblue"}):

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-103-1} \end{center}

After seeing this information, your supervisor realizes they are faced with a trade-off: the stock could produce more with high exploitation rates, but they are concerned about pushing the stock too low would be unsustainable. They tell you to determine the probability that the average escapement would not be pushed below 75\% of 13 million at each exploitation rate, as well as the probability that the average annual harvests will be at least 20\% greater than they are currently (approximately 8.5 million fish). Given your output, this is easy:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# determine if each element meets escapement criterion}
\NormalTok{Smeet =}\StringTok{ }\NormalTok{S_out }\OperatorTok{>}\StringTok{ }\NormalTok{(}\FloatTok{0.75} \OperatorTok{*}\StringTok{ }\DecValTok{13}\NormalTok{)}
\CommentTok{# determine if each element meets harvest criterion}
\NormalTok{Hmeet =}\StringTok{ }\NormalTok{H_out }\OperatorTok{>}\StringTok{ }\NormalTok{(}\FloatTok{1.2} \OperatorTok{*}\StringTok{ }\FloatTok{8.5}\NormalTok{)}
\CommentTok{# calculate the probability of each occuring at a given exploitation rate}
  \CommentTok{# remember, mean of a logical vector calculate the proportion of TRUEs}
\NormalTok{p_Smeet =}\StringTok{ }\KeywordTok{apply}\NormalTok{(Smeet, }\DecValTok{2}\NormalTok{, mean)}
\NormalTok{p_Hmeet =}\StringTok{ }\KeywordTok{apply}\NormalTok{(Hmeet, }\DecValTok{2}\NormalTok{, mean)}
\end{Highlighting}
\end{Shaded}

You plot this for your supervisor as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# the U levels to highlight on plot}
\NormalTok{plot_U =}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.05}\NormalTok{)}
\CommentTok{# create an empty plot}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(p_Smeet }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet, }\DataTypeTok{type =} \StringTok{"n"}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Probability of Meeting Harvest Criterion"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Probability of Meeting Escapement Criterion"}\NormalTok{)}
\CommentTok{# add gridlines}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.1}\NormalTok{), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.1}\NormalTok{), }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\CommentTok{#draw on the tradeoff curve}
\KeywordTok{lines}\NormalTok{(p_Smeet }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet, }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\CommentTok{# add points and text for particular U policies}
\KeywordTok{points}\NormalTok{(p_Smeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U] }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U],}
       \DataTypeTok{pch =} \DecValTok{16}\NormalTok{, }\DataTypeTok{cex =} \FloatTok{1.5}\NormalTok{)}
\KeywordTok{text}\NormalTok{(p_Smeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U] }\OperatorTok{~}\StringTok{ }\NormalTok{p_Hmeet[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U],}
     \DataTypeTok{labels =}\NormalTok{ U_try[U_try }\OperatorTok{%in%}\StringTok{ }\NormalTok{plot_U], }\DataTypeTok{pos =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-105-1} \end{center}

Equipped with this analysis, your supervisor plans to go to the policy-makers with the recommendation of adjusting the exploitation rate policy to use \(U = 0.5\), because they think it balances the trade-off. Notice how if the status quo was maintained, your model suggests you would have complete certainty of staying where you are now: escapement will remain above 75\% of its current level with a 100\% chance, but you would have no chance of improving harvests to greater than 20\% of their current level. Small increases in the exploitation rate (e.g., from 0.4 to 0.45) have a reasonably large gain in harvest performance, but hardly any losses for the escapement criterion. Your supervisor is willing to live with a 90\% chance that the escapement will stay where they desire in order to gain a \textgreater80\% chance of obtaining the desired amount of increases in harvest.

The utility of using Monte Carlo methods in this example is the ability to calculate the probability of some event you are interested in. There are analytical (i.e., not simulation-based) solutions to predict the annual harvest and escapement from a fixed \(U\) from a population with parameters \(\alpha\) and \(\beta\), but by incorporating randomness, you were able to obtain the relative weights of outcomes other than the expectation under the deterministic Ricker model, thereby allowing the assignment of probabilities to meeting the two criteria.

\hypertarget{resample-examples}{%
\section{Resampling-Based Examples}\label{resample-examples}}

\hypertarget{boot-test-ex}{%
\subsection{The Bootstrap}\label{boot-test-ex}}

Say you have a fitted model from which you want to propagate the uncertainty in some derived quantity. Consider the case of the \textbf{von Bertalanffy growth model}. This is a non-linear model used to predict the size of an organism (weight or length) based on its age. The model can be written for a non-linear regression model (see Section \ref{nls}) as:

\begin{equation}
  L_i = L_{\infty}\left(1 - e^{-k(age_i-t_0)}\right) + \varepsilon_i, \varepsilon_i \sim N(0, \sigma)
\label{eq:vonB}
\end{equation}

where \(L_i\) and \(age_i\) are the observed length and age of individual \(i\), respectively, and \(L_{\infty}\), \(k\), and \(t_0\) are parameters to be estimated. The interpretations of the parameters are as follows:

\begin{itemize}
\tightlist
\item
  \(L_{\infty}\): the maximum average length achieved
\item
  \(k\): a growth coefficient linked to metabolic rate. It specifies the rate of increase in length as the fish ages early in life
\item
  \(t_0\): the theoretical age when length equals zero (the x-intercept).
\end{itemize}

Use the data set \texttt{growth.csv} for this example (see the \protect\hyperlink{data-sets}{instructions} on acquiring data files). Read in and plot the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"../Data/growth.csv"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(length }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ dat, }\DataTypeTok{pch =} \DecValTok{16}\NormalTok{, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-107-1} \end{center}

Due to a large amount of variability in individual growth rates, the relationship looks pretty noisy. Notice how you have mostly young fish in your sample: this is characteristic of ``random'' sampling of fish populations.

Suppose you would like to obtain the probability that an average-sized fish of each age is sexually mature. You know that fish of this species mature at approximately 450 mm, and you simply need to determine the fraction of all fish at each age that are greater than 450 mm. However, you don't have any observations for some ages (e.g., age 8), so you cannot simply calculate this fraction based on your raw data. You need to fit the von Bertalanffy growth model, then carry the statistical uncertainty from the fitted model forward to the predicted length-at-age. This would be difficult to obtain using only the coefficient estimates and their standard errors, because of the non-linear relationship between the \(x\) and \(y\) variables.

Enter the \textbf{bootstrap}, which is a Monte Carlo analysis using an observed data set and a model. The \textbf{pseudocode} for a bootstrap analysis is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Resample from the original data (with replacement)
\item
  Fit a model of interest
\item
  Derive some quantity of interest from the fitted model
\item
  Repeat steps 1 - 3 many times
\item
  Summarize the randomized quantities from step 4
\end{enumerate}

In this example, you will apply a bootstrap approach to obtain the distribution of expected fish lengths at each age, then use these distributions to quantify the probability that an averaged-sized fish of each age is mature (i.e., greater than 450 mm).

You will write a function for each of steps 1 - 3 above. The first is to resample the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{randomize =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(dat) \{}
  \CommentTok{# number of observed pairs}
\NormalTok{  n =}\StringTok{ }\KeywordTok{nrow}\NormalTok{(dat)}
  \CommentTok{# sample the rows to determine which will be kept}
\NormalTok{  keep =}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\NormalTok{n, }\DataTypeTok{size =}\NormalTok{ n, }\DataTypeTok{replace =}\NormalTok{ T)}
  \CommentTok{# retreive these rows from the data}
\NormalTok{  dat[keep,]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Notice the use of \texttt{replace\ =\ T} here: without this, there would be no bootstrap. You would just sample the same observations over and over, their order in the rows would just be shuffled. Next, write a function to fit the model (revisit Section \ref{nls} for more details on \texttt{nls()}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_vonB =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(dat) \{}
  \KeywordTok{nls}\NormalTok{(length }\OperatorTok{~}\StringTok{ }\NormalTok{linf }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{k }\OperatorTok{*}\StringTok{ }\NormalTok{(age }\OperatorTok{-}\StringTok{ }\NormalTok{t0))),}
      \DataTypeTok{data =}\NormalTok{ dat,}
      \DataTypeTok{start =} \KeywordTok{c}\NormalTok{(}\DataTypeTok{linf =} \DecValTok{600}\NormalTok{, }\DataTypeTok{k =} \FloatTok{0.3}\NormalTok{, }\DataTypeTok{t0 =} \FloatTok{-0.2}\NormalTok{)}
\NormalTok{      )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This function will return a fitted model object when executed. Next, write a function to predict mean length-at-age:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create a vector of ages}
\NormalTok{ages =}\StringTok{ }\KeywordTok{min}\NormalTok{(dat}\OperatorTok{$}\NormalTok{age)}\OperatorTok{:}\KeywordTok{max}\NormalTok{(dat}\OperatorTok{$}\NormalTok{age)}
\NormalTok{pred_vonB =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(fit) \{}
  \CommentTok{# extract the coefficients}
\NormalTok{  ests =}\StringTok{ }\KeywordTok{coef}\NormalTok{(fit)}
  \CommentTok{# predict length-at-age}
\NormalTok{  ests[}\StringTok{"linf"}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{ests[}\StringTok{"k"}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{(ages }\OperatorTok{-}\StringTok{ }\NormalTok{ests[}\StringTok{"t0"}\NormalTok{])))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Notice your function will use the object \texttt{ages} even though it was not defined in the function. This has to do with \textbf{lexical scoping} and \textbf{environments}, which are beyond the scope of this introductory material. If you'd like more details, see the section in \citet{adv-r-cite} on it\footnote{The section on \textbf{lexical scoping} is found here: \url{http://adv-r.had.co.nz/Functions.html\#lexical-scoping}}. Basically, if an object with the same name as one defined in the function exists outside of the function, the function will use the one that is defined within the function. If there is no object defined in the function with that name, it will look outside of the function for that object.

Now, use these three functions to perform one iteration:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pred_vonB}\NormalTok{(}\DataTypeTok{fit =} \KeywordTok{fit_vonB}\NormalTok{(}\DataTypeTok{dat =} \KeywordTok{randomize}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ dat)))}
\end{Highlighting}
\end{Shaded}

You can wrap this inside of a \texttt{replicate()} call to perform step 4 above:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\NormalTok{out =}\StringTok{ }\KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =} \DecValTok{100}\NormalTok{, }\DataTypeTok{expr =}\NormalTok{ \{}
  \KeywordTok{pred_vonB}\NormalTok{(}\DataTypeTok{fit =} \KeywordTok{fit_vonB}\NormalTok{(}\DataTypeTok{dat =} \KeywordTok{randomize}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ dat)))}
\NormalTok{\})}

\KeywordTok{dim}\NormalTok{(out)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  10 100
\end{verbatim}

It appears the rows are different ages and the columns are different bootstrapped iterations. Summarize the random lengths at each age:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summ =}\StringTok{ }\KeywordTok{apply}\NormalTok{(out, }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{c}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(x), }\KeywordTok{quantile}\NormalTok{(x, }\KeywordTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{))))}
\end{Highlighting}
\end{Shaded}

Plot the data, the summarized ranges of mean lengths, and the length at which all fish are assumed to be mature (450 mm)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(length }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ dat, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{16}\NormalTok{,}
     \DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(dat}\OperatorTok{$}\NormalTok{length, summ[}\StringTok{"97.5%"}\NormalTok{,])),}
     \DataTypeTok{ylab =} \StringTok{"Length (mm)"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Age (years)"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(summ[}\StringTok{"mean"}\NormalTok{,] }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(summ[}\StringTok{"2.5%"}\NormalTok{,] }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(summ[}\StringTok{"97.5%"}\NormalTok{,] }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{h =} \DecValTok{450}\NormalTok{, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-115-1} \end{center}

Obtain the fraction of iterations that resulted in the mean length-at-age being greater than 450 mm. This is interpreted as the probability that the average-sized fish of each age is mature:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p_mat =}\StringTok{ }\KeywordTok{apply}\NormalTok{(out, }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{mean}\NormalTok{(x }\OperatorTok{>}\StringTok{ }\DecValTok{450}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(p_mat }\OperatorTok{~}\StringTok{ }\NormalTok{ages, }\DataTypeTok{type =} \StringTok{"b"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{17}\NormalTok{,}
     \DataTypeTok{xlab =} \StringTok{"Age (years)"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Probability of Average Fish Mature"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-117-1} \end{center}

This \textbf{maturity schedule} can be used by fishery managers in attempting to decide which ages should be allowed to be harvested and which should be allowed to grow more\footnote{possibly in a \textbf{yield-per-recruit} analysis}. Because each age has an associated expected length, managers can use what they know about the size selectivity of various gear types to set policies that attempt to target some ages more than others.

\hypertarget{perm-test-ex}{%
\subsection{Permutation Test}\label{perm-test-ex}}

In the previous example (Section \ref{boot-test-ex}), you learned about the bootstrap. A related Monte Carlo analysis is the \textbf{permutation test}. This is a non-parametric statistical test used to determine if there is a statistically-significant difference in the mean of some quantity between two populations. It is used in cases where the assumptions of a generalized linear model may not be met, but a p-value is still required.

The \textbf{pseudocode} for the permutation test is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculate the difference between means based on the original data set
\item
  Shuffle the group assignments randomly among the observations
\item
  Calculate the difference between the randomly-assigned groups
\item
  Repeat steps 2 - 3 many times. This builds the \textbf{null distribution}: the distribution of the test statistic (the difference) assuming the null hypothesis (that there is no difference) in means is true
\item
  Determine what fraction of the absolute differences were larger than the original difference. This constitutes a \textbf{two-tailed} p-value. One-tailed tests can also be derived using the same steps 1 - 4, which is left as an exercise.
\end{enumerate}

Use the data set \texttt{ponds.csv} for this example (see the \protect\hyperlink{data-sets}{instructions} on acquiring data files). This is the same data set used for \protect\hyperlink{ex1b}{Exercise 1B}, revisit that exercise for details on this hypothetical data set. Read in and plot the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"ponds.csv"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(chl.a }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{data =}\NormalTok{ dat)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-119-1} \end{center}

It appears as though there is a relatively strong signal indicating a difference. Use the permutation test to determine if it is statistically significant. Step 1 from the pseudocode is to calculate the observed difference between groups:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Dobs =}\StringTok{ }\KeywordTok{mean}\NormalTok{(dat}\OperatorTok{$}\NormalTok{chl.a[dat}\OperatorTok{$}\NormalTok{treatment }\OperatorTok{==}\StringTok{ "Add"}\NormalTok{]) }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(dat}\OperatorTok{$}\NormalTok{chl.a[dat}\OperatorTok{$}\NormalTok{treatment }\OperatorTok{==}\StringTok{ "Control"}\NormalTok{])}
\NormalTok{Dobs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.166
\end{verbatim}

Write a function to perform one iteration of steps 2 - 3 from the pseudocode:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# x is the group: Add or Control}
\CommentTok{# y is chl.a}
\NormalTok{perm =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y) \{}
  \CommentTok{# turn x to a character, easier to deal with}
\NormalTok{  x =}\StringTok{ }\KeywordTok{as.character}\NormalTok{(x)}
  \CommentTok{# shuffle the x values:}
\NormalTok{  x_shuff =}\StringTok{ }\KeywordTok{sample}\NormalTok{(x)}
  \CommentTok{# calculate the mean of each group:}
\NormalTok{  x_bar_add =}\StringTok{ }\KeywordTok{mean}\NormalTok{(y[x_shuff }\OperatorTok{==}\StringTok{ "Add"}\NormalTok{])}
\NormalTok{  x_bar_ctl =}\StringTok{ }\KeywordTok{mean}\NormalTok{(y[x_shuff }\OperatorTok{==}\StringTok{ "Control"}\NormalTok{])}
  \CommentTok{# calculate the difference:}
\NormalTok{  x_bar_add }\OperatorTok{-}\StringTok{ }\NormalTok{x_bar_ctl}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Use your function once:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{perm}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{treatment, }\DataTypeTok{y =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{chl.a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10.648
\end{verbatim}

Perform step 4 from the pseudocode by replicating your \texttt{perm()} function many times:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Dnull =}\StringTok{ }\KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =} \DecValTok{5000}\NormalTok{, }\DataTypeTok{expr =} \KeywordTok{perm}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{treatment, }\DataTypeTok{y =}\NormalTok{ dat}\OperatorTok{$}\NormalTok{chl.a))}
\end{Highlighting}
\end{Shaded}

Plot the distribution of the null test statistic and draw a line where the originally-observed difference falls:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(Dnull, }\DataTypeTok{col =} \StringTok{"grey"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v =}\NormalTok{ Dobs, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{3}\NormalTok{, }\DataTypeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-125-1} \end{center}

Notice the null distribution is centered on zero: this is because the null hypothesis is that there is no difference. The observation (blue line) falls way in the upper tail of the null distribution, indicating it is unlikely that an effect that large was observed by random chance. The two-tailed p-value can be calculated as:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\KeywordTok{abs}\NormalTok{(Dnull) }\OperatorTok{>=}\StringTok{ }\NormalTok{Dobs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

Very few (or zero) of the random data sets resulted in a difference greater than what was observed, indicating there is statistical support to the hypothesis that there is a non-zero difference between the two nutrient treatments.

\hypertarget{population-dynamics-1}{%
\section{Population dynamics}\label{population-dynamics-1}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{source}\NormalTok{(}\StringTok{"./R/Rcode/Final_report_Davidson2017.R"}\NormalTok{, }\DataTypeTok{echo =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## > library(boot)
## 
## > library(tidyverse)
## 
## > library(dplyr)
## 
## > library(ggplot2)
## 
## > library(qpcR)
## 
## > library(pwr)
## 
## > library(ggthemes)
## 
## > library(gridExtra)
## 
## > Data <- read.csv("./R/Data/RawCI.csv", header = T, 
## +     quote = "\"")
## 
## > Year <- unique(Data$Calves.1)
## 
## > year2010a <- c(3, 3, 2)
## 
## > year2010 <- filter(Data, Calves.1 < 2011)
## 
## > year2010 <- year2010$Interval.1[!is.na(year2010$Interval.1)]
## 
## > year2011a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2)
## 
## > year2011 <- filter(Data, Calves.1 < 2012)
## 
## > year2011 <- year2011$Interval.1[!is.na(year2011$Interval.1)]
## 
## > year2012a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2, 6, 4, 4, 4, 4, 4, 3, 3, 3, 3)
## 
## > year2012 <- filter(Data, Calves.1 < 2013)
## 
## > year2012 <- year2012$Interval.1[!is.na(year2012$Interval.1)]
## 
## > year2013a <- c(3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
## +     3, 3, 2, 6, 4, 4, 4, 4, 4, 3, 3, 3, 3, 6, 5, 4, 4, 4, 4, 
## +     4, 3, 3, 3, 3, 3, 3, 3, 3, .... [TRUNCATED] 
## 
## > full <- c(Data$Interval.1, Data$Interval.2)
## 
## > year2013 <- full[!is.na(unlist(full))]
## 
## > mean2010 <- sum(year2010)/length(year2010)
## 
## > s2010 <- sd(year2010)
## 
## > SE2010 <- s2010/(sqrt(length(year2010)))
## 
## > n2010 <- (length(year2010))
## 
## > low.qt2010 <- mean2010 - (qt(0.975, length(year2010)) * 
## +     SE2010)
## 
## > high.qt2010 <- mean2010 + (qt(0.975, length(year2010)) * 
## +     SE2010)
## 
## > mean2011 <- sum(year2011)/length(year2011)
## 
## > s2011 <- sd(year2011)
## 
## > SE2011 <- s2011/(sqrt(length(year2011)))
## 
## > n2011 <- (length(year2011))
## 
## > low.qt2011 <- mean2011 - (qt(0.975, length(year2011)) * 
## +     SE2011)
## 
## > high.qt2011 <- mean2011 + (qt(0.975, length(year2011)) * 
## +     SE2011)
## 
## > mean2012 <- sum(year2012)/length(year2012)
## 
## > s2012 <- sd(year2012)
## 
## > SE2012 <- s2012/(sqrt(length(year2012)))
## 
## > n2012 <- (length(year2012))
## 
## > low.qt2012 <- mean2012 - (qt(0.975, length(year2012)) * 
## +     SE2012)
## 
## > high.qt2012 <- mean2012 + (qt(0.975, length(year2012)) * 
## +     SE2012)
## 
## > mean2013 <- sum(year2013)/length(year2013)
## 
## > s2013 <- sd(year2013)
## 
## > SE2013 <- s2013/(sqrt(length(year2013)))
## 
## > n2013 <- (length(year2013))
## 
## > low.qt2013 <- mean2013 - (qt(0.975, length(year2013)) * 
## +     SE2013)
## 
## > high.qt2013 <- mean2013 + (qt(0.975, length(year2013)) * 
## +     SE2013)
## 
## > n <- c(length(year2010), length(year2011), length(year2012), 
## +     length(year2013))
## 
## > mY <- c(mean(year2010), mean(year2011), mean(year2012), 
## +     mean(year2013))
## 
## > year <- Year
## 
## > low.qt <- c(low.qt2010, low.qt2011, low.qt2012, low.qt2013)
## 
## > high.qt <- c(high.qt2010, high.qt2011, high.qt2012, 
## +     high.qt2013)
## 
## > sd <- c(s2010, s2011, s2012, s2013)
## 
## > sum.dat <- cbind(year, n, mY, low.qt, high.qt, sd)
## 
## > sum.dat <- as.data.frame(sum.dat)
## 
## > library(knitr)
## 
## > kable(sum.dat, format = "markdown")
## 
## 
## | year|  n|       mY|   low.qt|  high.qt|        sd|
## |----:|--:|--------:|--------:|--------:|---------:|
## | 2010|  3| 2.666667| 1.605851| 3.727482| 0.5773503|
## | 2011| 15| 2.866667| 2.673022| 3.060312| 0.3518658|
## | 2012| 25| 3.240000| 2.919170| 3.560830| 0.7788881|
## | 2013| 45| 3.311111| 3.056488| 3.565734| 0.8480518|
## 
## > ggplot(sum.dat, aes(y = mY, x = year)) + geom_point() + 
## +     geom_line() + geom_errorbar(aes(ymin = low.qt, ymax = high.qt), 
## +     width = 0.1) + .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-1} \end{center}

\begin{verbatim}
## 
## > par(mfrow = c(2, 2))
## 
## > plot(factor(year2010), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "a)", sub = "Sample size 3", ylab = "Frequency", 
## +     xlab = "Calving interval", cex.main = 1.5, font.main = 4, 
## +     col.main = "bl ..." ... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2011), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "b)", sub = "Sample size 15", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2012), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{verbatim}
## 
## > title(main = "c)", sub = "Sample size 25", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > plot(factor(year2013), xlim = c(0, 6), ylim = c(0, 
## +     40))
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-2} \end{center}

\begin{verbatim}
## 
## > title(main = "d)", sub = "Sample size 45", ylab = "Frequency", 
## +     xlab = "Calving interval", col.main = 4, cex.main = 1.5, 
## +     font.main = 4, .... [TRUNCATED] 
## 
## > box()
## 
## > library(qpcR)
## 
## > rawdata <- qpcR:::cbind.na(year2010, year2011, year2012, 
## +     year2013)
## 
## > rawdata <- as.data.frame(rawdata)
## 
## > year2010 <- data.frame(year2010, year = c("2010"))
## 
## > year2010 <- rename(year2010, interval = year2010, 
## +     year = year)
## 
## > year2011 <- data.frame(year2011, year = c("2011"))
## 
## > year2011 <- rename(year2011, interval = year2011, 
## +     year = year)
## 
## > year2012 <- data.frame(year2012, year = c("2012"))
## 
## > year2012 <- rename(year2012, interval = year2012, 
## +     year = year)
## 
## > year2013 <- data.frame(year2013, year = c("2013"))
## 
## > year2013 <- rename(year2013, interval = year2013, 
## +     year = year)
## 
## > ggplotraw <- rbind(year2010, year2011, year2012, year2013)
## 
## > ggplotraw$interval <- as.numeric(as.character(ggplotraw$interval))
## 
## > ggplot(year2013, aes(x = interval)) + geom_bar(alpha = 1, 
## +     width = 0.9, fill = "black") + xlab(expression("Calving" ~ 
## +     "interval" ~ (ita .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-3} \end{center}

\begin{verbatim}
## 
## > RealCI <- as.numeric(year2013$interval)
## 
## > xlong <- RealCI
## 
## > meanlong <- sum(xlong)/length(xlong)
## 
## > slong <- sd(xlong)
## 
## > SElong <- slong/(sqrt(length(xlong)))
## 
## > nlong <- (length(xlong))
## 
## > lowqtlong <- meanlong - (qt(0.975, nlong) * SElong)
## 
## > highqtlong <- meanlong + (qt(0.975, nlong) * SElong)
## 
## > MedCI <- c(RealCI[RealCI < 5], 3, 3, 3, 3, 2, 3)
## 
## > xmed <- MedCI
## 
## > meanmed <- sum(xmed)/length(xmed)
## 
## > smed <- sd(xmed)
## 
## > SEmed <- smed/(sqrt(length(xmed)))
## 
## > nmed <- (length(xmed))
## 
## > lowqtmed <- meanmed - (qt(0.975, length(xmed)) * SEmed)
## 
## > highqtmed <- meanmed + (qt(0.975, length(xmed)) * 
## +     SEmed)
## 
## > LowCI <- c(RealCI[RealCI < 4], 3, 3, 3, 3, 3, 2, 2, 
## +     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)
## 
## > xshort <- LowCI
## 
## > meanshort <- mean(xshort)
## 
## > sshort <- sd(xshort)
## 
## > SEshort <- sshort/(sqrt(length(xshort)))
## 
## > lowqtshort <- meanshort - (qt(0.975, length(xshort)) * 
## +     SEshort)
## 
## > highqtshort <- meanshort + (qt(0.975, length(xshort)) * 
## +     SEshort)
## 
## > bdata <- qpcR:::cbind.na(RealCI, MedCI, LowCI)
## 
## > bdata <- as.data.frame(bdata)
## 
## > par(mfrow = c(1, 3))
## 
## > plot(factor(bdata$LowCI), main = "Lowest possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(bdata$MedCI), main = "Medium possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(bdata$RealCI), main = "Observed interval")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-4} \end{center}

\begin{verbatim}
## 
## > par(mfrow = c(3, 1))
## 
## > plot(density(as.numeric(as.character(LowCI)), bw = 0.5), 
## +     main = "Lowest possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(density(as.numeric(as.character(MedCI)), bw = 0.5), 
## +     main = "Medium possible interval")
\end{verbatim}

\begin{verbatim}
## 
## > plot(density(as.numeric(as.character(RealCI)), bw = 0.5), 
## +     main = "Observed interval")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-5} \end{center}

\begin{verbatim}
## 
## > Sumtable <- data.frame(variable = c("low.qt", "mean", 
## +     "high.qt", "sd", "SE"), short = c(lowqtshort, meanshort, 
## +     highqtshort, sshort, SE .... [TRUNCATED] 
## 
## > n <- c(length(LowCI), length(MedCI), length(year2013$interval))
## 
## > mY <- c(mean(LowCI), mean(MedCI), mean(year2013$interval))
## 
## > interval <- c("Low", "Medium", "Observed")
## 
## > low.qt <- c(lowqtshort, lowqtmed, low.qt2013)
## 
## > high.qt <- c(highqtshort, highqtmed, high.qt2013)
## 
## > sd <- c(sshort, smed, s2013)
## 
## > Sumtable <- cbind(interval, n, mY, low.qt, high.qt, 
## +     sd)
## 
## > Sumtable <- as.data.frame(Sumtable)
## 
## > Sumtable$n <- as.numeric(as.character(Sumtable$n))
## 
## > Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
## 
## > Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
## 
## > Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
## 
## > Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
## 
## > Sumtable$interval <- as.character(Sumtable$interval)
## 
## > ggplot(Sumtable, aes(y = mY, x = interval)) + geom_point(size = 5) + 
## +     geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05, 
## +       .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-6} \end{center}

\begin{verbatim}
## 
## > library(knitr)
## 
## > kable(Sumtable, format = "markdown", col.names = c("Interval", 
## +     "Sample size", "Mean", "Lower limit", "Higher limit", "SD"))
## 
## 
## |Interval | Sample size|     Mean| Lower limit| Higher limit|        SD|
## |:--------|-----------:|--------:|-----------:|------------:|---------:|
## |Low      |          58| 2.568966|    2.437666|     2.700265| 0.4995461|
## |Medium   |          48| 3.104167|    2.943089|     3.265244| 0.5550382|
## |Observed |          45| 3.311111|    3.056488|     3.565734| 0.8480518|
## 
## > library(knitr)
## 
## > srwdat <- read.csv(file = "./R/Data/srw_data.csv")
## 
## > kable(srwdat, format = "markdown", col.names = c("Sample size", 
## +     "Mean", "Lower limit", "Higher limit", "SE", "Author", "Location"))
## 
## 
## | Sample size| Mean| Lower limit| Higher limit|   SE|Author             |Location                          |
## |-----------:|----:|-----------:|------------:|----:|:------------------|:---------------------------------|
## |          NA| 3.12|        3.07|         3.17|   NA|Best et al. 2001   |South Africa                      |
## |        1504| 3.15|        3.11|         3.18|   NA|Best et al. 2005   |South Africa (1971-2003 Updated)  |
## |          NA| 3.16|        3.13|         3.19|   NA|Brandao et al 2010 |South Africa ( 1971-2006 Updated) |
## |          NA| 3.35|          NA|           NA| 0.05|Cooke et al. 2001  |Argentina                         |
## |         749| 3.42|          NA|           NA| 0.11|Cooke et al. 2003  |Argentina                         |
## |          NA| 3.63|          NA|           NA| 0.13|Burnell 2001       |Australia                         |
## 
## > SAreps <- 1500
## 
## > ARreps <- 800
## 
## > Aussiereps <- 2000
## 
## > low <- 1000
## 
## > verylow <- 100
## 
## > lowest <- 10
## 
## > par(mfrow = c(2, 3))
## 
## > plot(factor(sample(year2013$interval, lowest, replace = T)), 
## +     main = "3 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, verylow, replace = T)), 
## +     main = "10 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, low, replace = T)), 
## +     main = "30 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, Aussiereps, 
## +     replace = T)), main = "500 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, ARreps, replace = T)), 
## +     main = "800 intervals")
\end{verbatim}

\begin{verbatim}
## 
## > plot(factor(sample(year2013$interval, SAreps, replace = T)), 
## +     main = "1500 intervals")
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-7} \end{center}

\begin{verbatim}
## 
## > boots <- 1000
## 
## > n <- c(1:1000)
## 
## > var10 <- paste0("n_", 1:10)
## 
## > sample10 <- matrix(data = NA, ncol = lowest, nrow = boots)
## 
## > colnames(sample10) <- as.list(var10)
## 
## > for (i in 1:boots) {
## +     sample10[i, ] <- sample(year2013$interval, lowest, replace = T)
## + }
## 
## > sample10 <- as.data.frame(sample10)
## 
## > sample10 <- sample10 %>% mutate(mean10 = rowMeans(sample10))
## 
## > sample10t <- as.matrix(sample10)
## 
## > sample10t <- t(sample10t)
## 
## > var100 <- paste0("n_", 1:100)
## 
## > sample100 <- matrix(data = NA, ncol = verylow, nrow = boots)
## 
## > colnames(sample100) <- as.list(var100)
## 
## > for (i in 1:boots) {
## +     sample100[i, ] <- sample(year2013$interval, verylow, replace = T)
## + }
## 
## > sample100 <- as.data.frame(sample100)
## 
## > sample100 <- sample100 %>% mutate(mean100 = rowMeans(sample100))
## 
## > var500 <- paste0("n_", 1:500)
## 
## > sample500 <- matrix(data = NA, ncol = 500, nrow = boots)
## 
## > colnames(sample500) <- as.list(var500)
## 
## > for (i in 1:boots) {
## +     sample500[i, ] <- sample(year2013$interval, 500, replace = T)
## + }
## 
## > sample500 <- as.data.frame(sample500)
## 
## > sample500 <- sample500 %>% mutate(mean500 = rowMeans(sample500))
## 
## > var1000 <- paste0("n_", 1:1000)
## 
## > sample1000 <- matrix(data = NA, ncol = low, nrow = boots)
## 
## > colnames(sample1000) <- as.list(var1000)
## 
## > for (i in 1:boots) {
## +     sample1000[i, ] <- sample(year2013$interval, low, replace = T)
## + }
## 
## > sample1000 <- as.data.frame(sample1000)
## 
## > sample1000 <- sample1000 %>% mutate(mean1000 = rowMeans(sample1000))
## 
## > varA <- paste0("n_", 1:2000)
## 
## > sampleA <- matrix(data = NA, ncol = Aussiereps, nrow = boots)
## 
## > colnames(sampleA) <- as.list(varA)
## 
## > for (i in 1:boots) {
## +     sampleA[i, ] <- sample(year2013$interval, Aussiereps, replace = T)
## + }
## 
## > sampleA <- as.data.frame(sampleA)
## 
## > sampleA <- sampleA %>% mutate(meanA = rowMeans(sampleA))
## 
## > sampleAt <- t(sampleA)
## 
## > for (i in c(1:ncol(sampleA))) {
## +     sampleA[, i] <- as.numeric(as.character(sampleA[, i]))
## + }
## 
## > ab <- sort(sampleA$meanA)
## 
## > nab <- length(ab)
## 
## > ab2.5 <- ab[25]
## 
## > ab0.97.5 <- ab[975]
## 
## > ab <- sort(sampleA$meanA)
## 
## > nab <- length(ab)
## 
## > ab2.5 <- ab[25]
## 
## > ab0.97.5 <- ab[975]
## 
## > par(mfrow = c(1, 1))
## 
## > plot(density(sample10$mean10, bw = 0.05), col = "black", 
## +     lty = 1, main = "", lwd = 5, ylim = c(0, 8), xlim = c(2, 
## +         4.5), axes = FAL .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-8} \end{center}

\begin{verbatim}
## 
## > lines(density(sample100$mean100, bw = 0.05), col = "black", 
## +     lty = 2, lwd = 4)
## 
## > lines(density(sample500$mean500, bw = 0.05), col = "black", 
## +     lty = 3, lwd = 3)
## 
## > lines(density(sample1000$mean1000, bw = 0.05), col = "black", 
## +     lty = 4, lwd = 2)
## 
## > lines(density(sampleA$meanA, bw = 0.05), col = "black", 
## +     lty = 5, lwd = 1)
## 
## > legend("topright", title = "Legend", c("n=10, cv=8.12 ", 
## +     "n=100, cv=2.43", "n=500, c.v=1.15", "n=1000, cv=0.79", "n=2000, cv=0.56"), 
## +     b .... [TRUNCATED] 
## 
## > axis(1, lwd = 2)
## 
## > axis(2, lwd = 2)
## 
## > plot(density(sample10$mean10, bw = 0.05), col = "black", 
## +     lty = 3, main = "", lwd = 1, ylim = c(0, 8), xlim = c(2.5, 
## +         4.5), axes = F .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-9} \end{center}

\begin{verbatim}
## 
## > lines(density(sample100$mean100, bw = 0.05), col = "black", 
## +     lty = 4, lwd = 1)
## 
## > lines(density(sample500$mean500, bw = 0.05), col = "black", 
## +     lty = 5, lwd = 1)
## 
## > lines(density(sample1000$mean1000, bw = 0.05), col = "black", 
## +     lty = 2, lwd = 1)
## 
## > lines(density(sampleA$meanA, bw = 0.05), col = "black", 
## +     lty = 1, lwd = 2)
## 
## > legend(y = 8, x = 3.9, title = expression(bold("Sample size (n)")), 
## +     c(expression(italic("n") ~ "=" ~ "10"), expression(italic("n") ~ 
## +       .... [TRUNCATED] 
## 
## > axis(1, lwd = 2)
## 
## > axis(2, lwd = 2)
## 
## > rev.one <- bdata$RealCI[1:45]
## 
## > sample.true <- year2013$interval
## 
## > pwr.test.results <- power.t.test(n = 45, delta = seq(0, 
## +     0.99, 0.001), sd = sd(sample.true), alternative = "one.sided", 
## +     sig.level = 0.0 .... [TRUNCATED] 
## 
## > pwr.analysis <- as.data.frame(cbind(pwr.test.results$power, 
## +     pwr.test.results$delta))
## 
## > colnames(pwr.analysis) <- c("Power", "Mean.difference")
## 
## > pwr.analysis.1 <- pwr.analysis %>% mutate(Alpha = 1 - 
## +     Power, Mean.estimate = 3.31 + Mean.difference)
## 
## > a <- filter(pwr.analysis.1, Alpha < 0.05)
## 
## > a[1, ]
##       Power Mean.difference      Alpha Mean.estimate
## 1 0.9501505           0.593 0.04984946         3.903
## 
## > ggplot(data = pwr.analysis.1, aes(x = Mean.estimate, 
## +     y = Alpha)) + geom_line(size = 1.5) + geom_vline(xintercept = 3.903, 
## +     col = "blue" .... [TRUNCATED]
\end{verbatim}

\begin{verbatim}
## 
## > rev.one <- bdata$RealCI[1:45]
## 
## > sample.true <- year2013$interval
## 
## > diff <- 3.63 - 3.31
## 
## > pwr.test.results <- power.t.test(n = seq(1, 200, 1), 
## +     delta = diff, sd = sd(sample.true), alternative = "one.sided", 
## +     sig.level = 0.05)
\end{verbatim}

\begin{verbatim}
## Warning in qt(sig.level/tside, nu, lower.tail = FALSE): NaNs produced
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-10} \end{center}

\begin{verbatim}
## 
## > pwr.analysis <- as.data.frame(cbind(pwr.test.results$power, 
## +     pwr.test.results$n))
## 
## > colnames(pwr.analysis) <- c("Power", "Sample.size")
## 
## > pwr.analysis.1 <- pwr.analysis %>% mutate(Alpha = 1 - 
## +     Power)
## 
## > a <- filter(pwr.analysis.1, Alpha < 0.05)
## 
## > a[1, ]
##       Power Sample.size     Alpha
## 1 0.9503366         153 0.0496634
## 
## > ggplot(data = pwr.analysis.1, aes(x = Sample.size, 
## +     y = Alpha)) + geom_line(size = 1.5) + geom_vline(xintercept = 45, 
## +     col = "red") + ge .... [TRUNCATED]
\end{verbatim}

\begin{verbatim}
## Warning: Removed 1 rows containing missing values (geom_path).
\end{verbatim}

\begin{verbatim}
## 
## > dat <- read.csv("./R/Data/raw_observations_2012.csv")
## 
## > glimpse(dat)
## Observations: 180
## Variables: 10
## $ ID          <fct> AI06006, AI06007, AI06015, AI06022, AI06038, AI100...
## $ X2006       <int> 1, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2007       <int> 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2008       <int> 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,...
## $ X2009       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2010       <int> 0, 0, 2, 0, 0, 6, 6, 5, 5, 3, 4, 2, 5, 4, 5, 3, 2,...
## $ X2011       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ X2012       <int> 0, 1, 2, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 12, 0, 0, 0...
## $ total       <int> 2, 4, 8, 5, 3, 6, 7, 5, 5, 3, 9, 2, 5, 16, 6, 3, 2...
## $ X..yrs.seen <int> 2, 3, 5, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1,...
## 
## > head(dat)
##        ID X2006 X2007 X2008 X2009 X2010 X2011 X2012 total X..yrs.seen
## 1 AI06006     1     0     1     0     0     0     0     2           2
## 2 AI06007     2     1     0     0     0     0     1     4           3
## 3 AI06015     2     1     1     0     2     0     2     8           5
## 4 AI06022     1     0     0     0     0     0     4     5           2
## 5 AI06038     1     0     2     0     0     0     0     3           2
## 6 AI10040     0     0     0     0     6     0     0     6           1
## 
## > dat1 <- read.csv("./R/Data/RawCI.csv", header = T, 
## +     quote = "\"")
## 
## > glimpse(dat1)
## Observations: 41
## Variables: 8
## $ ID            <fct> AI10124, AI10070, AI10086, AI08340, AI08341, AI0...
## $ Yr.first.seen <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves        <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves.1      <int> 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, ...
## $ Calves.2      <int> 2013, 2013, 2013, NA, NA, NA, NA, NA, NA, NA, NA...
## $ Interval.1    <int> 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 6, ...
## $ Interval.2    <int> 3, 3, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ X             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
## 
## > dat3 <- dplyr::select(dat, ID, X2006:X2012) %>% gather(year, 
## +     count, X2006:X2012)
## 
## > dat4 <- full_join(dat3, dat1, by = "ID")
\end{verbatim}

\begin{verbatim}
## Warning: Column `ID` joining factors with different levels, coercing to
## character vector
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-11} \end{center}

\begin{verbatim}
## 
## > dat5 <- dplyr::select(dat4, ID, year, count, Yr.first.seen, 
## +     Calves, Calves.1, Calves.2)
## 
## > dat6 <- filter(dat5, count > 0)
## 
## > glimpse(dat6)
## Observations: 237
## Variables: 7
## $ ID            <chr> "AI06006", "AI06007", "AI06015", "AI06022", "AI0...
## $ year          <chr> "X2006", "X2006", "X2006", "X2006", "X2006", "X2...
## $ count         <int> 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
## $ Yr.first.seen <int> NA, NA, NA, 2006, NA, NA, NA, 2007, 2007, NA, NA...
## $ Calves        <int> NA, NA, NA, 2006, NA, NA, NA, 2007, 2007, NA, NA...
## $ Calves.1      <int> NA, NA, NA, 2012, NA, NA, NA, 2013, 2010, NA, NA...
## $ Calves.2      <int> NA, NA, NA, NA, NA, NA, NA, NA, 2013, NA, NA, 20...
## 
## > dat7 <- mutate(dat6, year = ifelse(year == "X2006", 
## +     "2006", year), year = ifelse(year == "X2007", "2007", year), 
## +     year = ifelse(year == .... [TRUNCATED] 
## 
## > a <- group_by(dat7, ID, Yr.first.seen) %>% mutate(mother = ifelse(Yr.first.seen > 
## +     0, 1, 0)) %>% filter(mother == 1) %>% ungroup() %>% dplyr:: .... [TRUNCATED] 
## 
## > a
## # A tibble: 1 x 4
##   ID      year  Calves Calves.1
##   <chr>   <chr>  <int>    <int>
## 1 AI09216 2007    2009     2011
## 
## > greater.than.2 <- sample.true[sample.true > 2]
## 
## > mean.2 <- sum(greater.than.2)/length(greater.than.2)
## 
## > s.2 <- sd(greater.than.2)
## 
## > SE.2 <- s2013/(sqrt(length(greater.than.2)))
## 
## > n.2 <- length(greater.than.2)
## 
## > low.qt.2 <- mean.2 - (qt(0.975, length(greater.than.2)) * 
## +     SE.2)
## 
## > high.qt.2 <- mean.2 + (qt(0.975, length(greater.than.2)) * 
## +     SE.2)
## 
## > Sumtable[4, ] <- c("miss2year", n.2, mean.2, low.qt.2, 
## +     high.qt.2, sd(greater.than.2))
## 
## > boots <- 1000
## 
## > n <- c(1:1000)
## 
## > detect1 <- 44
## 
## > detect2 <- 42
## 
## > detect3 <- 40
## 
## > sample2 <- rep(NA, 1000)
## 
## > sample5 <- rep(NA, 1000)
## 
## > sample10 <- rep(NA, 1000)
## 
## > for (i in 1:boots) {
## +     sample2[i] <- mean(sample(year2013$interval, detect1, replace = T))
## +     sample5[i] <- mean(sample(year2013$interval, de .... [TRUNCATED] 
## 
## > sample2 <- sort(sample2)
## 
## > sample2.2.5 <- sample2[25]
## 
## > sample2.50 <- sample2[500]
## 
## > sample2.975 <- sample2[975]
## 
## > sample5 <- sort(sample5)
## 
## > sample5.2.5 <- sample5[25]
## 
## > sample5.50 <- sample5[500]
## 
## > sample5.975 <- sample5[975]
## 
## > sample10 <- sort(sample10)
## 
## > sample10.2.5 <- sample10[25]
## 
## > sample10.50 <- sample10[500]
## 
## > sample10.975 <- sample10[975]
## 
## > Sumtable[5, ] <- c("detect1", detect1, sample2.50, 
## +     sample2.2.5, sample2.975, NA)
## 
## > Sumtable[6, ] <- c("detect2", detect2, sample5.50, 
## +     sample5.2.5, sample5.975, NA)
## 
## > Sumtable[7, ] <- c("detect5", detect3, sample10.50, 
## +     sample10.2.5, sample10.975, NA)
## 
## > length(Data$ID)
## [1] 41
## 
## > length(dat$ID)
## [1] 180
## 
## > glimpse(Data)
## Observations: 41
## Variables: 8
## $ ID            <fct> AI10124, AI10070, AI10086, AI08340, AI08341, AI0...
## $ Yr.first.seen <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves        <int> 2007, 2008, 2007, 2008, 2008, 2008, 2008, 2008, ...
## $ Calves.1      <int> 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, ...
## $ Calves.2      <int> 2013, 2013, 2013, NA, NA, NA, NA, NA, NA, NA, NA...
## $ Interval.1    <int> 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 6, ...
## $ Interval.2    <int> 3, 3, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ X             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
## 
## > dat.detect <- dplyr::select(Data, ID, Calves, Calves.1, 
## +     Calves.2) %>% mutate(Calves = factor(Calves), Calves.1 = factor(Calves.1), 
## +     Cal .... [TRUNCATED] 
## 
## > a <- as.data.frame.matrix(table(Data$ID, Data$Calves))
## 
## > head(a)
##         2006 2007 2008 2009 2010 2011
## AI06022    1    0    0    0    0    0
## AI08340    0    0    1    0    0    0
## AI08341    0    0    1    0    0    0
## AI08343    0    0    1    0    0    0
## AI08355    0    0    1    0    0    0
## AI08362    0    0    1    0    0    0
## 
## > a[, 7] <- row.names(a)
## 
## > colnames(a)[1] <- "y2006"
## 
## > colnames(a)[2] <- "y2007"
## 
## > colnames(a)[3] <- "y2008"
## 
## > colnames(a)[4] <- "y2009"
## 
## > colnames(a)[5] <- "y2010"
## 
## > colnames(a)[6] <- "y2011"
## 
## > colnames(a)[7] <- "ID"
## 
## > a[, 8] <- 0
## 
## > colnames(a)[8] <- "y2012"
## 
## > a[, 9] <- 0
## 
## > colnames(a)[9] <- "y2013"
## 
## > a <- dplyr::select(a, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > b <- as.data.frame.matrix(table(Data$ID, Data$Calves.1))
## 
## > head(b)
##         2010 2011 2012 2013
## AI06022    0    0    1    0
## AI08340    0    1    0    0
## AI08341    0    1    0    0
## AI08343    0    0    0    1
## AI08355    0    1    0    0
## AI08362    0    1    0    0
## 
## > b[, 5] <- row.names(b)
## 
## > colnames(b)[5] <- "ID"
## 
## > b[, 6] <- 0
## 
## > colnames(b)[6] <- "y2006"
## 
## > b[, 7] <- 0
## 
## > colnames(b)[7] <- "y2007"
## 
## > b[, 8] <- 0
## 
## > colnames(b)[8] <- "y2008"
## 
## > b[, 9] <- 0
## 
## > colnames(b)[9] <- "y2009"
## 
## > colnames(b)[1] <- "y2010"
## 
## > colnames(b)[2] <- "y2011"
## 
## > colnames(b)[3] <- "y2012"
## 
## > colnames(b)[4] <- "y2013"
## 
## > b <- dplyr::select(b, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > c <- as.data.frame.matrix(table(Data$ID, Data$Calves.2))
## 
## > head(c)
##         2013
## AI06022    0
## AI08340    0
## AI08341    0
## AI08343    0
## AI08355    0
## AI08362    0
## 
## > colnames(c)[1] <- "y2013"
## 
## > c[, 2] <- row.names(c)
## 
## > colnames(c)[2] <- "ID"
## 
## > c[, 3] <- 0
## 
## > colnames(c)[3] <- "y2006"
## 
## > c[, 4] <- 0
## 
## > colnames(c)[4] <- "y2007"
## 
## > c[, 5] <- 0
## 
## > colnames(c)[5] <- "y2008"
## 
## > c[, 6] <- 0
## 
## > colnames(c)[6] <- "y2009"
## 
## > c[, 7] <- 0
## 
## > colnames(c)[7] <- "y2010"
## 
## > c[, 8] <- 0
## 
## > colnames(c)[8] <- "y2011"
## 
## > c[, 9] <- 0
## 
## > colnames(c)[9] <- "y2012"
## 
## > c <- dplyr::select(c, ID, y2006, y2007, y2008, y2009, 
## +     y2010, y2011, y2012, y2013)
## 
## > countdat <- rbind(a, b, c)
## 
## > glimpse(countdat)
## Observations: 123
## Variables: 9
## $ ID    <chr> "AI06022", "AI08340", "AI08341", "AI08343", "AI08355", "...
## $ y2006 <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2007 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2008 <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,...
## $ y2009 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...
## $ y2010 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2011 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2012 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ y2013 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## 
## > full.dat <- group_by(countdat, ID) %>% summarise(y2006 = sum(y2006), 
## +     y2007 = sum(y2007), y2008 = sum(y2008), y2009 = sum(y2009), 
## +     y2010 .... [TRUNCATED] 
## 
## > 2012 - 2006
## [1] 6
## 
## > sort(Data$ID)
##  [1] AI06022 AI08340 AI08341 AI08343 AI08355 AI08362 AI08364 AI08365
##  [9] AI08372 AI08378 AI08379 AI08383 AI08386 AI08387 AI08390 AI08395
## [17] AI08403 AI09216 AI09217 AI09221 AI09224 AI09225 AI09247 AI09249
## [25] AI09259 AI09265 AI09289 AI10043 AI10056 AI10070 AI10085 AI10086
## [33] AI10102 AI10124 AI10144 AI10160 AI10167 AI10170 AI10177 AI11408
## [41] AI11430
## 41 Levels: AI06022 AI08340 AI08341 AI08343 AI08355 AI08362 ... AI11430
## 
## > filter(Data, ID == "AI06022")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI06022          2006   2006     2012       NA          6         NA NA
## 
## > filter(Data, ID == "AI08340")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI08340          2008   2008     2011       NA          3         NA NA
## 
## > filter(Data, ID == "AI08343")
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI08343          2008   2008     2013       NA          5         NA NA
## 
## > head(Data)
##        ID Yr.first.seen Calves Calves.1 Calves.2 Interval.1 Interval.2  X
## 1 AI10124          2007   2007     2010     2013          3          3 NA
## 2 AI10070          2008   2008     2010     2013          2          3 NA
## 3 AI10086          2007   2007     2010     2013          3          3 NA
## 4 AI08340          2008   2008     2011       NA          3         NA NA
## 5 AI08341          2008   2008     2011       NA          3         NA NA
## 6 AI08355          2008   2008     2011       NA          3         NA NA
## 
## > longer5.6 <- c(sample.true, 5, 6, 6)
## 
## > mean.56 <- sum(longer5.6)/length(longer5.6)
## 
## > s.56 <- sd(longer5.6)
## 
## > SE.56 <- s.56/(sqrt(length(longer5.6)))
## 
## > n.56 <- (length(longer5.6))
## 
## > low.qt.56 <- mean.56 - (qt(0.975, length(longer5.6)) * 
## +     SE.56)
## 
## > high.qt.56 <- mean.56 + (qt(0.975, length(longer5.6)) * 
## +     SE.56)
## 
## > Sumtable[8, ] <- c("longer.56", n.56, mean.56, low.qt.56, 
## +     high.qt.56, sd(longer5.6))
## 
## > Sumtable <- as.data.frame(Sumtable)
## 
## > Sumtable$n <- as.numeric(as.character(Sumtable$n))
## 
## > Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
## 
## > Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
## 
## > Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
## 
## > Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
## 
## > Sumtable$interval <- as.character(Sumtable$interval)
## 
## > library(knitr)
## 
## > kable(Sumtable, format = "markdown", col.names = c("Interval", 
## +     "Sample size", "Mean", "Lower limit", "Higher limit", "SD"))
## 
## 
## |Interval  | Sample size|     Mean| Lower limit| Higher limit|        SD|
## |:---------|-----------:|--------:|-----------:|------------:|---------:|
## |Low       |          58| 2.568966|    2.437666|     2.700265| 0.4995461|
## |Medium    |          48| 3.104167|    2.943089|     3.265244| 0.5550382|
## |Observed  |          45| 3.311111|    3.056488|     3.565734| 0.8480518|
## |miss2year |          41| 3.439024|    3.171549|     3.706499| 0.7761695|
## |detect1   |          44| 3.295454|    3.090909|     3.545454|        NA|
## |detect2   |          42| 3.309524|    3.071429|     3.571429|        NA|
## |detect5   |          40| 3.300000|    3.075000|     3.575000|        NA|
## |longer.56 |          48| 3.458333|    3.165307|     3.751360| 1.0097047|
## 
## > ggplot(Sumtable, aes(y = mY, x = interval)) + geom_point(size = 5) + 
## +     geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05, 
## +       .... [TRUNCATED]
\end{verbatim}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-127-12} \end{center}

\hypertarget{plot-steps-2}{%
\subsection{Plot steps}\label{plot-steps-2}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## ----raw graph, echo=FALSE, message=FALSE, warning=FALSE-----------------}
\CommentTok{#plot data}
\KeywordTok{ggplot}\NormalTok{(sum.dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ mY, }\DataTypeTok{x =}\NormalTok{ year)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ low.qt, }\DataTypeTok{ymax =}\NormalTok{ high.qt), }\DataTypeTok{width =} \FloatTok{0.1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{A-beginners-guide-to-population-dynamics_files/figure-latex/unnamed-chunk-128-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ## ----raw graph 2, echo=FALSE, fig.height=6, fig.width=6, message=FALSE, warning=FALSE----}
\CommentTok{# }
\CommentTok{# #PLOTS}
\CommentTok{# par(mfrow=c(2,2))}
\CommentTok{# }
\CommentTok{# plot(factor(year2010),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="a)",sub="Sample size 3", ylab="Frequency",xlab="Calving interval",}
\CommentTok{#       cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2011),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="b)",sub="Sample size 15", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2012),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="c)",sub="Sample size 25", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# plot(factor(year2013),xlim=c(0,6),ylim=c(0,40))}
\CommentTok{# title(main="d)",sub="Sample size 45", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",}
\CommentTok{#       cex.sub = 1, font.sub = 3, col.sub = "red")}
\CommentTok{# box()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----raw graph 3, echo=FALSE, fig.height=6, fig.width=6, message=TRUE, warning=TRUE----}
\CommentTok{# library(qpcR)}
\CommentTok{# #data in one way for plot}
\CommentTok{# rawdata <- qpcR:::cbind.na(year2010,year2011,year2012,year2013)}
\CommentTok{# rawdata <- as.data.frame(rawdata)}
\CommentTok{# }
\CommentTok{# #in correct format for ggplot2}
\CommentTok{# year2010 <- data.frame(year2010,year = c("2010"))}
\CommentTok{# year2010 <- rename(year2010, interval = year2010, year = year )}
\CommentTok{# year2011 <- data.frame(year2011,year = c("2011"))}
\CommentTok{# year2011 <- rename(year2011, interval = year2011, year = year )}
\CommentTok{# year2012 <- data.frame(year2012,year = c("2012"))}
\CommentTok{# year2012 <- rename(year2012, interval = year2012, year = year )}
\CommentTok{# year2013 <- data.frame(year2013,year = c("2013"))}
\CommentTok{# year2013 <- rename(year2013, interval = year2013, year = year )}
\CommentTok{# ggplotraw <- rbind(year2010,year2011,year2012, year2013)}
\CommentTok{# ggplotraw$interval <- as.numeric(as.character(ggplotraw$interval))}
\CommentTok{# }
\CommentTok{# #sort(year2013$interval) - sort(sample.true)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ggplot(year2013,aes(x = interval)) +}
\CommentTok{#     geom_bar(alpha = 1, width = 0.9,fill = "black") +}
\CommentTok{#     xlab(expression("Calving"~"interval"~(italic("years")))) +}
\CommentTok{#     ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +}
\CommentTok{#     scale_y_continuous(breaks = c(0,5,10,15,20,25,30), limits = c(0,30)) +}
\CommentTok{#     theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black"))}
\CommentTok{# #PLOTS}
\CommentTok{# #code to store figure}
\CommentTok{# # png("Figure_2_NZSRW_calving_interval_2017_highres.png", width = 12, height = 14.8, units = 'cm', res = 1200)}
\CommentTok{# # dev.off()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals, echo=FALSE, fig.height=10, message=FALSE, warning=FALSE----}
\CommentTok{# #################################Missing calving intervals################}
\CommentTok{# #Intervals modified by accounting for missed intervals}
\CommentTok{# #Bradford et al. 2008}
\CommentTok{# }
\CommentTok{# #Raw Data}
\CommentTok{# RealCI <- as.numeric(year2013$interval)}
\CommentTok{# }
\CommentTok{# #Confidence interval}
\CommentTok{# xlong <- RealCI}
\CommentTok{# meanlong<-sum(xlong)/length(xlong)}
\CommentTok{# slong<-sd(xlong)}
\CommentTok{# SElong<-slong/(sqrt(length(xlong)))}
\CommentTok{# nlong<-(length(xlong))}
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# #2 sided t value at the 95% level = 2.093}
\CommentTok{# lowqtlong <- meanlong-(qt(0.975,nlong)*SElong)}
\CommentTok{# highqtlong <- meanlong+(qt(0.975,nlong)*SElong)}
\CommentTok{# }
\CommentTok{# ####################MED CI########################################}
\CommentTok{# # 2x 6's and 1x 5 replaced with 3threes}
\CommentTok{# MedCI <- c(RealCI[RealCI < 5],3,3,3,3,2,3)}
\CommentTok{# #sort(MedCI)}
\CommentTok{# xmed<-MedCI}
\CommentTok{# meanmed<-sum(xmed)/length(xmed)}
\CommentTok{# smed<-sd(xmed)}
\CommentTok{# SEmed<-smed/(sqrt(length(xmed)))}
\CommentTok{# nmed<-(length(xmed))}
\CommentTok{# }
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# lowqtmed <- meanmed-(qt(0.975,length(xmed))*SEmed)}
\CommentTok{# highqtmed <- meanmed+(qt(0.975,length(xmed))*SEmed)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ############################SHORT CI##################################}
\CommentTok{# #6,5 replaced with 2 year intervals}
\CommentTok{# }
\CommentTok{# LowCI <- c(RealCI[RealCI < 4],3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)}
\CommentTok{# xshort<-LowCI}
\CommentTok{# meanshort<-mean(xshort)}
\CommentTok{# sshort<-sd(xshort)}
\CommentTok{# SEshort<-sshort/(sqrt(length(xshort)))}
\CommentTok{# }
\CommentTok{# #Standard error and confidence intervals}
\CommentTok{# lowqtshort <- meanshort-(qt(0.975,length(xshort))*SEshort)}
\CommentTok{# highqtshort <- meanshort+(qt(0.975,length(xshort))*SEshort)}
\CommentTok{# }
\CommentTok{# bdata <-qpcR:::cbind.na(RealCI,MedCI,LowCI)}
\CommentTok{# bdata <- as.data.frame(bdata)}
\CommentTok{# }
\CommentTok{# #Structure of data set}
\CommentTok{# #str(bdata)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot, echo=FALSE, fig.height=3.5, fig.width=5.5, message=FALSE, warning=FALSE----}
\CommentTok{# #Basic plots}
\CommentTok{# par(mfrow=c(1,3))}
\CommentTok{# plot(factor(bdata$LowCI),main="Lowest possible interval")}
\CommentTok{# plot(factor(bdata$MedCI), main="Medium possible interval")}
\CommentTok{# plot(factor(bdata$RealCI),main="Observed interval")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot2, fig.height=5.5, fig.width=4.5, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# #Density basic plots}
\CommentTok{# par(mfrow=c(3,1))}
\CommentTok{# plot(density(as.numeric(as.character(LowCI)),bw=.5), main="Lowest possible interval")}
\CommentTok{# plot(density(as.numeric(as.character(MedCI)),bw= 0.5), main="Medium possible interval")}
\CommentTok{# plot(density(as.numeric(as.character(RealCI)),bw = 0.5),main="Observed interval")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals table, fig.height=8, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# }
\CommentTok{# ###################################SUMMARY############################}
\CommentTok{# #Pull out important information}
\CommentTok{# Sumtable<-data.frame(variable = c("low.qt","mean","high.qt","sd", "SE"),                 short=c(lowqtshort,meanshort,highqtshort,sshort,SEshort),}
\CommentTok{#                      medium=c(lowqtmed,meanmed,highqtmed,smed,SEmed),}
\CommentTok{#                      real=c(lowqtlong,meanlong,highqtlong,slong,SElong))}
\CommentTok{# }
\CommentTok{# #Make dataframe to plot}
\CommentTok{# n <- c(length(LowCI),length(MedCI),length(year2013$interval))}
\CommentTok{# mY <- c(mean(LowCI),mean(MedCI),mean(year2013$interval))}
\CommentTok{# interval <-c("Low", "Medium","Observed")}
\CommentTok{# low.qt <- c(lowqtshort,lowqtmed,low.qt2013)}
\CommentTok{# high.qt <- c(highqtshort,highqtmed,high.qt2013)}
\CommentTok{# sd <- c(sshort,smed,s2013)}
\CommentTok{# Sumtable <- cbind(interval,n,mY,low.qt,high.qt,sd)}
\CommentTok{# Sumtable <-  as.data.frame(Sumtable)}
\CommentTok{# }
\CommentTok{#  Sumtable$n <- as.numeric(as.character(Sumtable$n))}
\CommentTok{#  Sumtable$mY <- as.numeric(as.character(Sumtable$mY))}
\CommentTok{#  Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))}
\CommentTok{#  Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))}
\CommentTok{#  Sumtable$sd <- as.numeric(as.character(Sumtable$sd))}
\CommentTok{#  Sumtable$interval <- as.character(Sumtable$interval)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing intervals plot3, echo=FALSE, fig.height=4, message=FALSE, warning=FALSE----}
\CommentTok{# ggplot(Sumtable, aes(y = mY, x = interval)) +}
\CommentTok{#   geom_point(size = 5) +}
\CommentTok{#   geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +}
\CommentTok{#   scale_y_continuous(breaks = round(seq(2.3, 3.6, by = 0.2),1)) +}
\CommentTok{#   labs(y = "Mean calving interval",x = "Calving interval modification" ) +}
\CommentTok{#   geom_point(size = 3) +}
\CommentTok{#   theme_classic() +}
\CommentTok{#   theme_hc() +}
\CommentTok{#   theme(legend.position="none")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing_data_table, echo=FALSE--------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# }
\CommentTok{# kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----srw_data_table, echo=FALSE------------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# setwd("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data")}
\CommentTok{# srwdat <- read.csv(file = "srw_data.csv")}
\CommentTok{# }
\CommentTok{# #str(srwdat)}
\CommentTok{# kable(srwdat, format = "markdown",col.names = c("Sample size","Mean", "Lower limit", "Higher limit", "SE","Author", "Location"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap single, echo=FALSE, fig.height=5--------------------------}
\CommentTok{# ############################NZ Simple sample##############################}
\CommentTok{# #WITH replacement}
\CommentTok{# }
\CommentTok{# # to try and match number of intervals observed in other populations}
\CommentTok{# # find references}
\CommentTok{# SAreps <- 1500}
\CommentTok{# ARreps <- 800}
\CommentTok{# Aussiereps <- 2000}
\CommentTok{# low <- 1000}
\CommentTok{# verylow <- 100}
\CommentTok{# lowest <- 10}
\CommentTok{# }
\CommentTok{# #Very raw plots}
\CommentTok{# par(mfrow=c(2,3))}
\CommentTok{# plot(factor(sample(year2013$interval,lowest,replace=T)),main = "3 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,verylow,replace=T)),main = "10 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,low,replace=T)),main = "30 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,Aussiereps,replace=T)),main = "500 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,ARreps,replace=T)),main = "800 intervals")}
\CommentTok{# plot(factor(sample(year2013$interval,SAreps,replace=T)),main = "1500 intervals")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap_multiple, echo=FALSE--------------------------------------}
\CommentTok{# #do each one 1000 times}
\CommentTok{# boots <- 1000}
\CommentTok{# n <- c(1:1000)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ###########################n10}
\CommentTok{# var10 <- paste0("n_", 1:10)}
\CommentTok{# sample10 <-matrix(data = NA, ncol = lowest, nrow = boots)}
\CommentTok{# colnames(sample10) <- as.list(var10)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample10 [i, ] <- sample(year2013$interval,lowest,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample10 <- as.data.frame(sample10)}
\CommentTok{# sample10 <- sample10 %>%}
\CommentTok{#             mutate(mean10 = rowMeans(sample10))}
\CommentTok{# }
\CommentTok{# sample10t <- as.matrix(sample10)}
\CommentTok{# sample10t <-t(sample10t)}
\CommentTok{# }
\CommentTok{# #########################verylow sample size}
\CommentTok{# #set up variable names}
\CommentTok{# var100 <- paste0("n_", 1:100)}
\CommentTok{# }
\CommentTok{# sample100 <-matrix(data = NA, ncol = verylow, nrow = boots)}
\CommentTok{# colnames(sample100) <- as.list(var100)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample100 [i, ] <- sample(year2013$interval,verylow,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample100 <- as.data.frame(sample100)}
\CommentTok{# sample100 <- sample100 %>%}
\CommentTok{#             mutate(mean100 = rowMeans(sample100))}
\CommentTok{# }
\CommentTok{# #########################middle one}
\CommentTok{# #set up variable names}
\CommentTok{# var500 <- paste0("n_", 1:500)}
\CommentTok{# }
\CommentTok{# sample500 <-matrix(data = NA, ncol = 500, nrow = boots)}
\CommentTok{# colnames(sample500) <- as.list(var500)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample500 [i, ] <- sample(year2013$interval,500,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample500 <- as.data.frame(sample500)}
\CommentTok{# sample500 <- sample500 %>%}
\CommentTok{#             mutate(mean500 = rowMeans(sample500))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #########################low sample size}
\CommentTok{# #set up variable names}
\CommentTok{# var1000 <- paste0("n_", 1:1000)}
\CommentTok{# }
\CommentTok{# sample1000 <-matrix(data = NA, ncol = low, nrow = boots)}
\CommentTok{# colnames(sample1000) <- as.list(var1000)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample1000 [i, ] <- sample(year2013$interval,low,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sample1000 <- as.data.frame(sample1000)}
\CommentTok{# sample1000 <- sample1000 %>%}
\CommentTok{#             mutate(mean1000 = rowMeans(sample1000))}
\CommentTok{# }
\CommentTok{# #########################AUS sample size}
\CommentTok{# #set up variable names}
\CommentTok{# varA <- paste0("n_", 1:2000)}
\CommentTok{# }
\CommentTok{# sampleA <-matrix(data = NA, ncol = Aussiereps, nrow =  boots)}
\CommentTok{# colnames(sampleA) <- as.list(varA)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sampleA [i, ] <- sample(year2013$interval,Aussiereps,replace=T)}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# sampleA <- as.data.frame(sampleA)}
\CommentTok{# sampleA <- sampleA %>%}
\CommentTok{#             mutate(meanA = rowMeans(sampleA))}
\CommentTok{# }
\CommentTok{# sampleAt <- t(sampleA)}
\CommentTok{# }
\CommentTok{# for(i in c(1:ncol(sampleA))) \{}
\CommentTok{#     sampleA[,i] <- as.numeric(as.character(sampleA[,i]))}
\CommentTok{# \}}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #COnfidence intervals}
\CommentTok{# }
\CommentTok{# ab <- sort(sampleA$meanA)}
\CommentTok{# nab <- length(ab)}
\CommentTok{# #low = 25/1000}
\CommentTok{# ab2.5 <- ab[25]}
\CommentTok{# #high = 975/1000}
\CommentTok{# ab0.97.5 <- ab[975]}
\CommentTok{# }
\CommentTok{# ab <- sort(sampleA$meanA)}
\CommentTok{# nab <- length(ab)}
\CommentTok{# #low = 25/1000}
\CommentTok{# ab2.5 <- ab[25]}
\CommentTok{# #high = 975/1000}
\CommentTok{# ab0.97.5 <- ab[975]}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----bootstrap plot2, fig.height=5, message=FALSE, warning=FALSE, include=FALSE----}
\CommentTok{# #plot the data over each other to look at change in density}
\CommentTok{# par(mfrow=c(1,1))}
\CommentTok{# #plot(density(sample3$mean3,bw = .15),lwd = 3,lyt = 5, main = "", xlab = "Calving interval", box = FALSE,axis = FALSE)}
\CommentTok{# }
\CommentTok{# plot(density(sample10$mean10,bw = .05),col ="black", lty = 1, main = "", lwd = 5,ylim = c(0,8),xlim = c(2,4.5), axes=FALSE,xlab = "Calving interval")}
\CommentTok{# lines(density(sample100$mean100,bw = .05),col ="black", lty = 2, lwd = 4)}
\CommentTok{# lines(density(sample500$mean500,bw = .05),col ="black", lty = 3, lwd = 3)}
\CommentTok{# lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 4, lwd = 2)}
\CommentTok{# lines(density(sampleA$meanA,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# legend('topright',title = "Legend", c("n=10, cv=8.12 ", "n=100, cv=2.43", "n=500, c.v=1.15", "n=1000, cv=0.79", "n=2000, cv=0.56"),bty = "n",}
\CommentTok{#   lty = c(1,2,3,4,5), lwd = c(5,4,3,2,1), cex=.75)}
\CommentTok{# axis(1,lwd=2)}
\CommentTok{# axis(2,lwd=2)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----final plot for publication1, echo=FALSE-----------------------------}
\CommentTok{# #final [plot]}
\CommentTok{# #size defined by NZJFMR}
\CommentTok{# #  195 mm (h) ? 148 mm (w).}
\CommentTok{# #ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +}
\CommentTok{# }
\CommentTok{# plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE, xlab = expression("Calving"~"interval"~(italic("years"))))}
\CommentTok{# lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)}
\CommentTok{# lines(density(sample500$mean500,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 2, lwd = 1)}
\CommentTok{# lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)}
\CommentTok{# legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",}
\CommentTok{#   lty = c(3,4,5,2,1), lwd = c(1,1,1,1,2), cex=1)}
\CommentTok{#  axis(1,lwd=2)}
\CommentTok{# axis(2,lwd=2)}
\CommentTok{# }
\CommentTok{# # PLOT CODE FOR PUBLICATION}
\CommentTok{# # png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_lowres.png", width = 14.8, height = 14.8, units = 'cm', res = 400)}
\CommentTok{# # dev.off()}
\CommentTok{# #}
\CommentTok{# #}
\CommentTok{# # png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_highres.png", width = 14.8, height = 14.8, units = 'cm', res = 1200)}
\CommentTok{# #}
\CommentTok{# # plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE,xlab = expression("Calving"~"interval"~(italic("years"))))}
\CommentTok{# # lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)}
\CommentTok{# # lines(density(sample500$mean500,bw = .05),col ="black", lty = 2, lwd = 1)}
\CommentTok{# # lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 5, lwd = 1)}
\CommentTok{# # lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)}
\CommentTok{# # legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",}
\CommentTok{# #   lty = c(3,4,2,5,1), lwd = c(1,1,1,1,2), cex=1)}
\CommentTok{# # axis(1,lwd=2)}
\CommentTok{# # axis(2,lwd=2)}
\CommentTok{# #}
\CommentTok{# # dev.off()}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_1, echo=TRUE----------------------------------------}
\CommentTok{# #observed sample}
\CommentTok{# rev.one <- bdata$RealCI[1:45]}
\CommentTok{# }
\CommentTok{# #sample 45 times}
\CommentTok{# sample.true <- year2013$interval}
\CommentTok{# }
\CommentTok{# #power analysis}
\CommentTok{# pwr.test.results <- power.t.test(n = 45,# sample size}
\CommentTok{#              delta = seq(0,0.99,0.001),  #difference between means}
\CommentTok{#              sd = sd(sample.true),      #observed variation}
\CommentTok{#              alternative = "one.sided", #observed test type}
\CommentTok{#              sig.level = 0.05)          #significance level}
\CommentTok{# }
\CommentTok{# #additional packages are avaliable for more complex analysis}
\CommentTok{# #but have not done this as don't think it is needed}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_1_plot, echo=FALSE, message=FALSE, warning=FALSE----}
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis <- as.data.frame(cbind(}
\CommentTok{#                               pwr.test.results$power,}
\CommentTok{#                               pwr.test.results$delta))}
\CommentTok{# }
\CommentTok{# colnames(pwr.analysis) <- c("Power","Mean.difference")}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis.1 <- pwr.analysis %>%}
\CommentTok{#   mutate(Alpha = 1- Power,}
\CommentTok{#          Mean.estimate = 3.31 + Mean.difference)}
\CommentTok{# # %>%}
\CommentTok{# #   select(Alpha,Mean.estimate)}
\CommentTok{# }
\CommentTok{# #work out where the cut-off is}
\CommentTok{# a <- filter(pwr.analysis.1, Alpha < 0.05)}
\CommentTok{# a[1,]}
\CommentTok{# }
\CommentTok{# #plot data}
\CommentTok{# ggplot(data = pwr.analysis.1, aes(x = Mean.estimate, y = Alpha)) +}
\CommentTok{#   geom_line(size = 1.5) +}
\CommentTok{#   geom_vline(xintercept = 3.903, col = "blue") +}
\CommentTok{#   geom_hline(yintercept = 0.05) +}
\CommentTok{#   theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black")) +}
\CommentTok{#   ggtitle("Raw data result plot (n = 45)")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment_2_plot, echo=FALSE, message=FALSE, warning=FALSE----}
\CommentTok{# #observed sample}
\CommentTok{# rev.one <- bdata$RealCI[1:45]}
\CommentTok{# }
\CommentTok{# #sample 45 times}
\CommentTok{# sample.true <- year2013$interval}
\CommentTok{# }
\CommentTok{# #difference}
\CommentTok{# diff <- 3.63-3.31  #observed mean of australian population}
\CommentTok{# }
\CommentTok{# #power analysis}
\CommentTok{# pwr.test.results <- power.t.test(n = seq(1,200,1),# sample size}
\CommentTok{#              delta = diff,  #difference between means}
\CommentTok{#              sd = sd(sample.true),      #observed variation}
\CommentTok{#              alternative = "one.sided", #observed test type}
\CommentTok{#              sig.level = 0.05)          #significance level}
\CommentTok{# }
\CommentTok{# #additional packages are avaliable for more complex analysis}
\CommentTok{# #but have not done this as don't think it is needed}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis <- as.data.frame(cbind(}
\CommentTok{#                               pwr.test.results$power,}
\CommentTok{#                               pwr.test.results$n))}
\CommentTok{# }
\CommentTok{# colnames(pwr.analysis) <- c("Power","Sample.size")}
\CommentTok{# }
\CommentTok{# #sort data into ggplot format}
\CommentTok{# pwr.analysis.1 <- pwr.analysis %>%}
\CommentTok{#   mutate(Alpha = 1- Power)}
\CommentTok{# # %>%}
\CommentTok{# #   select(Alpha,Mean.estimate)}
\CommentTok{# }
\CommentTok{# #work out where the cut-off is}
\CommentTok{# a <- filter(pwr.analysis.1, Alpha < 0.05)}
\CommentTok{# a[1,]}
\CommentTok{# }
\CommentTok{# #plot data}
\CommentTok{# ggplot(data = pwr.analysis.1, aes(x = Sample.size, y = Alpha)) +}
\CommentTok{#   geom_line(size = 1.5) +}
\CommentTok{#   geom_vline(xintercept = 45, col = "red") +}
\CommentTok{#   geom_vline(xintercept = 153, col = "blue") +}
\CommentTok{#   geom_hline(yintercept = 0.05) +}
\CommentTok{#   scale_y_continuous(limits = c(0,1)) +}
\CommentTok{#   theme(axis.line = element_line(colour = 'black', size = 0.65),}
\CommentTok{#           axis.ticks = element_line(colour = "black", size = 0.65),}
\CommentTok{#           panel.border = element_blank(),}
\CommentTok{#           panel.grid.major = element_blank(),}
\CommentTok{#           panel.grid.minor = element_blank(),}
\CommentTok{#           legend.key = element_blank(),}
\CommentTok{#           strip.background = element_rect(fill = "white", colour = "black", size = 1),}
\CommentTok{#           panel.background = element_rect(fill = "white",}
\CommentTok{#             colour = NA),}
\CommentTok{#           axis.text = element_text(size = rel(0.8),}
\CommentTok{#             colour = "black")) +}
\CommentTok{#    ggtitle("Observed difference between Australian and NZ mean")}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missed individuals 1, echo=FALSE------------------------------------}
\CommentTok{# dat <- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/raw_observations_2012.csv")}
\CommentTok{# #data structure}
\CommentTok{# glimpse(dat)}
\CommentTok{# head(dat)}
\CommentTok{# #And the second dataset}
\CommentTok{# dat1<- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/RawCI.csv", header=T, quote="\textbackslash{}"")}
\CommentTok{# #data structure}
\CommentTok{# glimpse(dat1)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missed individuals 2, echo=FALSE, message=FALSE, warning=FALSE------}
\CommentTok{# ##I can then modify this data to}
\CommentTok{# #restructure dataset of capture to long dataset}
\CommentTok{# dat3 <- dplyr::select(dat, ID, X2006:X2012)%>%}
\CommentTok{#                gather(year, count,X2006:X2012)}
\CommentTok{# }
\CommentTok{# #add data on calves}
\CommentTok{# dat4 <- full_join(dat3,dat1, by = "ID")}
\CommentTok{# dat5 <- dplyr::select(dat4,ID,year,count,Yr.first.seen,Calves,Calves.1,Calves.2)}
\CommentTok{# }
\CommentTok{# dat6 <- filter(dat5,count >0)}
\CommentTok{# glimpse(dat6)}
\CommentTok{# }
\CommentTok{# dat7 <- mutate(dat6, year = ifelse(year == "X2006","2006", year),}
\CommentTok{#             year = ifelse(year == "X2007","2007", year),}
\CommentTok{#             year = ifelse(year == "X2008","2008", year),}
\CommentTok{#             year = ifelse(year == "X2009","2009", year),}
\CommentTok{#             year = ifelse(year == "X2010","2010", year),}
\CommentTok{#             year = ifelse(year == "X2011","2011", year),}
\CommentTok{#             year = ifelse(year == "X2012","2012", year))}
\CommentTok{# }
\CommentTok{# a <- group_by(dat7, ID, Yr.first.seen) %>%}
\CommentTok{#   mutate(mother = ifelse(Yr.first.seen > 0, 1, 0)) %>%}
\CommentTok{#   filter(mother == 1) %>%}
\CommentTok{#   ungroup() %>%}
\CommentTok{#   dplyr::select(ID,year,Calves,Calves.1) %>%}
\CommentTok{#   filter(Calves.1<2013) %>%}
\CommentTok{#   filter(!year == Calves) %>%}
\CommentTok{# filter(!year ==Calves.1)}
\CommentTok{# }
\CommentTok{# a}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment3, echo=TRUE, message=FALSE, warning=FALSE-----------}
\CommentTok{# greater.than.2 <- sample.true[sample.true>2]}
\CommentTok{# }
\CommentTok{# #greater.than.2}
\CommentTok{# mean.2<-sum(greater.than.2)/length(greater.than.2)}
\CommentTok{# s.2<-sd(greater.than.2)}
\CommentTok{# SE.2<-s2013/(sqrt(length(greater.than.2)))}
\CommentTok{# n.2<-length(greater.than.2)}
\CommentTok{# low.qt.2<- mean.2-(qt(0.975,length(greater.than.2))*SE.2)}
\CommentTok{# high.qt.2 <- mean.2+(qt(0.975,length(greater.than.2))*SE.2)}
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[4,] <- c("miss2year",n.2,mean.2,low.qt.2,}
\CommentTok{#                   high.qt.2,sd(greater.than.2))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----different missing intervals 1, echo=TRUE----------------------------}
\CommentTok{# ########################### 2.2%}
\CommentTok{# #parameters}
\CommentTok{# boots <- 1000}
\CommentTok{# n <- c(1:1000)}
\CommentTok{# }
\CommentTok{# ###round all percentages upwards}
\CommentTok{# detect1 <- 44  # (45*1.02) - 45 = 0.9}
\CommentTok{# detect2 <- 42   #  (45*1.05) - 45 = 2.25}
\CommentTok{# detect3 <- 40  # (45*1.10) - 45 = 4.5}
\CommentTok{# }
\CommentTok{# sample2 <-rep(NA, 1000)}
\CommentTok{# sample5 <-rep(NA, 1000)}
\CommentTok{# sample10 <-rep(NA, 1000)}
\CommentTok{# }
\CommentTok{# for (i in 1:boots) \{}
\CommentTok{#                     sample2[i]<-mean(sample(year2013$interval,detect1,replace=T))}
\CommentTok{#                     sample5[i]<-mean(sample(year2013$interval,detect2,replace=T))}
\CommentTok{#                     sample10[i]<-mean(sample(year2013$interval,detect3,replace=T))}
\CommentTok{#                         \}  #i}
\CommentTok{# }
\CommentTok{# ######################estimates##############}
\CommentTok{# sample2 <- sort(sample2)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample2.2.5 <- sample2[25]}
\CommentTok{# #median}
\CommentTok{# sample2.50 <- sample2[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample2.975 <- sample2[975]}
\CommentTok{# }
\CommentTok{# sample5 <- sort(sample5)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample5.2.5 <- sample5[25]}
\CommentTok{# #median}
\CommentTok{# sample5.50 <- sample5[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample5.975 <- sample5[975]}
\CommentTok{# }
\CommentTok{# sample10 <- sort(sample10)}
\CommentTok{# #low = 25/1000}
\CommentTok{# sample10.2.5 <- sample10[25]}
\CommentTok{# #median}
\CommentTok{# sample10.50 <- sample10[500]}
\CommentTok{# #high = 975/1000}
\CommentTok{# sample10.975 <- sample10[975]}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[5,] <- c("detect1",detect1,sample2.50,sample2.2.5,sample2.975,NA)}
\CommentTok{# Sumtable[6,] <- c("detect2",detect2,sample5.50,sample5.2.5,sample5.975,NA)}
\CommentTok{# Sumtable[7,] <- c("detect5",detect3,sample10.50,sample10.2.5,sample10.975,NA)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----detection sim.2-----------------------------------------------------}
\CommentTok{# }
\CommentTok{# #be very careful as Dat is just IDS and no id of females with calves}
\CommentTok{# #BUT Data is identified females...}
\CommentTok{# length(Data$ID)}
\CommentTok{# length(dat$ID)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# glimpse(Data)}
\CommentTok{# dat.detect <- dplyr::select(Data,ID,Calves,Calves.1, Calves.2) %>%}
\CommentTok{#                   mutate(Calves = factor(Calves),}
\CommentTok{#                          Calves.1 = factor(Calves.1),}
\CommentTok{#                          Calves.2 = factor(Calves.2))}
\CommentTok{# }
\CommentTok{# a <- as.data.frame.matrix(table(Data$ID,Data$Calves))}
\CommentTok{# head(a)}
\CommentTok{# a[,7] <-row.names(a)}
\CommentTok{# colnames(a)[1] <- "y2006"}
\CommentTok{# colnames(a)[2] <- "y2007"}
\CommentTok{# colnames(a)[3] <- "y2008"}
\CommentTok{# colnames(a)[4] <- "y2009"}
\CommentTok{# colnames(a)[5] <- "y2010"}
\CommentTok{# colnames(a)[6] <- "y2011"}
\CommentTok{# colnames(a)[7] <- "ID"}
\CommentTok{# a[,8] <- 0}
\CommentTok{# colnames(a)[8] <- "y2012"}
\CommentTok{# a[,9] <- 0}
\CommentTok{# colnames(a)[9] <- "y2013"}
\CommentTok{# a <- dplyr::select(a,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012, y2013)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# b <- as.data.frame.matrix(table(Data$ID,Data$Calves.1))}
\CommentTok{# head(b)}
\CommentTok{# b[,5] <-row.names(b)}
\CommentTok{# colnames(b)[5] <- "ID"}
\CommentTok{# b[,6] <- 0}
\CommentTok{# colnames(b)[6] <- "y2006"}
\CommentTok{# b[,7] <- 0}
\CommentTok{# colnames(b)[7] <- "y2007"}
\CommentTok{# b[,8] <- 0}
\CommentTok{# colnames(b)[8] <- "y2008"}
\CommentTok{# b[,9] <- 0}
\CommentTok{# colnames(b)[9] <- "y2009"}
\CommentTok{# colnames(b)[1] <- "y2010"}
\CommentTok{# colnames(b)[2] <- "y2011"}
\CommentTok{# colnames(b)[3] <- "y2012"}
\CommentTok{# colnames(b)[4] <- "y2013"}
\CommentTok{# b <- dplyr::select(b,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012, y2013)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# c <- as.data.frame.matrix(table(Data$ID,Data$Calves.2))}
\CommentTok{# head(c)}
\CommentTok{# colnames(c)[1] <- "y2013"}
\CommentTok{# c[,2] <-row.names(c)}
\CommentTok{# colnames(c)[2] <- "ID"}
\CommentTok{# c[,3] <- 0}
\CommentTok{# colnames(c)[3] <- "y2006"}
\CommentTok{# c[,4] <- 0}
\CommentTok{# colnames(c)[4] <- "y2007"}
\CommentTok{# c[,5] <- 0}
\CommentTok{# colnames(c)[5] <- "y2008"}
\CommentTok{# c[,6] <- 0}
\CommentTok{# colnames(c)[6] <- "y2009"}
\CommentTok{# c[,7] <- 0}
\CommentTok{# colnames(c)[7] <- "y2010"}
\CommentTok{# c[,8] <- 0}
\CommentTok{# colnames(c)[8] <- "y2011"}
\CommentTok{# c[,9] <- 0}
\CommentTok{# colnames(c)[9] <- "y2012"}
\CommentTok{# }
\CommentTok{# c <- dplyr::select(c,ID,y2006,y2007,y2008, y2009, y2010, y2011, y2012,y2013)}
\CommentTok{# }
\CommentTok{# countdat <- rbind(a,b,c)}
\CommentTok{# glimpse(countdat)}
\CommentTok{# head(full.dat)}
\CommentTok{# }
\CommentTok{# full.dat <- group_by(countdat, ID) %>%}
\CommentTok{#   summarise(y2006 = sum(y2006),}
\CommentTok{#             y2007 = sum(y2007),}
\CommentTok{#             y2008 = sum(y2008),}
\CommentTok{#             y2009 = sum(y2009),}
\CommentTok{#             y2010 = sum(y2010),}
\CommentTok{#             y2011 = sum(y2011),}
\CommentTok{#             y2012 = sum(y2012),}
\CommentTok{#             y2013 = sum(y2013))}
\CommentTok{# }
\CommentTok{# 2012-2006}
\CommentTok{# }
\CommentTok{# ##checking....}
\CommentTok{# }
\CommentTok{# sort(Data$ID)}
\CommentTok{# filter(Data, ID == "AI06022")}
\CommentTok{# filter(Data, ID == "AI08340")}
\CommentTok{# filter(Data, ID == "AI08343")}
\CommentTok{# }
\CommentTok{# head(Data)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# # glimpse(c)}
\CommentTok{# # Data$Calves.1,}
\CommentTok{# # # Spread and gather are complements}
\CommentTok{# # df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))}
\CommentTok{# # df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----different missing intervals 2---------------------------------------}
\CommentTok{# longer5.6 <- c(sample.true,5,6,6)}
\CommentTok{# }
\CommentTok{# #greater.than.2}
\CommentTok{# mean.56<-sum(longer5.6)/length(longer5.6)}
\CommentTok{# s.56<-sd(longer5.6)}
\CommentTok{# SE.56<-s.56/(sqrt(length(longer5.6)))}
\CommentTok{# n.56<-(length(longer5.6))}
\CommentTok{# low.qt.56<- mean.56-(qt(0.975,length(longer5.6))*SE.56)}
\CommentTok{# high.qt.56 <- mean.56+(qt(0.975,length(longer5.6))*SE.56)}
\CommentTok{# }
\CommentTok{# #add it to the table from bradford data}
\CommentTok{# Sumtable[8,] <- c("longer.56",n.56,mean.56,low.qt.56,high.qt.56,sd(longer5.6))}
\CommentTok{# }
\CommentTok{# ###sort out numbering in dataframe}
\CommentTok{# Sumtable <-  as.data.frame(Sumtable)}
\CommentTok{# }
\CommentTok{#  Sumtable$n <- as.numeric(as.character(Sumtable$n))}
\CommentTok{#  Sumtable$mY <- as.numeric(as.character(Sumtable$mY))}
\CommentTok{#  Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))}
\CommentTok{#  Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))}
\CommentTok{#  Sumtable$sd <- as.numeric(as.character(Sumtable$sd))}
\CommentTok{#  Sumtable$interval <- as.character(Sumtable$interval)}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----missing_data_table 2, echo=FALSE------------------------------------}
\CommentTok{# library(knitr)}
\CommentTok{# }
\CommentTok{# kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))}
\CommentTok{# }
\CommentTok{# }
\CommentTok{# }
\CommentTok{# ## ----referee_comment3_plot, echo=FALSE-----------------------------------}
\CommentTok{# ggplot(Sumtable, aes(y = mY, x = interval)) +}
\CommentTok{#   geom_point(size = 5) +}
\CommentTok{#   geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +}
\CommentTok{#   scale_y_continuous(breaks = round(seq(2.3, 5, by = 0.2),1)) +}
\CommentTok{#   labs(y = "Mean calving interval",x = "Calving interval modification" ) +}
\CommentTok{#   geom_point(size = 3) +}
\CommentTok{#   theme_classic() +}
\CommentTok{#   theme_hc() +}
\CommentTok{#   theme(legend.position="none")}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{exercise-4-2}{%
\section{Exercise 4}\label{exercise-4-2}}

In these exercises, you will be adapting the code written in this chapter to investigate slightly different questions. You should create a new R script \texttt{Ex4.R} in your working directory for these exercises so your chapter code is left unchanged. Exercise 4A is based solely on the required material and Exercises 4B - 4F are based on the example cases. You should work through each example before attempting each of the later exercises.

\emph{The solutions to this exercise are found at the end of this book (\protect\hyperlink{ex4a-answers}{here}). You are \textbf{strongly recommended} to make a good attempt at completing this exercise on your own and only look at the solutions when you are truly stumped.}

\hypertarget{exercise-4a-required-material-only-2}{%
\subsection*{Exercise 4A: Required Material Only}\label{exercise-4a-required-material-only-2}}
\addcontentsline{toc}{subsection}{Exercise 4A: Required Material Only}

These questions are based on the material in Sections \ref{randomness} - \ref{mc-summaries} only.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate flipping an unfair coin (probability of heads = 0.6) 100 times using \texttt{rbinom()}. Count the number of heads and tails.
\item
  Simulate flipping the same unfair coin 100 times, but using \texttt{sample()} instead. Determine what fraction of the flips resulted in heads.
\item
  Simulate rolling a fair 6-sided die 100 times using \texttt{sample()}. Determine what fraction of the rolls resulted in an even number.
\item
  Simulate rolling the same die 100 times, but use the function \texttt{rmultinom()} instead. Look at the help file for details on how to use this function. Determine what fraction of the rolls resulted in an odd number.
\end{enumerate}

\protect\hyperlink{ex4a-answers}{Solutions}

\hypertarget{exercise-4b-test-rnorm-2}{%
\subsection*{\texorpdfstring{Exercise 4B: Test \texttt{rnorm}}{Exercise 4B: Test rnorm}}\label{exercise-4b-test-rnorm-2}}
\addcontentsline{toc}{subsection}{Exercise 4B: Test \texttt{rnorm}}

These questions will require you to adapt the code written in Section \ref{rnorm-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adapt this example to investigate another univariate probability distribution, like \texttt{-lnorm()}, \texttt{-pois()}, or \texttt{-beta()}. See the help files (e.g., \texttt{?rpois}) for details on how to use each function.
\end{enumerate}

\protect\hyperlink{ex4b-answers}{Solutions}

\hypertarget{exercise-4c-stochastic-power-analysis-2}{%
\subsection*{Exercise 4C: Stochastic Power Analysis}\label{exercise-4c-stochastic-power-analysis-2}}
\addcontentsline{toc}{subsection}{Exercise 4C: Stochastic Power Analysis}

These questions will require you to adapt the code written in Section \ref{power-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What sample size \texttt{n} do you need to have a power of 0.8 of detecting a significant difference between the two tagging methods?
\item
  How do the inferences from the power analysis change if you are interested in \texttt{p\_new\ =\ 0.4} instead of \texttt{p\_new\ =\ 0.25}? Do you need to tag more or fewer fish in this case?
\item
  Your analysis takes a bit of time to run so you are interested in tracking its progress. Add a progress message to your nested \texttt{for()} loop that will print the sample size currently being analyzed:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}r}\StringTok{"}\NormalTok{, }\StringTok{"Sample Size = "}\NormalTok{, n_try[n])}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{I) \{}
\NormalTok{    ...}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\protect\hyperlink{ex4c-answers}{Solutions}

\hypertarget{exercise-4d-harvest-policy-analysis-2}{%
\subsection*{Exercise 4D: Harvest Policy Analysis}\label{exercise-4d-harvest-policy-analysis-2}}
\addcontentsline{toc}{subsection}{Exercise 4D: Harvest Policy Analysis}

These questions will require you to adapt the code written in Section \ref{harv-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add an argument to \texttt{ricker\_sim()} that will give the user an option to create a plot that shows the time series of recruitment, harvest, and escapement all on the same plot. Set the default to be to not plot the result, in case you forget to turn it off before performing the Monte Carlo analysis.
\item
  Add an \emph{error handler} to \texttt{ricker\_sim()} that will cause the function to return an error \texttt{if()} the names of the vector passed to the \texttt{param} argument aren't what the function is expecting. You can use \texttt{stop("Error\ Message\ Goes\ Here")} to have your function stop and return an error.
\item
  How do the results of the trade-off analysis differ if the process error was larger (a larger value of \(\sigma\))?
\item
  Add implementation error to the harvest policy. That is, if the target exploitation rate is \(U\), make the real exploitation rate in year \(y\) be: \(U_y \sim Beta(a,b)\), where \(a = 100U\) and \(b = 100(1-U)\). You can make there be more implementation error by inserting a smaller number other than 100 here. How does this affect the trade-off analysis?
\end{enumerate}

\protect\hyperlink{ex4d-answers}{Solutions}

\hypertarget{exercise-4e-the-bootstrap-2}{%
\subsection*{Exercise 4E: The Bootstrap}\label{exercise-4e-the-bootstrap-2}}
\addcontentsline{toc}{subsection}{Exercise 4E: The Bootstrap}

These questions will require you to adapt the code written in Section \ref{boot-test-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replicate the bootstrap analysis, but adapt it for the linear regression example in Section \ref{regression}. Stop at the step where you summarize the 95\% interval range.
\item
  Compare the 95\% bootstrap confidence intervals to the intervals you get by running the \texttt{predict()} function on the original data set with the argument \texttt{interval\ =\ "confidence"}.
\end{enumerate}

\protect\hyperlink{ex4e-answers}{Solutions}

\hypertarget{exercise-4f-permutation-tests-2}{%
\subsection*{Exercise 4F: Permutation Tests}\label{exercise-4f-permutation-tests-2}}
\addcontentsline{toc}{subsection}{Exercise 4F: Permutation Tests}

These questions will require you to adapt the code written in Section \ref{perm-test-ex}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adapt the code to perform a permutation test for the difference in each of the zooplankton densities between treatments. Don't forget to fix the missing value in the \texttt{chao} variable. See \protect\hyperlink{ex1b}{Exercise 2} for more details on this.
\item
  Adapt the code to perform a permutation test for another data set used in this book where there are observations of both a categorical variable and a continuous variable. The data sets \texttt{sockeye.csv}, \texttt{growth.csv}, or \texttt{creel.csv} should be good starting points.
\item
  Add a calculation of the p-value for a one-tailed test (i.e., that the difference in means is greater or less than zero). Steps 1 - 4 are the same: all you need is \texttt{Dnull} and \texttt{Dobs}. Don't be afraid to Google this if you are confused.
\end{enumerate}

\protect\hyperlink{ex4f-answers}{Solutions}

\bibliography{book.bib,packages.bib}


\end{document}
